{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kostrovskiy/prog/AI/NLP/DeepPavlov/env/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/kostrovskiy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kostrovskiy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/kostrovskiy/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/kostrovskiy/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n",
      "2018-08-02 22:43:43.134 DEBUG in 'gensim.models.doc2vec'['doc2vec'] at line 73: Fast version of gensim.models.doc2vec is being used\n",
      "2018-08-02 22:43:43.145 INFO in 'summa.preprocessing.cleaner'['textcleaner'] at line 20: 'pattern' package not found; tag filters are not available for English\n",
      "2018-08-02 22:43:55.113 DEBUG in 'matplotlib.backends'['__init__'] at line 90: backend module://ipykernel.pylab.backend_inline version unknown\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import deeppavlov\n",
    "from deeppavlov.dataset_readers.ontonotes_reader import OntonotesReader\n",
    "from deeppavlov.models.preprocessors.capitalization import CapitalizationPreprocessor\n",
    "from deeppavlov.models.embedders.glove_embedder import GloVeEmbedder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'valid', 'test'])\n",
      "Num of train sentences: 75187\n",
      "Num of test sentences: 9479\n"
     ]
    }
   ],
   "source": [
    "reader = OntonotesReader()\n",
    "dataset = reader.read(data_path='data/')\n",
    "print(dataset.keys())\n",
    "print('Num of train sentences: {}'.format(len(dataset['train'])))\n",
    "print('Num of test sentences: {}'.format(len(dataset['test'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['Mr.', 'Bush', 'also', 'named', 'former', 'Cuban', 'refugee', 'Mel', 'Martinez', 'as', 'Secretary', 'of', 'Housing', 'and', 'Urban', 'Development', '.'], ['O', 'B-PERSON', 'O', 'O', 'O', 'B-NORP', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O']), (['Currently', ',', 'the', 'degree', 'of', 'dependence', 'on', 'the', 'outside', 'of', 'China', \"'s\", 'economy', 'has', 'reached', '42', '%', ',', 'and', 'the', 'space', 'of', 'utilizing', 'overseas', 'markets', 'and', 'resources', 'is', 'in', 'the', 'process', 'of', 'expanding', ',', 'but', 'is', 'more', 'easily', 'subject', 'to', 'the', 'influences', 'of', 'the', 'international', 'environment', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'B-PERCENT', 'I-PERCENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['But', 'whether', 'such', 'moves', 'can', 'win', 'back', 'the', 'confidence', 'of', 'East', 'Germans', ',', 'who', 'have', 'taken', 'to', 'the', 'streets', 'by', 'the', 'thousands', 'in', 'recent', 'weeks', 'to', 'demand', 'democratic', 'changes', ',', 'depends', 'largely', 'on', 'whether', 'they', 'feel', 'they', 'can', 'trust', 'Mr.', 'Krenz', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'I-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O']), (['Andy', 'Cairns'], ['B-PERSON', 'I-PERSON']), (['I', 'totally', 'insist', 'on', 'it', '.'], ['O', 'O', 'O', 'O', 'O', 'O']), (['kind', 'of', 'threw', 'me', 'off'], ['O', 'O', 'O', 'O', 'O']), (['We', 'have', 'had', 'the', 'most', 'truthful', ',', 'constructive', ',', 'profound', 'negotiations', 'ever', 'to', 'be', 'held', 'since', 'this', 'phase', 'in', 'the', 'peace', 'talks', 'has', 'started', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['How', 'much', 'of', 'the', 'ancient', 'form', 'of', 'the', 'festival', 'survives', ',', 'and', 'what', 'new', 'elements', 'have', 'been', 'added', 'in', 'our', 'time', '?'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['The', 'notice', 'pointed', 'out', 'that', 'the', 'general', 'goal', 'of', 'fostering', 'and', 'developing', 'the', 'talented', 'people', 'market', 'is', ':', 'to', 'realize', 'individuals', 'independently', 'choosing', 'occupations', ',', 'work', 'units', 'independently', 'choosing', 'personnel', ',', 'markets', 'adjusting', 'to', 'supply', 'and', 'demand', ',', 'social', 'services', 'improving', ',', 'and', 'social', 'security', 'strengthening', ',', 'and', 'let', 'the', 'market', 'play', 'a', 'foundational', 'role', 'in', 'the', 'allocation', 'of', 'talent', 'resources', 'under', 'the', 'macro-control', 'of', 'the', 'state', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['Now', 'without', 'Saddam', 'Hussein', 'you', 'can', 'look', 'across', 'the', 'region', 'and', 'see', 'that', 'uh', 'a', 'lot', 'is', 'changing', 'thanks', 'to', 'the', 'President', \"'s\", 'democracy', 'uh', 'promotion', 'and', 'the', 'hard', 'work', 'of', 'people', 'in', 'those', 'countries', '/.'], ['O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'])]\n"
     ]
    }
   ],
   "source": [
    "n_examples = 10\n",
    "np.random.seed(12)\n",
    "indices = np.random.choice(len(dataset['train']), size=n_examples)\n",
    "# indices = (10,20,30,40,50)\n",
    "examples = [dataset['train'][i] for i in indices]\n",
    "print(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split tokens and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tokens_tags(dataset: list):\n",
    "    tokens = []\n",
    "    tags = []\n",
    "    for sample in dataset:\n",
    "        tokens.append(sample[0])\n",
    "        tags.append(sample[1])\n",
    "    return tokens, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train,tags_train = split_tokens_tags(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elmo wrapper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElmoEmbedder():\n",
    "    def __init__(self):\n",
    "        self.elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
    "        sess = tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        self.sess = sess\n",
    "\n",
    "    def get_tokens_embeddings(self, tokens_input: list, tokens_length:list=None):\n",
    "        if not tokens_length:\n",
    "            if isinstance(tokens_input[0], list):\n",
    "                tokens_length = [len(seq) for seq in tokens_input]\n",
    "            else:\n",
    "                tokens_length = len(tokens_input)\n",
    "        embeddings = self.elmo(\n",
    "                        inputs={\n",
    "                            \"tokens\": tokens_input,\n",
    "                            \"sequence_len\": tokens_length\n",
    "                        },\n",
    "                        signature=\"tokens\",\n",
    "                        as_dict=True)[\"elmo\"]\n",
    "        embeddings = self.sess.run([embeddings])\n",
    "        return embeddings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags2binary(tags, symb=True):\n",
    "    tags = copy.deepcopy(tags)\n",
    "    for seq in tags:\n",
    "        for i in range(len(seq)):\n",
    "            if symb:\n",
    "                if seq[i] != 'O':\n",
    "                    seq[i] = 'T'\n",
    "            else:\n",
    "                seq[i] = 1 if seq[i] != 'O' else 0\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lower_case(tokens:list):\n",
    "    tokens_lower = []\n",
    "    for seq in tokens:\n",
    "        tokens_lower.append([])\n",
    "        for token in seq:\n",
    "            tokens_lower[-1].append(token.lower())\n",
    "    return tokens_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens_len(tokens):\n",
    "    if isinstance(tokens[0], str):\n",
    "        tokens = [tokens]\n",
    "    return [len(seq) for seq in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding(tokens:list):\n",
    "    if isinstance(tokens[0], str):\n",
    "        return tokens, len(tokens)\n",
    "    elif isinstance(tokens[0], list):\n",
    "        tokens = copy.deepcopy(tokens)\n",
    "        max_len = 0\n",
    "        for seq in tokens:\n",
    "            if len(seq) > max_len:\n",
    "                max_len = len(seq)\n",
    "        for seq in tokens:\n",
    "            i = len(seq)\n",
    "            while i < max_len:\n",
    "                seq.append('')\n",
    "                i += 1\n",
    "        return tokens\n",
    "    else:\n",
    "        raise Exception('tokens should be either list of strings or list of lists of strings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(ar: list):\n",
    "    flat = []\n",
    "    for sublist in ar:\n",
    "        flat += sublist\n",
    "    return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_list_elements(ar: list, indices: list):\n",
    "    return [ar[i] for i in indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositeEmbedder():\n",
    "    def __init__(self, use_elmo=True, elmo_scale=1., use_cap_feat=False, use_glove=False):\n",
    "        self.use_elmo = use_elmo\n",
    "        self.elmo_scale = elmo_scale\n",
    "        self.use_cap_feat = use_cap_feat\n",
    "        self.use_glove = use_glove\n",
    "        if self.use_elmo:\n",
    "            self.elmo = ElmoEmbedder()\n",
    "        if self.use_cap_feat:\n",
    "            self.cap_prep = CapitalizationPreprocessor()\n",
    "        if self.use_glove:\n",
    "            self.glove = GloVeEmbedder('embeddings/glove.6B/glove.6B.100d.txt', pad_zero=True)\n",
    "        \n",
    "    def embed(self, tokens: list):\n",
    "        if isinstance(tokens[0], str):\n",
    "            tokens = [tokens]\n",
    "        # Get ELMo embeddings\n",
    "        if self.use_elmo:\n",
    "            tokens_input = add_padding(tokens)\n",
    "            tokens_length = get_tokens_len(tokens)\n",
    "            embeddings = self.elmo.get_tokens_embeddings(tokens_input, tokens_length)\n",
    "            embeddings *= self.elmo_scale\n",
    "            embed_size = embeddings.shape[-1]\n",
    "#             print(embeddings.shape)\n",
    "#             print(embed_size)\n",
    "\n",
    "        # Use capitalization features\n",
    "        if self.use_cap_feat:\n",
    "#             print('Use capitalization features')\n",
    "            cap_features = self.cap_prep(tokens)\n",
    "    #         print(cap_features)\n",
    "#             print(cap_features.shape)\n",
    "            embeddings = np.concatenate((embeddings, cap_features), axis=2)\n",
    "            embed_size = embeddings.shape[-1]\n",
    "#             print(embeddings.shape)\n",
    "\n",
    "        # Use GloVe embeddings\n",
    "        if self.use_glove:\n",
    "#             print('Use GloVe')\n",
    "            \n",
    "            glove_embed = self.glove(to_lower_case(tokens))\n",
    "            glove_embed = np.array(glove_embed)\n",
    "            if not self.use_elmo:\n",
    "                embeddings = glove_embed\n",
    "            else: \n",
    "                embeddings = np.concatenate((embeddings, glove_embed), axis=2)\n",
    "            embed_size = embeddings.shape[-1]\n",
    "#             print(embeddings.shape)\n",
    "        \n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate similarity of embedding vector to some prototype (centroid or smth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sim(token_vec, ne_prototype)->dict:\n",
    "    sim = {}\n",
    "    sim['euc_dist'] = np.linalg.norm(token_vec - ne_prototype)\n",
    "    sim['dot_prod'] = np.dot(token_vec, ne_prototype)\n",
    "    sim['cosine'] = np.dot(token_vec, ne_prototype)/(np.linalg.norm(token_vec)*np.linalg.norm(ne_prototype)) if np.linalg.norm(ne_prototype) != 0 else 0\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sim_batch(tokens: list, embeddings: np.ndarray, ne_prototype: np.ndarray)->list:\n",
    "    sim_list = []\n",
    "    tokens_length = get_tokens_len(tokens)\n",
    "    for i in range(len(tokens_length)):\n",
    "        sim_list.append([])\n",
    "        for j in range(tokens_length[i]):\n",
    "            token_vec = embeddings[i,j,:]\n",
    "            sim_list[i].append(calc_sim(token_vec, ne_prototype))\n",
    "    return sim_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_sim(sim_list):\n",
    "    sims_flat = {'euc_dist': [], 'dot_prod': [], 'cosine': []}\n",
    "    for i in range(len(sim_list)):\n",
    "        for j in range(len(sim_list[i])):\n",
    "            for sim_type in ['euc_dist', 'dot_prod', 'cosine']:\n",
    "                sims_flat[sim_type].append(sim_list[i][j][sim_type])\n",
    "    for sim_type in ['euc_dist', 'dot_prod', 'cosine']:\n",
    "        sims_flat[sim_type] = np.array(sims_flat[sim_type])\n",
    "    return sims_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate centroid for named entities embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ne_centroid_vec(tokens: list, tags: list, embeddings: np.ndarray=None, embedder: CompositeEmbedder=None):\n",
    "\n",
    "    # Calculate embeddings\n",
    "    if embedder != None:\n",
    "        embeddings = embedder.embed(tokens)\n",
    "\n",
    "    # Calculate average vector for ne-tags\n",
    "    embed_size = embeddings.shape[-1]\n",
    "    ne_prototype = np.zeros((embed_size,))\n",
    "    tokens_length = get_tokens_len(tokens)\n",
    "    n_ne_tags = 0\n",
    "    for i in range(len(tokens_length)):\n",
    "        for j in range(tokens_length[i]):\n",
    "            if tags[i][j] == 'T':\n",
    "                ne_prototype += embeddings[i,j,:].reshape((embed_size,))\n",
    "                n_ne_tags += 1\n",
    "    if n_ne_tags != 0:\n",
    "        ne_prototype /= n_ne_tags\n",
    "#     print('ne mean vector: {}'.format(ne_prototype))\n",
    "    \n",
    "    # Calculate similarities\n",
    "    sim_list = calc_sim_batch(tokens, embeddings, ne_prototype)\n",
    "\n",
    "    return ne_prototype, sim_list, embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate similarities of some test tokens to NE prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sim_to_ne_prototype(tokens: list, ne_prototype: np.ndarray, embeddings: np.ndarray=None, embedder: CompositeEmbedder=None):\n",
    "    if isinstance(tokens[0], str):\n",
    "        tokens = [tokens]\n",
    "    \n",
    "    tokens_length = get_tokens_len(tokens)\n",
    "    \n",
    "    # Calculate embeddings\n",
    "    if embedder != None:\n",
    "        embeddings = embedder.embed(tokens)\n",
    "    \n",
    "    # Calculate similarities\n",
    "    sim_list = calc_sim_batch(tokens, embeddings, ne_prototype)\n",
    "    \n",
    "    return sim_list, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/aggregation/scaling:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with aggregation/scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:28.801 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/aggregation/scaling:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with aggregation/scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/aggregation/weights:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with aggregation/weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:28.807 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/aggregation/weights:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with aggregation/weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/W_cnn_0:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:28.817 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/CNN/W_cnn_0:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/W_cnn_1:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:28.824 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/CNN/W_cnn_1:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/W_cnn_2:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:28.835 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/CNN/W_cnn_2:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/W_cnn_3:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:28.842 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/CNN/W_cnn_3:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/W_cnn_4:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:28.853 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/CNN/W_cnn_4:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/W_cnn_5:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:28.866 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/CNN/W_cnn_5:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/W_cnn_6:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:28.872 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/CNN/W_cnn_6:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/b_cnn_0:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:28.885 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/CNN/b_cnn_0:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/b_cnn_1:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:28.891 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/CNN/b_cnn_1:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/b_cnn_2:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:28.901 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/CNN/b_cnn_2:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/b_cnn_3:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:28.907 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/CNN/b_cnn_3:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/b_cnn_4:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:28.919 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/CNN/b_cnn_4:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/b_cnn_5:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:28.927 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/CNN/b_cnn_5:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/b_cnn_6:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:28.933 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/CNN/b_cnn_6:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN_high_0/W_carry:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_0/W_carry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:28.939 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/CNN_high_0/W_carry:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_0/W_carry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN_high_0/W_transform:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_0/W_transform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:28.946 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/CNN_high_0/W_transform:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_0/W_transform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN_high_0/b_carry:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_0/b_carry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:28.953 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/CNN_high_0/b_carry:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_0/b_carry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN_high_0/b_transform:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_0/b_transform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:28.962 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/CNN_high_0/b_transform:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_0/b_transform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN_high_1/W_carry:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_1/W_carry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:28.969 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/CNN_high_1/W_carry:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_1/W_carry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN_high_1/W_transform:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_1/W_transform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:28.977 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/CNN_high_1/W_transform:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_1/W_transform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN_high_1/b_carry:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_1/b_carry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:28.983 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/CNN_high_1/b_carry:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_1/b_carry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN_high_1/b_transform:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_1/b_transform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:28.991 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/CNN_high_1/b_transform:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_1/b_transform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN_proj/W_proj:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_proj/W_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:29.0 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/CNN_proj/W_proj:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_proj/W_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN_proj/b_proj:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_proj/b_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:29.7 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/CNN_proj/b_proj:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_proj/b_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:29.14 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:29.20 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:29.28 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:29.35 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:29.42 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:29.51 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:29.60 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:29.66 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:29.73 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:29.79 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:29.84 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:29.90 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/char_embed:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/char_embed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-02 23:27:29.98 INFO in 'tensorflow'['tf_logging'] at line 116: Initialize variable module_1/bilm/char_embed:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/char_embed\n",
      "2018-08-02 23:27:29.623 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 60: [loading embeddings from `/home/kostrovskiy/prog/AI/NLP/DeepPavlov/download/embeddings/glove.6B/glove.6B.100d.txt`]\n",
      "2018-08-02 23:27:29.624 INFO in 'gensim.models.keyedvectors'['keyedvectors'] at line 204: loading projection weights from /home/kostrovskiy/prog/AI/NLP/DeepPavlov/download/embeddings/glove.6B/glove.6B.100d.txt\n",
      "2018-08-02 23:27:29.624 DEBUG in 'smart_open.smart_open_lib'['smart_open_lib'] at line 176: {'kw': {}, 'mode': 'rb', 'uri': '/home/kostrovskiy/prog/AI/NLP/DeepPavlov/download/embeddings/glove.6B/glove.6B.100d.txt'}\n",
      "2018-08-02 23:27:59.890 INFO in 'gensim.models.keyedvectors'['keyedvectors'] at line 266: loaded (400000, 100) matrix from /home/kostrovskiy/prog/AI/NLP/DeepPavlov/download/embeddings/glove.6B/glove.6B.100d.txt\n"
     ]
    }
   ],
   "source": [
    "embedder = CompositeEmbedder(use_elmo=True, elmo_scale=1, use_cap_feat=True, use_glove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate NE centroid for given examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_prototype, _, _ = calc_ne_centroid_vec(tokens_train, tags_train, embedder=embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select some unlabeled examples from test set and estimate similarity to named entity for each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_sentences = 10\n",
    "np.random.seed(44)\n",
    "indices_test = np.random.choice(len(dataset['test']), size=n_test_sentences)\n",
    "test_sentences = select_list_elements(dataset['test'], indices_test)\n",
    "tokens_test,tags_test = split_tokens_tags(test_sentences)\n",
    "# print(tokens_test)\n",
    "# print(tags_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_list_test, _ = calc_sim_to_ne_prototype(tokens_test, ne_prototype, embedder=embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group similarities with tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_tokens_sim(tokens: list, sim_list: list, sim_type='cosine'):\n",
    "    tokens_sim = []\n",
    "    for i in range(len(tokens)):\n",
    "        tokens_sim.append([])\n",
    "        for j in range(len(tokens[i])):\n",
    "            tokens_sim[-1].append((tokens[i][j], sim_list[i][j][sim_type]))\n",
    "    return tokens_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_test_sim = zip_tokens_sim(tokens_test, sim_list_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print test sentences with NE similarities estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorate_ne_token(token, tag):\n",
    "    if tag == 'T':\n",
    "        token = '[[' + token + ']]'\n",
    "    return token\n",
    "def format_labeled_examples(tokens_input: list, tags_input: list):\n",
    "    s = '+++++++++ Input examples +++++++++\\n\\n'\n",
    "    for i in range(len(tokens_input)):\n",
    "        for j in range(len(tokens_input[i])):\n",
    "            s += decorate_ne_token(tokens_input[i][j], tags_input[i][j]) + ' '\n",
    "        s += '\\n\\n'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_inference_results(tokens_sim: list):\n",
    "    s = '+++++++++ Tests +++++++++\\n\\n'\n",
    "    for seq in tokens_sim:\n",
    "        for token, sim in seq:\n",
    "            s += '{}[{:.3f}]'.format(token, sim)\n",
    "            s += ' '\n",
    "        s += '\\n\\n'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++ Input examples +++++++++\n",
      "\n",
      "Mr. [[Bush]] also named former [[Cuban]] refugee [[Mel]] [[Martinez]] as Secretary of [[Housing]] [[and]] [[Urban]] [[Development]] . \n",
      "\n",
      "Currently , the degree of dependence on the outside of [[China]] 's economy has reached [[42]] [[%]] , and the space of utilizing overseas markets and resources is in the process of expanding , but is more easily subject to the influences of the international environment . \n",
      "\n",
      "But whether such moves can win back the confidence of [[East]] [[Germans]] , who have taken to the streets by the [[thousands]] in [[recent]] [[weeks]] to demand democratic changes , depends largely on whether they feel they can trust Mr. [[Krenz]] . \n",
      "\n",
      "[[Andy]] [[Cairns]] \n",
      "\n",
      "I totally insist on it . \n",
      "\n",
      "kind of threw me off \n",
      "\n",
      "We have had the most truthful , constructive , profound negotiations ever to be held since this phase in the peace talks has started . \n",
      "\n",
      "How much of the ancient form of the festival survives , and what new elements have been added in our time ? \n",
      "\n",
      "The notice pointed out that the general goal of fostering and developing the talented people market is : to realize individuals independently choosing occupations , work units independently choosing personnel , markets adjusting to supply and demand , social services improving , and social security strengthening , and let the market play a foundational role in the allocation of talent resources under the macro-control of the state . \n",
      "\n",
      "Now without [[Saddam]] [[Hussein]] you can look across the region and see that uh a lot is changing thanks to the President 's democracy uh promotion and the hard work of people in those countries /. \n",
      "\n",
      "+++++++++ Tests +++++++++\n",
      "\n",
      "Mainland[0.323] China[0.438] shares[0.176] the[0.254] same[0.209] language[0.227] as[0.235] Taiwan[0.464] and[0.298] it[0.335] offers[0.167] attractive[0.233] investment[0.289] conditions[0.285] .[0.261] \n",
      "\n",
      "Remember[0.282] who[0.334] Janet[0.229] shared[0.235] the[0.196] stage[0.198] with[0.311] at[0.202] the[0.302] Superbowl[0.240] ?[0.203] \n",
      "\n",
      "Once[0.320] you[0.238] invoke[0.139] the[0.285] wrath[0.228] or[0.210] the[0.315] extreme[0.208] interest[0.246] of[0.211] a[0.312] federal[0.273] prosecutor[0.348] you[0.278] have[0.274] to[0.245] be[0.269] very[0.230] very[0.235] careful[0.261] /.[0.196] \n",
      "\n",
      "With[0.309] each[0.257] new[0.249] era[0.277] ,[0.324] role[0.269] models[0.304] change[0.314] .[0.257] \n",
      "\n",
      "The[0.329] FBI[0.297] message[0.217] went[0.180] to[0.217] three[0.360] Pentagon[0.346] agencies[0.353] ,[0.318] and[0.316] as[0.260] a[0.249] result[0.172] ,[0.309] the[0.334] visit[0.269] of[0.202] one[0.321] American[0.323] warship[0.269] to[0.227] Yemen[0.431] was[0.276] canceled[0.280] .[0.265] \n",
      "\n",
      "The[0.331] Bush[0.346] administration[0.345] ,[0.317] trying[0.290] to[0.260] blunt[0.233] growing[0.258] demands[0.308] from[0.277] Western[0.331] Europe[0.467] for[0.269] a[0.299] relaxation[0.217] of[0.181] controls[0.297] on[0.230] exports[0.341] to[0.237] the[0.355] Soviet[0.275] bloc[0.343] ,[0.336] is[0.286] questioning[0.212] whether[0.293] Italy[0.466] 's[0.222] Ing[0.201] .[0.313] C.[0.221] Olivetti[0.278] &[0.140] Co.[0.229] supplied[0.131] militarily[0.212] valuable[0.183] technology[0.306] to[0.234] the[0.382] Soviets[0.413] .[0.278] \n",
      "\n",
      "When[0.329] they[0.293] did[0.251] that[0.392] and[0.299] I[0.317] saw[0.245] them[0.387] and[0.313] I[0.313] told[0.210] them[0.363] in[0.237] a[0.245] voice[0.236] of[0.217] Milosevic[0.374] ,[0.308] ``[0.375] Ladies[0.292] and[0.245] gentleman[0.248] ,[0.317] I[0.319] am[0.243] definitely[0.210] finished[0.291] .[0.258] ''[0.276] \n",
      "\n",
      "Recapping[0.178] the[0.330] developments[0.334] of[0.204] this[0.284] disturbing[0.129] day[0.330] in[0.232] the[0.318] Middle[0.263] East[0.361] and[0.267] the[0.319] Arabian[0.207] Peninsula[0.287] --[0.290] at[0.267] least[0.257] six[0.338] American[0.320] sailors[0.282] are[0.242] dead[0.274] ,[0.290] 11[0.342] still[0.223] missing[0.273] and[0.247] 35[0.338] injured[0.266] after[0.236] what[0.281] intelligence[0.223] experts[0.245] say[0.234] was[0.198] a[0.227] well[0.166] -[0.221] planned[0.230] terrorist[0.237] bombing[0.246] that[0.247] ripped[0.117] a[0.223] 20[0.255] x[0.138] 40[0.264] -[0.186] foot[0.145] hole[0.139] in[0.210] the[0.290] Navy[0.265] destroyer[0.204] ``[0.287] USS[0.213] Cole[0.332] ''[0.252] in[0.225] the[0.285] Yemeni[0.241] port[0.195] of[0.147] Aden[0.366] .[0.246] \n",
      "\n",
      "Characters[0.310] proliferate[0.200] out[0.273] of[0.165] the[0.268] imagination[0.259] of[0.212] the[0.329] narrator[0.294] so[0.256] that[0.319] at[0.240] a[0.230] certain[0.178] point[0.225] ,[0.302] you[0.286] have[0.281] a[0.269] new[0.262] he[0.401] ,[0.325] you[0.324] have[0.285] a[0.277] new[0.254] she[0.381] ,[0.312] you[0.301] have[0.276] a[0.263] you[0.385] ,[0.302] and[0.301] each[0.263] one[0.349] of[0.199] these[0.322] characters[0.291] tells[0.167] stories[0.250] ,[0.292] each[0.211] story[0.232] of[0.189] which[0.305] is[0.245] designed[0.230] to[0.232] give[0.190] you[0.249] a[0.216] deeper[0.127] sense[0.172] of[0.198] the[0.285] richness[0.233] and[0.217] the[0.283] complexity[0.234] of[0.188] life[0.333] in[0.254] China[0.516] .[0.266] \n",
      "\n",
      "%uh[0.199] but[0.283] it[0.317] 's[0.208] a[0.208] lot[0.197] less[0.201] expensive[0.225] if[0.236] we[0.218] do[0.185] it[0.329] that[0.257] way[0.240] than[0.248] if[0.239] we[0.226] actually[0.176] make[0.225] my[0.227] parents[0.252] in[0.208] law[0.225] pay[0.193] it[0.356] ,[0.317] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = ''\n",
    "text += format_labeled_examples(tokens_train, tags_train)\n",
    "text += format_inference_results(tokens_test_sim)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
