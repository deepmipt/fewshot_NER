{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5484,
     "status": "ok",
     "timestamp": 1535754876249,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "8FklJFwcPj4U",
    "outputId": "5b85dbb6-4bf1-456e-bc79-b2757286463c"
   },
   "outputs": [],
   "source": [
    "# For google colab\n",
    "# ! pip install deeppavlov\n",
    "# ! pip install pybind11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HWrowqeyPaAj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-10 18:30:34.403 DEBUG in 'matplotlib.backends'['__init__'] at line 90: backend module://ipykernel.pylab.backend_inline version unknown\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "from math import ceil, floor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from typing import *\n",
    "import copy\n",
    "import sys\n",
    "from deeppavlov.dataset_readers.ontonotes_reader import OntonotesReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dz9piiTQa_Nr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FGoiwLqLPaAo"
   },
   "outputs": [],
   "source": [
    "TRAIN_ELMO = False\n",
    "TRAIN_ALL_ELMO_PARAMS = False\n",
    "MULTICLASS = False\n",
    "USE_BIO_MARKUP = False\n",
    "N_EXAMPLES = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QD4qUfNcPaAr"
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    reader = OntonotesReader()\n",
    "    dataset = reader.read(data_path='data/')\n",
    "    # print(dataset.keys())\n",
    "    print('Num of train sentences: {}'.format(len(dataset['train'])))\n",
    "    print('Num of valid sentences: {}'.format(len(dataset['valid'])))\n",
    "    print('Num of test sentences: {}'.format(len(dataset['test'])))\n",
    "    print(dataset['train'][50:60])\n",
    "    return dataset\n",
    "\n",
    "def filter_data_by_ne_type(data:list, ne_types:list, tags2binary=False, preserveBIO=False, keepIfAny=True):\n",
    "    if ne_types == None or len(ne_types) == 0:\n",
    "        return data\n",
    "    data_filtered = []\n",
    "    for tokens,tags in data:\n",
    "        contains_all = True\n",
    "        contains_any = False\n",
    "        tags_norm = [getNeTagMainPart(t) for t in tags]\n",
    "        for ne_type in ne_types:\n",
    "            if not ne_type in tags_norm:\n",
    "                contains_all = False\n",
    "            if ne_type in tags_norm:\n",
    "                contains_any = True\n",
    "        if contains_all or (keepIfAny and contains_any):\n",
    "            if tags2binary:\n",
    "                if preserveBIO:\n",
    "                    tags = [tags[i][:2]+'T' if t in ne_types else 'O' for i,t in enumerate(tags_norm)]\n",
    "                else:\n",
    "                    tags = ['T' if t in ne_types else 'O' for t in tags_norm]\n",
    "            else:\n",
    "                if preserveBIO:\n",
    "                    tags = [tags[i][:2]+t if t in ne_types else 'O' for i,t in enumerate(tags_norm)]\n",
    "                else:\n",
    "                    tags = [t if t in ne_types else 'O' for i,t in enumerate(tags_norm)]\n",
    "            data_filtered.append((tokens,tags))\n",
    "    return data_filtered\n",
    "\n",
    "def filter_dataset_by_ne_types(dataset: list, ne_types, tags2binary=True, preserveBIO=False, keepIfAny=True):\n",
    "    dataset = copy.deepcopy(dataset)\n",
    "    if not isinstance(ne_types, list):\n",
    "        ne_types = [ne_types]\n",
    "    for dataset_type in ['train', 'valid', 'test']:\n",
    "        dataset[dataset_type] = filter_data_by_ne_type(dataset[dataset_type], ne_types, tags2binary=tags2binary, preserveBIO=preserveBIO)\n",
    "        print('Num of {} sentences: {}'.format(dataset_type, len(dataset[dataset_type])))\n",
    "    return dataset\n",
    "\n",
    "def get_data_sample(data, n_samples: int):\n",
    "    indices = np.random.choice(len(data), size=n_samples, replace=False)\n",
    "    return split_tokens_tags([data[i] for i in indices])\n",
    "\n",
    "def get_tokens_len(tokens):\n",
    "    if isinstance(tokens[0], str):\n",
    "        tokens = [tokens]\n",
    "    return [len(seq) for seq in tokens]\n",
    "\n",
    "def to_lower_case(tokens:list):\n",
    "    tokens_lower = []\n",
    "    for seq in tokens:\n",
    "        tokens_lower.append([])\n",
    "        for token in seq:\n",
    "            tokens_lower[-1].append(token.lower())\n",
    "    return tokens_lower\n",
    "\n",
    "def add_padding(tokens:list):\n",
    "    if isinstance(tokens[0], str):\n",
    "        return tokens, len(tokens)\n",
    "    elif isinstance(tokens[0], list):\n",
    "        tokens = copy.deepcopy(tokens)\n",
    "        max_len = 0\n",
    "        for seq in tokens:\n",
    "            if len(seq) > max_len:\n",
    "                max_len = len(seq)\n",
    "        for seq in tokens:\n",
    "            i = len(seq)\n",
    "            while i < max_len:\n",
    "                seq.append('')\n",
    "                i += 1\n",
    "        return tokens\n",
    "    else:\n",
    "        raise Exception('tokens should be either list of strings or list of lists of strings')\n",
    "  \n",
    "def getNeTagMainPart(tag:str):\n",
    "    return tag[2:] if len(tag) > 2 else tag\n",
    "\n",
    "def tags2binaryFlat(tags):\n",
    "    return np.array([1 if t == 'T' or (len(t) > 2 and t[2:] == 'T') else 0 for seq in tags for t in seq])\n",
    "\n",
    "def tagsEncodePadded(tags:list, binary=True, tag2idx=None):\n",
    "#     if tag2idx:\n",
    "#         binary = False\n",
    "    if isinstance(tags[0], str):\n",
    "        tags = [tags]\n",
    "    n_sentences = len(tags)\n",
    "    tokens_length = get_tokens_len(tags)\n",
    "    max_len = np.max(tokens_length)\n",
    "    y = np.zeros((n_sentences, max_len))\n",
    "    for i, sen in enumerate(tags):\n",
    "        for j, tag in enumerate(sen):\n",
    "            if binary: \n",
    "                y[i][j] = 1 if tags[i][j] != 'O' else 0\n",
    "            else:\n",
    "                if tag2idx:\n",
    "#                     tag_name = tag if USE_BIO_MARKUP else getNeTagMainPart(tag)\n",
    "                    tag_name = tag   # in case when BIO markup was deleted from data\n",
    "                    y[i][j] = tag2idx[tag_name]\n",
    "                else:\n",
    "                    raise Exception('tag2idx dictionary should be provided')\n",
    "    return y\n",
    "\n",
    "def get_matrices(tokens, tags, embedder):\n",
    "    return (embeddings2feat_mat(embedder.embed(tokens), get_tokens_len(tokens)),\n",
    "           tags2binaryFlat(tags))\n",
    "  \n",
    "def split_tokens_tags(dataset: list):\n",
    "    tokens = []\n",
    "    tags = []\n",
    "    for sample in dataset:\n",
    "        tokens.append(sample[0])\n",
    "        tags.append(sample[1])\n",
    "    return tokens, tags\n",
    "\n",
    "def count_tags(dataset: list):\n",
    "    tag_counts = {}\n",
    "    for data_type in ['train', 'valid', 'test']:\n",
    "        tag_counts[data_type] = {}\n",
    "        for sen in dataset[data_type]:\n",
    "            tags = sen[1]\n",
    "            for tag in tags:\n",
    "                if tag_counts[data_type].get(tag):\n",
    "                    tag_counts[data_type][tag] += 1\n",
    "                else:\n",
    "                    tag_counts[data_type][tag] = 1\n",
    "    return tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11467,
     "status": "ok",
     "timestamp": 1535754891200,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "gKtBm_jBPaAt",
    "outputId": "b9bf0ed3-d79a-45e2-be3c-3de8fec4c838"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of train sentences: 75187\n",
      "Num of valid sentences: 9603\n",
      "Num of test sentences: 9479\n",
      "[(['Actions', 'had', 'to', 'be', 'taken', 'to', 'break', 'through', 'the', 'blockade', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['On', 'a', 'night', 'in', 'late', 'July', '1940', ',', 'the', 'atmosphere', 'in', 'Zhuanbi', 'Village', 'in', 'Shaanxi', 'was', 'unusual', '.'], ['O', 'B-DATE', 'I-DATE', 'I-DATE', 'I-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'B-GPE', 'O', 'O', 'O']), (['Villager', 'Xiao', 'Jianghe', 'has', 'a', 'vivid', 'memory', 'of', 'this', 'piece', 'of', 'history', '.'], ['O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['On', 'that', 'dark', 'night', ',', 'everyone', 'was', 'sleeping', 'when', 'human', 'voices', 'and', 'neighing', 'horses', 'were', 'heard', 'within', 'the', 'village', '.'], ['O', 'B-TIME', 'I-TIME', 'I-TIME', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['People', 'all', 'got', 'up', '.'], ['O', 'O', 'O', 'O', 'O']), (['Did', 'something', 'happen', '?'], ['O', 'O', 'O', 'O']), (['Some', 'folks', 'got', 'up', '.'], ['O', 'O', 'O', 'O', 'O']), (['Opening', 'the', 'street', 'gate', ',', 'they', 'saw', 'a', 'soldier', 'standing', 'by', 'the', 'gate', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['Folks', ',', 'go', 'back', ',', 'go', 'back', ',', 'nothing', 'is', 'wrong', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['Our', 'troops', 'are', 'just', 'going', 'to', 'stay', 'here', 'for', 'the', 'night', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'])]\n",
      "NE types used for training:\n",
      "['PERSON']\n",
      "1 in total\n",
      "Num of train sentences: 12195\n",
      "Num of valid sentences: 1553\n",
      "Num of test sentences: 1573\n",
      "Number of sentences in filtered dataset: train: 12195, valid: 1553, test: 1573\n",
      "Tag counts:\n",
      "{'train': {'T': 26576, 'O': 271533}, 'valid': {'O': 34401, 'T': 3415}, 'test': {'O': 34672, 'T': 3400}}\n"
     ]
    }
   ],
   "source": [
    "dataset_orig = read_data()\n",
    "ne_types = ['PERSON']\n",
    "print('NE types used for training:')\n",
    "print(ne_types)\n",
    "print('{} in total'.format(len(ne_types)))\n",
    "dataset = filter_dataset_by_ne_types(dataset_orig, ne_types, tags2binary=not MULTICLASS, preserveBIO=USE_BIO_MARKUP, keepIfAny=True)\n",
    "print('Number of sentences in filtered dataset: train: {}, valid: {}, test: {}'.format(len(dataset['train']), len(dataset['valid']), len(dataset['test'])))\n",
    "tag_counts = count_tags(dataset)\n",
    "print('Tag counts:')\n",
    "print(tag_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 578,
     "status": "ok",
     "timestamp": 1535754891874,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "T74bOXjxPaAw",
    "outputId": "8b445d09-09ec-40db-aa2d-193270babf83"
   },
   "outputs": [],
   "source": [
    "# print(dataset['train'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support set:\n",
      "[(['Considering', 'that', 'Gao', 'fled', 'a', 'tyrannical', 'government', 'to', 'become', 'an', 'expatriate', ',', 'many', 'people', 'wonder', 'whether', 'Gao', \"'s\", 'literature', 'insists', 'upon', 'humanitarianism', 'and', 'high', 'principles', '.'], ['O', 'O', 'T', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'T', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['and', 'she', 'said', 'Alison', 'she', 'said', 'I', 'just', 'felt', 'real', 'strong', 'I', 'needed', 'to', 'call', 'and', 'tell', 'you', 'that', 'God', \"'s\", 'taking', 'you', 'to', 'your', 'promised', 'land'], ['O', 'O', 'O', 'T', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['Chiewpy', ',', 'France', \"'s\", 'Minister', 'of', 'Foreign', 'Affairs', ',', 'also', 'expressed', 'clearly', 'last', 'week', 'that', ',', '\"', 'the', 'prerequisites', 'for', '\"', 'lifting', 'the', 'embargo', '\"', 'are', 'that', 'France', 'withdraws', 'its', 'blue', 'helmet', 'troops', 'and', 'the', 'withdrawal', 'of', 'all', 'peacekeeping', 'forces', 'of', 'the', 'UN', '\"', '.'], ['T', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['Ken', 'Blackwell', 'Secretary', 'of', 'State', 'of', 'Ohio', 'and', 'US', 'congressman', 'Sherrod', 'Brown', 'of', 'Ohio', '/.'], ['T', 'T', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'T', 'T', 'O', 'O', 'O']), (['Mr.', 'Lorin', 'responded', ',', '``', 'No', '.', \"''\"], ['O', 'T', 'O', 'O', 'O', 'O', 'O', 'O']), (['Guo', 'Kai', \"'s\", 'Economics', 'Notes'], ['T', 'T', 'T', 'O', 'O']), (['Meanwhile', ',', 'a', 'federal', 'jury', 'found', 'Mr.', 'Bilzerian', 'guilty', 'on', 'securities', 'fraud', 'and', 'other', 'charges', 'in', 'June', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'T', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['``', 'I', 'would', \"n't\", 'say', 'it', \"'s\", 'quite', 'a', 'veto', ',', \"''\", 'Mr.', 'Boren', 'demurs', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'T', 'O', 'O']), (['My', 'regards', ',', 'brother', 'Al', 'Shaheen', '.'], ['O', 'O', 'O', 'O', 'T', 'T', 'O']), (['Then', ',', 'perhaps', ',', 'Mr.', 'Ovcharenko', \"'s\", 'ideas', 'would', \"n't\", 'sound', 'like', 'so', 'much', 'blarney', '.'], ['O', 'O', 'O', 'O', 'O', 'T', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'])]\n",
      "Valid set:\n",
      "[(['So', 'declares', 'Gennie', 'Yen', ',', 'the', 'director', 'of', 'the', 'ROC', 'Office', 'of', 'the', 'Palau', 'Visitors', 'Authority', '.'], ['O', 'O', 'T', 'T', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['Here', \"'s\", 'the', 'difference', 'between', 'Bush', 'and', 'Gore', 'when', 'it', 'comes', 'to', 'corporate', 'power', '.'], ['O', 'O', 'O', 'O', 'O', 'T', 'O', 'T', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['John', 'Scottsdale', 'is', 'on', 'the', 'front', 'lines', 'in', 'Iraq', '.'], ['T', 'T', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['Secretary', 'of', 'State', 'Baker', ',', 'in', 'his', 'first', 'major', 'arms', '-', 'control', 'speech', ',', 'called', 'for', 'a', 'new', 'military', 'relationship', 'with', 'Moscow', 'to', 'reduce', '``', 'first', 'strike', \"''\", 'nuclear', 'arms', '.'], ['O', 'O', 'O', 'T', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['-LSB-', 'Board', 'of', 'Supervisors', 'Chairman', 'Chris', '-RSB-', 'Zimmerman', 'and', 'others', 'speaking', 'yesterday', 'said', 'that', 'the', 'vounty', 'sees', 'the', 'empty', 'space', 'as', 'an', 'opportunity', 'to', '``', 'reimagine', \"''\", 'and', '``', 'brand', \"''\", 'Crystal', 'City', 'as', 'an', 'attractive', 'destination', '.'], ['O', 'O', 'O', 'O', 'O', 'T', 'T', 'T', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['In', 'implementing', 'the', 'orders', ',', 'Mansour', 'went', 'with', 'a', 'group', 'of', 'his', 'assistants', 'on', 'January', '13', ',', '2005', ',', 'two', 'days', 'before', 'the', 'celebration', ',', 'to', 'the', 'restaurant', ',', 'where', 'he', 'started', 'to', 'plant', 'an', 'explosive', 'package', 'containing', '15', 'kilograms', 'of', '\"', 'T.', 'N.', 'T.', '\"', 'substance', '.'], ['O', 'O', 'O', 'O', 'O', 'T', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['Jonathan', 'Aiken', 'reports', '.'], ['T', 'T', 'O', 'O']), (['According', 'to', 'a', 'detailed', 'report', 'by', 'Zbigniew', 'Bochniarz', 'of', 'the', 'University', 'of', 'Minnesota', \"'s\", 'Hubert', 'Humphrey', 'Institute', ',', '27', 'areas', 'containing', 'a', 'third', 'of', 'Poland', \"'s\", 'population', 'are', 'regarded', 'as', '``', 'ecological', 'hazards', \"''\", 'due', 'to', 'multiple', 'violations', 'of', 'standards', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'T', 'T', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['Mcfedden', 'has', 'created', 'models', 'aimed', 'at', 'figuring', 'out', 'how', 'people', 'make', 'life', \"'s\", 'big', 'choices', ',', 'like', 'when', 'to', 'get', 'married', 'and', 'how', 'many', 'children', 'to', 'have', '.'], ['T', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['We', 'will', 'witness', 'the', 'mechanisms', 'of', 'bargaining', 'after', 'the', 'arrival', 'of', 'the', 'well', '-', 'regarded', 'Rice', 'who', 'certainly', 'visited', 'the', 'occupying', 'entity', 'and', 'arranged', 'a', 'new', 'game', 'with', 'it', 'called', 'the', 'establishment', 'of', 'a', 'new', 'Palestinian', 'state', 'to', 'entice', 'us', 'to', 'support', 'it', 'materially', 'and', 'morally', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'T', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'])]\n"
     ]
    }
   ],
   "source": [
    "indices = np.random.choice(len(dataset['train']), size=N_EXAMPLES, replace=False)\n",
    "train_sen_count = floor(N_EXAMPLES/2)\n",
    "valid_sen_count = N_EXAMPLES - train_sen_count\n",
    "support_set = [dataset['train'][i] for i in indices[:train_sen_count]]\n",
    "valid_set = [dataset['train'][i] for i in indices[train_sen_count:]]\n",
    "print('Support set:')\n",
    "print(support_set)\n",
    "print('Valid set:')\n",
    "print(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 551,
     "status": "ok",
     "timestamp": 1535754892805,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "KkFrEV5kPaAz",
    "outputId": "103de6d6-d2ac-4f52-c3f9-fc5d76d8c336"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'PERSON': 1}\n",
      "['O', 'PERSON']\n"
     ]
    }
   ],
   "source": [
    "tag2idx = {}\n",
    "idx2tag = []\n",
    "tag2idx['O'] = 0\n",
    "idx2tag.append('O')\n",
    "i = 1\n",
    "for tag in ne_types:\n",
    "    if USE_BIO_MARKUP:\n",
    "        tag2idx['B-'+tag] = i\n",
    "        tag2idx['I-'+tag] = i+1\n",
    "        idx2tag.append('B-'+tag)\n",
    "        idx2tag.append('I-'+tag)\n",
    "        i += 2\n",
    "    else:\n",
    "        tag2idx[tag] = i\n",
    "        idx2tag.append(tag)\n",
    "        i += 1\n",
    "print(tag2idx)\n",
    "print(idx2tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZK3jHAGzPaA2"
   },
   "outputs": [],
   "source": [
    "from deeppavlov.core.common.check_gpu import GPU_AVAILABLE\n",
    "INITIALIZER = tf.contrib.layers.xavier_initializer\n",
    "\n",
    "def cudnn_lstm_wrapper(units, n_hidden, n_layers=1, trainable_initial_states=None, seq_lengths=None, initial_h=None,\n",
    "                       initial_c=None, name='cudnn_lstm', reuse=False):\n",
    "\n",
    "    if GPU_AVAILABLE:\n",
    "        return cudnn_lstm(units, n_hidden, n_layers, trainable_initial_states,\n",
    "                          seq_lengths, initial_h, initial_c, name, reuse)\n",
    "\n",
    "    log.info('\\nWarning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. '\n",
    "             'It is okay for inference mode, but '\n",
    "             'if you train your model with this cell it could NOT be used with '\n",
    "             'tf.contrib.cudnn_rnn.CudnnLSTMCell later. '\n",
    "             )\n",
    "\n",
    "    return cudnn_compatible_lstm(units, n_hidden, n_layers, trainable_initial_states,\n",
    "                                 seq_lengths, initial_h, initial_c, name, reuse)\n",
    "\n",
    "def cudnn_lstm(units, n_hidden, n_layers=1, trainable_initial_states=None, seq_lengths=None, initial_h=None,\n",
    "               initial_c=None, name='cudnn_lstm', reuse=False):\n",
    "    \"\"\" Fast CuDNN LSTM implementation\n",
    "\n",
    "        Args:\n",
    "            units: tf.Tensor with dimensions [B x T x F], where\n",
    "                B - batch size\n",
    "                T - number of tokens\n",
    "                F - features\n",
    "            n_hidden: dimensionality of hidden state\n",
    "            n_layers: number of layers\n",
    "            trainable_initial_states: whether to create a special trainable variable\n",
    "                to initialize the hidden states of the network or use just zeros\n",
    "            seq_lengths: tensor of sequence lengths with dimension [B]\n",
    "            initial_h: optional initial hidden state, masks trainable_initial_states\n",
    "                if provided\n",
    "            initial_c: optional initial cell state, masks trainable_initial_states\n",
    "                if provided\n",
    "            name: name of the variable scope to use\n",
    "            reuse:whether to reuse already initialized variable\n",
    "\n",
    "\n",
    "        Returns:\n",
    "            h - all hidden states along T dimension,\n",
    "                tf.Tensor with dimensionality [B x T x F]\n",
    "            h_last - last hidden state, tf.Tensor with dimensionality [B x (n_layers * H)]\n",
    "                where H - number of hidden units\n",
    "            c_last - last cell state, tf.Tensor with dimensionality [B x (n_layers * H)]\n",
    "                where H - number of hidden units\n",
    "        \"\"\"\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        lstm = tf.contrib.cudnn_rnn.CudnnLSTM(num_layers=n_layers,\n",
    "                                              num_units=n_hidden)\n",
    "        if trainable_initial_states:\n",
    "            init_h = tf.get_variable('init_h', [n_layers, 1, n_hidden])\n",
    "            init_h = tf.tile(init_h, (1, tf.shape(units)[0], 1))\n",
    "            init_c = tf.get_variable('init_c', [n_layers, 1, n_hidden])\n",
    "            init_c = tf.tile(init_c, (1, tf.shape(units)[0], 1))\n",
    "        else:\n",
    "            init_h = init_c = tf.zeros([n_layers, tf.shape(units)[0], n_hidden])\n",
    "\n",
    "        initial_h = initial_h or init_h\n",
    "        initial_c = initial_c or init_c\n",
    "\n",
    "        h, (h_last, c_last) = lstm(tf.transpose(units, (1, 0, 2)), (initial_h, initial_c))\n",
    "        h = tf.transpose(h, (1, 0, 2))\n",
    "        h_last = tf.reshape(h_last, shape=(-1, n_hidden))\n",
    "        c_last = tf.reshape(c_last, shape=(-1, n_hidden))\n",
    "\n",
    "        # Extract last states if they are provided\n",
    "        if seq_lengths is not None:\n",
    "            indices = tf.stack([tf.range(tf.shape(h)[0]), seq_lengths], axis=1)\n",
    "            h_last = tf.gather_nd(h, indices)\n",
    "\n",
    "        return h, (h_last, c_last)\n",
    "\n",
    "def cudnn_bi_lstm(units,\n",
    "                  n_hidden,\n",
    "                  seq_lengths=None,\n",
    "                  n_layers=1,\n",
    "                  trainable_initial_states=False,\n",
    "                  name='cudnn_bi_lstm',\n",
    "                  reuse=False):\n",
    "    \"\"\" Fast CuDNN Bi-LSTM implementation\n",
    "\n",
    "        Args:\n",
    "            units: tf.Tensor with dimensions [B x T x F], where\n",
    "                B - batch size\n",
    "                T - number of tokens\n",
    "                F - features\n",
    "            n_hidden: dimensionality of hidden state\n",
    "            seq_lengths: number of tokens in each sample in the batch\n",
    "            n_layers: number of layers\n",
    "            trainable_initial_states: whether to create a special trainable variable\n",
    "                to initialize the hidden states of the network or use just zeros\n",
    "            name: name of the variable scope to use\n",
    "            reuse:whether to reuse already initialized variable\n",
    "\n",
    "        Returns:\n",
    "            h - all hidden states along T dimension,\n",
    "                tf.Tensor with dimensionality [B x T x F]\n",
    "            h_last - last hidden state, tf.Tensor with dimensionality [B x H * 2]\n",
    "                where H - number of hidden units\n",
    "            c_last - last cell state, tf.Tensor with dimensionality [B x H * 2]\n",
    "                where H - number of hidden units\n",
    "        \"\"\"\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        if seq_lengths is None:\n",
    "            seq_lengths = tf.ones([tf.shape(units)[0]], dtype=tf.int32) * tf.shape(units)[1]\n",
    "        with tf.variable_scope('Forward'):\n",
    "            h_fw, (h_fw_last, c_fw_last) = cudnn_lstm_wrapper(units,\n",
    "                                                              n_hidden,\n",
    "                                                              n_layers=n_layers,\n",
    "                                                              trainable_initial_states=trainable_initial_states,\n",
    "                                                              seq_lengths=seq_lengths)\n",
    "\n",
    "        with tf.variable_scope('Backward'):\n",
    "            reversed_units = tf.reverse_sequence(units, seq_lengths=seq_lengths, seq_dim=1, batch_dim=0)\n",
    "            h_bw, (h_bw_last, c_bw_last) = cudnn_lstm_wrapper(reversed_units,\n",
    "                                                              n_hidden,\n",
    "                                                              n_layers=n_layers,\n",
    "                                                              trainable_initial_states=trainable_initial_states,\n",
    "                                                              seq_lengths=seq_lengths)\n",
    "\n",
    "            h_bw = tf.reverse_sequence(h_bw, seq_lengths=seq_lengths, seq_dim=1, batch_dim=0)\n",
    "        return (h_fw, h_bw), ((h_fw_last, c_fw_last), (h_bw_last, c_bw_last))\n",
    "\n",
    "def bi_rnn(units: tf.Tensor,\n",
    "           n_hidden: List,\n",
    "           cell_type='gru',\n",
    "           seq_lengths=None,\n",
    "           trainable_initial_states=False,\n",
    "           use_peepholes=False,\n",
    "           name='Bi-'):\n",
    "    \"\"\" Bi directional recurrent neural network. GRU or LSTM\n",
    "\n",
    "        Args:\n",
    "            units: a tensorflow tensor with dimensionality [None, n_tokens, n_features]\n",
    "            n_hidden_list: list with number of hidden units at the ouput of each layer\n",
    "            seq_lengths: length of sequences for different length sequences in batch\n",
    "                can be None for maximum length as a length for every sample in the batch\n",
    "            cell_type: 'lstm' or 'gru'\n",
    "            trainable_initial_states: whether to create a special trainable variable\n",
    "                to initialize the hidden states of the network or use just zeros\n",
    "            use_peepholes: whether to use peephole connections (only 'lstm' case affected)\n",
    "            name: what variable_scope to use for the network parameters\n",
    "            add_l2_losses: whether to add l2 losses on network kernels to\n",
    "                tf.GraphKeys.REGULARIZATION_LOSSES or not\n",
    "        Returns:\n",
    "            units: tensor at the output of the last recurrent layer\n",
    "                with dimensionality [None, n_tokens, n_hidden_list[-1]]\n",
    "            last_units: tensor of last hidden states for GRU and tuple\n",
    "                of last hidden stated and last cell states for LSTM\n",
    "                dimensionality of cell states and hidden states are\n",
    "                similar and equal to [B x 2 * H], where B - batch\n",
    "                size and H is number of hidden units\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.variable_scope(name + '_' + cell_type.upper()):\n",
    "        if cell_type == 'gru':\n",
    "            forward_cell = tf.nn.rnn_cell.GRUCell(n_hidden, kernel_initializer=INITIALIZER())\n",
    "            backward_cell = tf.nn.rnn_cell.GRUCell(n_hidden, kernel_initializer=INITIALIZER())\n",
    "            if trainable_initial_states:\n",
    "                initial_state_fw = tf.tile(tf.get_variable('init_fw_h', [1, n_hidden]), (tf.shape(units)[0], 1))\n",
    "                initial_state_bw = tf.tile(tf.get_variable('init_bw_h', [1, n_hidden]), (tf.shape(units)[0], 1))\n",
    "            else:\n",
    "                initial_state_fw = initial_state_bw = None\n",
    "        elif cell_type == 'lstm':\n",
    "            forward_cell = tf.nn.rnn_cell.LSTMCell(n_hidden, use_peepholes=use_peepholes, initializer=INITIALIZER())\n",
    "            backward_cell = tf.nn.rnn_cell.LSTMCell(n_hidden, use_peepholes=use_peepholes, initializer=INITIALIZER())\n",
    "            if trainable_initial_states:\n",
    "                initial_state_fw = tf.nn.rnn_cell.LSTMStateTuple(\n",
    "                    tf.tile(tf.get_variable('init_fw_c', [1, n_hidden]), (tf.shape(units)[0], 1)),\n",
    "                    tf.tile(tf.get_variable('init_fw_h', [1, n_hidden]), (tf.shape(units)[0], 1)))\n",
    "                initial_state_bw = tf.nn.rnn_cell.LSTMStateTuple(\n",
    "                    tf.tile(tf.get_variable('init_bw_c', [1, n_hidden]), (tf.shape(units)[0], 1)),\n",
    "                    tf.tile(tf.get_variable('init_bw_h', [1, n_hidden]), (tf.shape(units)[0], 1)))\n",
    "            else:\n",
    "                initial_state_fw = initial_state_bw = None\n",
    "        else:\n",
    "            raise RuntimeError('cell_type must be either \"gru\" or \"lstm\"s')\n",
    "        (rnn_output_fw, rnn_output_bw), (fw, bw) = \\\n",
    "            tf.nn.bidirectional_dynamic_rnn(forward_cell,\n",
    "                                            backward_cell,\n",
    "                                            units,\n",
    "                                            dtype=tf.float32,\n",
    "                                            sequence_length=seq_lengths,\n",
    "                                            initial_state_fw=initial_state_fw,\n",
    "                                            initial_state_bw=initial_state_bw)\n",
    "    kernels = [var for var in forward_cell.trainable_variables +\n",
    "               backward_cell.trainable_variables if 'kernel' in var.name]\n",
    "    for kernel in kernels:\n",
    "        tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, tf.nn.l2_loss(kernel))\n",
    "    return (rnn_output_fw, rnn_output_bw), (fw, bw)\n",
    "\n",
    "def build_cudnn_rnn(units, mask, n_hidden_list:Tuple[int]=(128,), cell_type:str='lstm', intra_layer_dropout:bool=False, dropout_ph=None):\n",
    "    sequence_lengths = tf.to_int32(tf.reduce_sum(mask, axis=1))\n",
    "    for n, n_hidden in enumerate(n_hidden_list):\n",
    "        with tf.variable_scope(cell_type.upper() + '_' + str(n)):\n",
    "            if cell_type.lower() == 'lstm':\n",
    "                units, _ = cudnn_bi_lstm(units, n_hidden, sequence_lengths)\n",
    "            elif cell_type.lower() == 'gru':\n",
    "                units, _ = cudnn_bi_gru(units, n_hidden, sequence_lengths)\n",
    "            else:\n",
    "                raise RuntimeError('Wrong cell type \"{}\"! Only \"gru\" and \"lstm\"!'.format(cell_type))\n",
    "            units = tf.concat(units, -1)\n",
    "            if intra_layer_dropout and n != len(n_hidden_list) - 1:\n",
    "                units = variational_dropout(units, dropout_ph)\n",
    "    return units\n",
    "\n",
    "def build_rnn(units, n_hidden_list:Tuple[int]=(128,), cell_type:str='lstm', intra_layer_dropout:bool=False, dropout_ph=None):\n",
    "    for n, n_hidden in enumerate(n_hidden_list):\n",
    "        units, _ = bi_rnn(units, n_hidden, cell_type=cell_type, name='Layer_' + str(n))\n",
    "        units = tf.concat(units, -1)\n",
    "        if intra_layer_dropout and n != len(n_hidden_list) - 1:\n",
    "            units = variational_dropout(units, dropout_ph)\n",
    "    return units\n",
    "\n",
    "def build_top(units, n_tags=18*2+1, top_dropout:bool=False, two_dense_on_top:bool=False, n_hidden=128):\n",
    "    if top_dropout:\n",
    "        units = variational_dropout(units, dropout_ph)\n",
    "    if two_dense_on_top:\n",
    "        units = tf.layers.dense(units, n_hidden, activation=tf.nn.relu,\n",
    "                                kernel_initializer=INITIALIZER(),\n",
    "                                kernel_regularizer=tf.nn.l2_loss)\n",
    "    logits = tf.layers.dense(units, n_tags, activation=None,\n",
    "                             kernel_initializer=INITIALIZER(),\n",
    "                             kernel_regularizer=tf.nn.l2_loss)\n",
    "    return logits\n",
    "\n",
    "def build_train_predict(logits, n_tags, mask, y_ph, use_crf, learning_rate_ph, clip_grad_norm, l2_reg):\n",
    "    res = {}\n",
    "    if use_crf:\n",
    "        sequence_lengths = tf.reduce_sum(mask, axis=1)\n",
    "        log_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood(logits, y_ph, sequence_lengths)\n",
    "        loss_tensor = -log_likelihood\n",
    "        res['transition_params'] = transition_params\n",
    "    else:\n",
    "        ground_truth_labels = tf.one_hot(y_ph, n_tags)\n",
    "        loss_tensor = tf.nn.softmax_cross_entropy_with_logits(labels=ground_truth_labels, logits=logits)\n",
    "        loss_tensor = loss_tensor * mask\n",
    "        y_pred = tf.argmax(logits, axis=-1)\n",
    "        res['y_pred'] = y_pred\n",
    "\n",
    "    loss = tf.reduce_mean(loss_tensor)\n",
    "\n",
    "    # L2 regularization\n",
    "    if l2_reg > 0:\n",
    "        loss += l2_reg * tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "    res['loss'] = loss\n",
    "        \n",
    "    # optimizer = partial(tf.train.MomentumOptimizer, momentum=0.9, use_nesterov=True)\n",
    "    optimizer = tf.train.AdamOptimizer\n",
    "    train_op = get_train_op(loss, learning_rate_ph, optimizer, clip_norm=clip_grad_norm)\n",
    "    res['train_op'] = train_op\n",
    "    return res\n",
    "\n",
    "def predict_no_crf(y_pred, mask_ph, feed_dict):\n",
    "    pred_idxs, mask = sess.run([y_pred, mask_ph], feed_dict)\n",
    "\n",
    "    # Filter by sequece length\n",
    "    sequence_lengths = np.sum(mask, axis=1).astype(np.int32)\n",
    "    pred = []\n",
    "    for utt, l in zip(pred_idxs, sequence_lengths):\n",
    "        pred.append(utt[:l])\n",
    "    return pred\n",
    "\n",
    "def predict_crf(logits, transition_params, mask_ph, feed_dict):\n",
    "    logits, trans_params, mask = sess.run([logits,\n",
    "                                           transition_params,\n",
    "                                           mask_ph],\n",
    "                                           feed_dict=feed_dict)\n",
    "    sequence_lengths = np.maximum(np.sum(mask, axis=1).astype(np.int32), 1)\n",
    "    # iterate over the sentences because no batching in viterbi_decode\n",
    "    pred = []\n",
    "    for logit, sequence_length in zip(logits, sequence_lengths):\n",
    "        logit = logit[:int(sequence_length)]  # keep only the valid steps\n",
    "        viterbi_seq, viterbi_score = tf.contrib.crf.viterbi_decode(logit, trans_params)\n",
    "        pred += [viterbi_seq]\n",
    "    return pred\n",
    "\n",
    "def get_train_op(loss,\n",
    "                 learning_rate,\n",
    "                 optimizer=None,\n",
    "                 clip_norm=None,\n",
    "                 learnable_scopes=None,\n",
    "                 optimizer_scope_name=None,\n",
    "                 trainable_vars:list=None):\n",
    "    \"\"\" Get train operation for given loss\n",
    "\n",
    "    Args:\n",
    "        loss: loss, tf tensor or scalar\n",
    "        learning_rate: scalar or placeholder\n",
    "        clip_norm: clip gradients norm by clip_norm\n",
    "        learnable_scopes: which scopes are trainable (None for all)\n",
    "        optimizer: instance of tf.train.Optimizer, default Adam\n",
    "\n",
    "    Returns:\n",
    "        train_op\n",
    "    \"\"\"\n",
    "    if optimizer_scope_name is None:\n",
    "        opt_scope = tf.variable_scope('Optimizer')\n",
    "    else:\n",
    "        opt_scope = tf.variable_scope(optimizer_scope_name)\n",
    "    with opt_scope:\n",
    "        if learnable_scopes is None:\n",
    "            variables_to_train = tf.global_variables()\n",
    "        else:\n",
    "            variables_to_train = []\n",
    "            for scope_name in learnable_scopes:\n",
    "                for var in tf.global_variables():\n",
    "                    if scope_name in var.name:\n",
    "                        variables_to_train.append(var)\n",
    "        if trainable_vars:\n",
    "            variables_to_train = trainable_vars\n",
    "            \n",
    "        if optimizer is None:\n",
    "            optimizer = tf.train.AdamOptimizer\n",
    "\n",
    "        # For batch norm it is necessary to update running averages\n",
    "        extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(extra_update_ops):\n",
    "            opt = optimizer(learning_rate)\n",
    "            grads_and_vars = opt.compute_gradients(loss, var_list=variables_to_train)\n",
    "            if clip_norm is not None:\n",
    "                grads_and_vars = [(tf.clip_by_norm(grad, clip_norm), var)\n",
    "                                  for grad, var in grads_and_vars] #  if grad is not None\n",
    "            train_op = opt.apply_gradients(grads_and_vars)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9cfEVVG1PaA4"
   },
   "outputs": [],
   "source": [
    "# def get_batch(dataset, batch_size=None, binaryTags=True, tag2idx=None):\n",
    "#     if not batch_size:\n",
    "#         batch_size = len(dataset)\n",
    "#     indices = np.arange(len(dataset))\n",
    "#     np.random.shuffle(indices)\n",
    "#     tokens_train, tags_train = split_tokens_tags([dataset[i] for i in indices[:batch_size]])\n",
    "#     mask_train = make_mask(tokens_train)\n",
    "#     tokens_train = add_padding(tokens_train)\n",
    "#     y_train = tagsEncodePadded(tags_train, binary=binaryTags, tag2idx=tag2idx)\n",
    "    \n",
    "#     tokens_valid, tags_valid = split_tokens_tags([dataset[i] for i in indices[batch_size:]])\n",
    "#     mask_valid = make_mask(tokens_valid)\n",
    "#     tokens_valid = add_padding(tokens_valid)\n",
    "#     y_valid = tagsEncodePadded(tags_valid, binary=binaryTags, tag2idx=tag2idx)\n",
    "    \n",
    "#     return ((tokens_train, tags_train, mask_train, y_train), (tokens_valid, tags_valid, mask_valid, y_valid))\n",
    "\n",
    "def get_batch(dataset, batch_size=None, binaryTags=True, tag2idx=None):\n",
    "    if not batch_size:\n",
    "        batch_size = len(dataset)\n",
    "    tokens, tags = get_data_sample(dataset, batch_size)\n",
    "    mask = make_mask(tokens)\n",
    "    tokens_length = get_tokens_len(tokens)\n",
    "    tokens = add_padding(tokens)\n",
    "    y = tagsEncodePadded(tags, binary=binaryTags, tag2idx=tag2idx)\n",
    "    return tokens, tags, mask, y\n",
    "\n",
    "def make_mask(seq_list):\n",
    "  seq_count = len(seq_list)\n",
    "  seq_length = [len(s) for s in seq_list]\n",
    "  max_len = np.max(seq_length)\n",
    "  mask = np.zeros((seq_count, max_len), dtype=int)\n",
    "  seq_length = np.tile(np.expand_dims(seq_length, axis=-1), (1, max_len))\n",
    "  range_ar = np.tile(np.arange(1, max_len+1, 1), (seq_count, 1))\n",
    "  mask[range_ar <= seq_length] = 1\n",
    "  return mask\n",
    "\n",
    "def flatten_with_mask(seq_mat, mask):\n",
    "  return seq_mat[mask == 1]\n",
    "\n",
    "def concatenate_arrays(ar_list):\n",
    "  return np.concatenate(ar_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bHZPI7b3PaA7"
   },
   "outputs": [],
   "source": [
    "class DatasetIterator:\n",
    "    def __init__(self, data):\n",
    "        self.data = {\n",
    "            'train': data['train'],\n",
    "            'valid': data['valid'],\n",
    "            'test': data['test']\n",
    "        }\n",
    "        \n",
    "    def get_samples_count(self, data_type='train'):\n",
    "        return len(self.data[data_type])\n",
    "\n",
    "    def gen_batches(self, batch_size, data_type='train', shuffle=True, binaryTags=False, tag2idx=None):\n",
    "        indices = np.arange(len(self.data[data_type]))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(indices)\n",
    "        n = indices.size\n",
    "        k = 0\n",
    "        while k < n:\n",
    "            top = k + batch_size\n",
    "            if top > n: \n",
    "                top = n\n",
    "            indices_batch = indices[k:top]\n",
    "            tokens,tags = split_tokens_tags([self.data[data_type][i] for i in indices_batch])\n",
    "            mask = make_mask(tokens)\n",
    "            tokens_length = get_tokens_len(tokens)\n",
    "            tokens = add_padding(tokens)\n",
    "            y = tagsEncodePadded(tags, binary=binaryTags, tag2idx=tag2idx)\n",
    "            yield tokens, tags, mask, y\n",
    "            k += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dataset(batch_generator, tag2idx, data_type='valid'):\n",
    "    pred_total = []\n",
    "    true_total = []\n",
    "    loss_valid_total = 0\n",
    "    for i, (tokens_valid, tags_valid, mask_valid, y_valid) in enumerate(batch_generator.gen_batches(32, data_type=data_type, shuffle=False, binaryTags=not MULTICLASS, tag2idx=tag2idx)):\n",
    "        feed_valid = fill_feed_dict({tokens_input_ph: tokens_valid, mask_ph: mask_valid, y_ph: y_valid, training_ph: False}, train=False)\n",
    "        y_valid_flat = flatten_with_mask(y_valid, mask_valid)\n",
    "        loss_valid = sess.run([loss], feed_dict=feed_valid)[0]\n",
    "        if use_crf:\n",
    "            pred = predict_crf(logits, transition_params, mask_ph, feed_dict=feed_valid)\n",
    "        else:\n",
    "            pred = predict_no_crf(y_pred, mask_ph, feed_dict=feed_valid)\n",
    "        pred = concatenate_arrays(pred)\n",
    "        loss_valid_total += loss_valid\n",
    "        pred_total = np.concatenate([pred_total, pred])\n",
    "        true_total = np.concatenate([true_total, y_valid_flat])\n",
    "    n_tags = len(tag2idx.keys())\n",
    "    f1_valid = f1_score(true_total, pred_total, average=None, labels=list(range(1,n_tags)))\n",
    "    loss_valid_total = loss_valid_total/(i+1)\n",
    "    \n",
    "    return {'loss': loss_valid_total, 'f1': f1_valid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dFG9BPwlPaA9"
   },
   "outputs": [],
   "source": [
    "def eval_valid(batch_generator, tag2idx):\n",
    "    pred_total = []\n",
    "    true_total = []\n",
    "    loss_valid_total = 0\n",
    "    for i, (tokens_valid, tags_valid, mask_valid, y_valid) in enumerate(batch_generator.gen_batches(32, data_type='valid', shuffle=False, binaryTags=False, tag2idx=tag2idx)):\n",
    "        feed_valid = fill_feed_dict({tokens_input_ph: tokens_valid, mask_ph: mask_valid, y_ph: y_valid, training_ph: False}, train=False)\n",
    "        y_valid_flat = flatten_with_mask(y_valid, mask_valid)\n",
    "        loss_valid = sess.run([loss], feed_dict=feed_valid)[0]\n",
    "        if use_crf:\n",
    "            pred = predict_crf(logits, transition_params, mask_ph, feed_dict=feed_valid)\n",
    "        else:\n",
    "            pred = predict_no_crf(y_pred, mask_ph, feed_dict=feed_valid)\n",
    "#         print('y_true: {}'.format(y_valid))\n",
    "#         print('y_pred: {}'.format(pred))\n",
    "        pred = concatenate_arrays(pred)\n",
    "        loss_valid_total += loss_valid\n",
    "        pred_total = np.concatenate([pred_total, pred])\n",
    "        true_total = np.concatenate([true_total, y_valid_flat])\n",
    "#     print(np.unique(true_total))\n",
    "#     print(np.unique(pred_total))\n",
    "#     print(true_total.size == pred_total.size)\n",
    "#     a = np.arange(true_total.size)\n",
    "#     print(a[true_total == 2])\n",
    "#     print(a[pred_total == 2])\n",
    "    n_tags = len(tag2idx.keys())\n",
    "    f1_valid = f1_score(true_total, pred_total, average=None, labels=list(range(1,n_tags)))\n",
    "#     print(f1_valid)\n",
    "    loss_valid_total = loss_valid_total/(i+1)\n",
    "    \n",
    "    return {'loss': loss_valid_total, 'f1': f1_valid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l2WmzRJuPaBB"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kiXGWeaSPaBD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-10 18:30:39.999 INFO in 'tensorflow'['tf_logging'] at line 159: Using /tmp/tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/1\", trainable=TRAIN_ELMO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 498,
     "status": "ok",
     "timestamp": 1535754900840,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "fIemR3FYPaBI",
    "outputId": "d1e86786-96ed-42c0-b74d-9d5c434f53be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(tf.trainable_variables())\n",
    "elmo_vars = []\n",
    "if TRAIN_ELMO:\n",
    "    elmo_coef = {'layer_coefficients': tf.trainable_variables()[-2], 'scaling': tf.trainable_variables()[-1]}\n",
    "    print(elmo_coef)\n",
    "    elmo_vars = tf.trainable_variables()\n",
    "    elmo_vars_coef = list(elmo_coef.values())\n",
    "    elmo_vars_cell_weights = [v for v in elmo_vars if v not in elmo_vars_coef]\n",
    "    vars_dict = {v.name:v for v in tf.trainable_variables()}\n",
    "if TRAIN_ALL_ELMO_PARAMS:\n",
    "    cell0_kernel = vars_dict['module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0']\n",
    "    cell1_kernel = vars_dict['module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9_1Gj9SCPaBK"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "use_cudnn_rnn = True\n",
    "l2_reg = 0\n",
    "n_hidden_list = (128,)\n",
    "cell_type = 'lstm'\n",
    "n_tags = len(idx2tag)\n",
    "use_crf = True\n",
    "clip_grad_norm = 5.0\n",
    "learning_rate = 1e-3\n",
    "lr_decay = 0.5\n",
    "lr_min = 1e-5\n",
    "dropout_keep_prob = 1\n",
    "batch_size = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RiD7H4jnPaBN"
   },
   "source": [
    "### Build computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d9Ja_jdYPaBN"
   },
   "outputs": [],
   "source": [
    "# Placeholders\n",
    "tokens_input_ph = tf.placeholder(shape=[None, None], dtype=tf.string)\n",
    "# tokens_length_ph = tf.placeholder(shape=[None], dtype=tf.int32)\n",
    "mask_ph = tf.placeholder(tf.float32, [None, None], name='Mask_ph')\n",
    "y_ph = tf.placeholder(shape=[None, None], dtype=tf.int32, name='y_ph')\n",
    "learning_rate_ph = tf.placeholder_with_default(learning_rate, shape=[], name='learning_rate')\n",
    "dropout_ph = tf.placeholder_with_default(dropout_keep_prob, shape=[], name='dropout')\n",
    "training_ph = tf.placeholder_with_default(False, shape=[], name='is_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PElhM3v9PaBQ"
   },
   "outputs": [],
   "source": [
    "def fill_feed_dict(inp: dict, train=True):\n",
    "    feed_dict = {learning_rate_ph: learning_rate, dropout_ph: dropout_keep_prob if train else 1.0, training_ph: train}\n",
    "    feed_dict.update(inp)\n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7763,
     "status": "ok",
     "timestamp": 1535754911225,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "2k__QsnjPaBU",
    "outputId": "c5837ecf-def7-4a1e-fb33-eae4a87e691d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-10 18:30:40.701 INFO in 'tensorflow'['tf_logging'] at line 115: Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-43f176f69ae1>:117: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-10 18:30:40.837 WARNING in 'tensorflow'['tf_logging'] at line 125: From <ipython-input-10-43f176f69ae1>:117: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/clement/virtenv/env/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:454: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-10 18:30:40.860 WARNING in 'tensorflow'['tf_logging'] at line 125: From /home/clement/virtenv/env/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:454: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n",
      "/home/clement/virtenv/env/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "y_pred = None\n",
    "transition_params = None\n",
    "tokens_length = tf.to_int32(tf.reduce_sum(mask_ph, axis=1))\n",
    "emb = elmo(inputs={\"tokens\": tokens_input_ph,\n",
    "                    \"sequence_len\": tokens_length},\n",
    "                  signature=\"tokens\",\n",
    "                  as_dict=True)['elmo']\n",
    "# mask = tf.sequence_mask(lengths=tokens_length_ph, dtype=tf.float32)\n",
    "features = emb\n",
    "if use_cudnn_rnn:\n",
    "    units = build_cudnn_rnn(features, mask_ph, n_hidden_list, cell_type)\n",
    "else:\n",
    "    units = build_rnn(features, n_hidden_list, cell_type)\n",
    "\n",
    "logits = build_top(units, n_tags=n_tags)\n",
    "\n",
    "out_dict = build_train_predict(logits, n_tags, mask_ph, y_ph, use_crf, learning_rate_ph, clip_grad_norm, l2_reg)\n",
    "train_op_all = out_dict['train_op']\n",
    "loss = out_dict['loss']\n",
    "if use_crf:\n",
    "    transition_params = out_dict['transition_params']\n",
    "else:\n",
    "    y_pred = out_dict['y_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1535754911923,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "Girz7LPfPaBZ",
    "outputId": "108a2794-fd9a-43e6-e6e9-9d75d3b5eb46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'LSTM_0/cudnn_bi_lstm/Forward/cudnn_lstm/cudnn_lstm/opaque_kernel:0' shape=<unknown> dtype=float32_ref>, <tf.Variable 'LSTM_0/cudnn_bi_lstm/Backward/cudnn_lstm/cudnn_lstm/opaque_kernel:0' shape=<unknown> dtype=float32_ref>, <tf.Variable 'dense/kernel:0' shape=(256, 2) dtype=float32_ref>, <tf.Variable 'dense/bias:0' shape=(2,) dtype=float32_ref>, <tf.Variable 'transitions:0' shape=(2, 2) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "all_vars = tf.trainable_variables()\n",
    "model_vars = [v for v in all_vars if v not in elmo_vars]\n",
    "print(model_vars)\n",
    "vars_dict = {v.name:v for v in tf.trainable_variables()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8061,
     "status": "ok",
     "timestamp": 1535754920250,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "nYhuNEucPaBe",
    "outputId": "81407e25-7cb5-4e47-bc96-8174ada4ee7b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clement/virtenv/env/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "# Optimizers for different parameters\n",
    "with tf.variable_scope('Optimizer', reuse=tf.AUTO_REUSE):\n",
    "    train_op_model = get_train_op(loss, learning_rate_ph, tf.train.AdamOptimizer, clip_norm=clip_grad_norm, trainable_vars=model_vars)\n",
    "    if TRAIN_ELMO:\n",
    "        train_op_elmo = get_train_op(loss, learning_rate_ph, tf.train.AdamOptimizer, clip_norm=clip_grad_norm, trainable_vars=elmo_vars)\n",
    "        train_op_elmo_coef = get_train_op(loss, learning_rate_ph, tf.train.AdamOptimizer, clip_norm=clip_grad_norm, trainable_vars=elmo_vars_coef)\n",
    "        train_op_elmo_cell_weights = get_train_op(loss, learning_rate_ph, tf.train.AdamOptimizer, clip_norm=clip_grad_norm, trainable_vars=elmo_vars_cell_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zC9DxF3EPaBk"
   },
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter('./graph/bilstm_crf_elmo_bio_multi', tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlqOMRZ_kVuf"
   },
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = tf.trainable_variables()\n",
    "vars_dict = {v.name: v for v in variables}\n",
    "saver = tf.train.Saver(vars_dict)\n",
    "MODEL_SAVE_PATH = \"./model_params/lstm_fewshot.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6190,
     "status": "ok",
     "timestamp": 1535754931375,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "7m5dO-N2PaBp",
    "outputId": "6ed6a02d-2b7b-4fd8-9d8e-8a1ce5f21aae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_op = tf.global_variables_initializer()\n",
    "sess.run([initialize_op])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oqnoc3KbPaBt"
   },
   "outputs": [],
   "source": [
    "dataset_iterator = DatasetIterator(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QNPK6IDSPaBv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Here', \"'s\", 'the', 'difference', 'between', 'Bush', 'and', 'Gore', 'when', 'it', 'comes', 'to', 'corporate', 'power', '.', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['According', 'to', 'a', 'detailed', 'report', 'by', 'Zbigniew', 'Bochniarz', 'of', 'the', 'University', 'of', 'Minnesota', \"'s\", 'Hubert', 'Humphrey', 'Institute', ',', '27', 'areas', 'containing', 'a', 'third', 'of', 'Poland', \"'s\", 'population', 'are', 'regarded', 'as', '``', 'ecological', 'hazards', \"''\", 'due', 'to', 'multiple', 'violations', 'of', 'standards', '.', '', '', '', '', '', '', ''], ['-LSB-', 'Board', 'of', 'Supervisors', 'Chairman', 'Chris', '-RSB-', 'Zimmerman', 'and', 'others', 'speaking', 'yesterday', 'said', 'that', 'the', 'vounty', 'sees', 'the', 'empty', 'space', 'as', 'an', 'opportunity', 'to', '``', 'reimagine', \"''\", 'and', '``', 'brand', \"''\", 'Crystal', 'City', 'as', 'an', 'attractive', 'destination', '.', '', '', '', '', '', '', '', '', '', ''], ['So', 'declares', 'Gennie', 'Yen', ',', 'the', 'director', 'of', 'the', 'ROC', 'Office', 'of', 'the', 'Palau', 'Visitors', 'Authority', '.', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['John', 'Scottsdale', 'is', 'on', 'the', 'front', 'lines', 'in', 'Iraq', '.', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['Secretary', 'of', 'State', 'Baker', ',', 'in', 'his', 'first', 'major', 'arms', '-', 'control', 'speech', ',', 'called', 'for', 'a', 'new', 'military', 'relationship', 'with', 'Moscow', 'to', 'reduce', '``', 'first', 'strike', \"''\", 'nuclear', 'arms', '.', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['We', 'will', 'witness', 'the', 'mechanisms', 'of', 'bargaining', 'after', 'the', 'arrival', 'of', 'the', 'well', '-', 'regarded', 'Rice', 'who', 'certainly', 'visited', 'the', 'occupying', 'entity', 'and', 'arranged', 'a', 'new', 'game', 'with', 'it', 'called', 'the', 'establishment', 'of', 'a', 'new', 'Palestinian', 'state', 'to', 'entice', 'us', 'to', 'support', 'it', 'materially', 'and', 'morally', '.', ''], ['Mcfedden', 'has', 'created', 'models', 'aimed', 'at', 'figuring', 'out', 'how', 'people', 'make', 'life', \"'s\", 'big', 'choices', ',', 'like', 'when', 'to', 'get', 'married', 'and', 'how', 'many', 'children', 'to', 'have', '.', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['In', 'implementing', 'the', 'orders', ',', 'Mansour', 'went', 'with', 'a', 'group', 'of', 'his', 'assistants', 'on', 'January', '13', ',', '2005', ',', 'two', 'days', 'before', 'the', 'celebration', ',', 'to', 'the', 'restaurant', ',', 'where', 'he', 'started', 'to', 'plant', 'an', 'explosive', 'package', 'containing', '15', 'kilograms', 'of', '\"', 'T.', 'N.', 'T.', '\"', 'substance', '.'], ['Jonathan', 'Aiken', 'reports', '.', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']]\n",
      "[['O', 'O', 'O', 'O', 'O', 'T', 'O', 'T', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'T', 'T', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'T', 'T', 'T', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'T', 'T', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['T', 'T', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'T', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'T', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['T', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'T', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['T', 'T', 'O', 'O']]\n"
     ]
    }
   ],
   "source": [
    "tokens_valid, tags_valid, mask_valid, y_valid = get_batch(valid_set, None, binaryTags=not MULTICLASS, tag2idx=tag2idx)\n",
    "feed_valid = fill_feed_dict({tokens_input_ph: tokens_valid, mask_ph: mask_valid, y_ph: y_valid, training_ph: False}, train=False)\n",
    "y_valid_flat = flatten_with_mask(y_valid, mask_valid)\n",
    "print(tokens_valid)\n",
    "print(tags_valid)\n",
    "print(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vs3vYbzrPaBy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0, 'PERSON': 1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9dOdH8vdPaB8"
   },
   "outputs": [],
   "source": [
    "training_schedule = [{'train_op': train_op_model, 'n_steps': 100, 'lr': 1e-3}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saving path: ./model_params/lstm_fewshot.ckpt\n",
      "Step 1/100\n",
      "Model saved.\n",
      "Train loss = 25.65250587463379\n",
      "Valid loss = 24.66534996032715\n",
      "Valid F1 score = 0.11486486486486486\n",
      "Step 2/100\n",
      "Step 3/100\n",
      "Step 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clement/virtenv/env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5/100\n",
      "Train loss = 4.470335960388184\n",
      "Step 6/100\n",
      "Step 7/100\n",
      "Step 8/100\n",
      "Model saved.\n",
      "Step 9/100\n",
      "Model saved.\n",
      "Step 10/100\n",
      "Model saved.\n",
      "Train loss = 1.4181360006332397\n",
      "Valid loss = 3.3976149559020996\n",
      "Valid F1 score = 0.7058823529411765\n",
      "Step 11/100\n",
      "Model saved.\n",
      "Step 12/100\n",
      "Step 13/100\n",
      "Step 14/100\n",
      "Step 15/100\n",
      "Train loss = 0.6080315709114075\n",
      "Step 16/100\n",
      "Running out of patience\n",
      "New learning rate: 0.0005\n",
      "Restoring best model ...\n",
      "INFO:tensorflow:Restoring parameters from ./model_params/lstm_fewshot.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-10 18:30:58.467 INFO in 'tensorflow'['tf_logging'] at line 115: Restoring parameters from ./model_params/lstm_fewshot.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17/100\n",
      "Step 18/100\n",
      "Step 19/100\n",
      "Step 20/100\n",
      "Train loss = 1.0069618225097656\n",
      "Valid loss = 2.565377712249756\n",
      "Valid F1 score = 0.7428571428571428\n",
      "Step 21/100\n",
      "Model saved.\n",
      "Step 22/100\n",
      "Step 23/100\n",
      "Step 24/100\n",
      "Step 25/100\n",
      "Train loss = 0.28436151146888733\n",
      "Step 26/100\n",
      "Step 27/100\n",
      "Step 28/100\n",
      "Running out of patience\n",
      "New learning rate: 0.00025\n",
      "Restoring best model ...\n",
      "INFO:tensorflow:Restoring parameters from ./model_params/lstm_fewshot.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-10 18:31:03.407 INFO in 'tensorflow'['tf_logging'] at line 115: Restoring parameters from ./model_params/lstm_fewshot.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 29/100\n",
      "Model saved.\n",
      "Step 30/100\n",
      "Train loss = 0.49649491906166077\n",
      "Valid loss = 2.3288092613220215\n",
      "Valid F1 score = 0.7407407407407407\n",
      "Step 31/100\n",
      "Step 32/100\n",
      "Step 33/100\n",
      "Step 34/100\n",
      "Step 35/100\n",
      "Train loss = 0.40121904015541077\n",
      "Step 36/100\n",
      "Step 37/100\n",
      "Step 38/100\n",
      "Step 39/100\n",
      "Step 40/100\n",
      "Running out of patience\n",
      "New learning rate: 0.000125\n",
      "Restoring best model ...\n",
      "INFO:tensorflow:Restoring parameters from ./model_params/lstm_fewshot.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-10 18:31:08.766 INFO in 'tensorflow'['tf_logging'] at line 115: Restoring parameters from ./model_params/lstm_fewshot.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss = 0.6032584309577942\n",
      "Valid loss = 2.010068416595459\n",
      "Valid F1 score = 0.7407407407407407\n",
      "Step 41/100\n",
      "Step 42/100\n",
      "Step 43/100\n",
      "Step 44/100\n",
      "Step 45/100\n",
      "Train loss = 0.38099098205566406\n",
      "Step 46/100\n",
      "Step 47/100\n",
      "Step 48/100\n",
      "Step 49/100\n",
      "Step 50/100\n",
      "Train loss = 0.3883148729801178\n",
      "Valid loss = 2.187182903289795\n",
      "Valid F1 score = 0.7407407407407407\n",
      "Step 51/100\n",
      "Running out of patience\n",
      "New learning rate: 6.25e-05\n",
      "Restoring best model ...\n",
      "INFO:tensorflow:Restoring parameters from ./model_params/lstm_fewshot.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-10 18:31:13.488 INFO in 'tensorflow'['tf_logging'] at line 115: Restoring parameters from ./model_params/lstm_fewshot.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 52/100\n",
      "Step 53/100\n",
      "Step 54/100\n",
      "Step 55/100\n",
      "Train loss = 0.4715353548526764\n",
      "Step 56/100\n",
      "Step 57/100\n",
      "Step 58/100\n",
      "Step 59/100\n",
      "Step 60/100\n",
      "Train loss = 0.6947228312492371\n",
      "Valid loss = 2.2722971439361572\n",
      "Valid F1 score = 0.7407407407407407\n",
      "Step 61/100\n",
      "Step 62/100\n",
      "Running out of patience\n",
      "New learning rate: 3.125e-05\n",
      "Restoring best model ...\n",
      "INFO:tensorflow:Restoring parameters from ./model_params/lstm_fewshot.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-10 18:31:18.352 INFO in 'tensorflow'['tf_logging'] at line 115: Restoring parameters from ./model_params/lstm_fewshot.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 63/100\n",
      "Step 64/100\n",
      "Step 65/100\n",
      "Train loss = 0.7419493794441223\n",
      "Step 66/100\n",
      "Step 67/100\n",
      "Step 68/100\n",
      "Step 69/100\n",
      "Step 70/100\n",
      "Train loss = 0.6391718983650208\n",
      "Valid loss = 2.3220596313476562\n",
      "Valid F1 score = 0.7407407407407407\n",
      "Step 71/100\n",
      "Step 72/100\n",
      "Step 73/100\n",
      "Running out of patience\n",
      "New learning rate: 1.5625e-05\n",
      "Restoring best model ...\n",
      "INFO:tensorflow:Restoring parameters from ./model_params/lstm_fewshot.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-10 18:31:23.903 INFO in 'tensorflow'['tf_logging'] at line 115: Restoring parameters from ./model_params/lstm_fewshot.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 74/100\n",
      "Step 75/100\n",
      "Train loss = 0.5274060368537903\n",
      "Step 76/100\n",
      "Step 77/100\n",
      "Step 78/100\n",
      "Step 79/100\n",
      "Step 80/100\n",
      "Train loss = 0.3956778943538666\n",
      "Valid loss = 2.352055072784424\n",
      "Valid F1 score = 0.7407407407407407\n",
      "Step 81/100\n",
      "Step 82/100\n",
      "Step 83/100\n",
      "Step 84/100\n",
      "Running out of patience\n",
      "New learning rate: 7.8125e-06\n",
      "Learning rate below limit. Stop training.\n"
     ]
    }
   ],
   "source": [
    "num_steps = 100\n",
    "patience_limit = 10\n",
    "patience = 0\n",
    "num_steps = np.sum([s['n_steps'] for s in training_schedule])\n",
    "stage = 0\n",
    "n_steps_prev_stages = 0\n",
    "display_step = 5\n",
    "valid_step = 10\n",
    "losses = {'train': [], 'valid': []}\n",
    "f1_scores = {'train': [], 'valid': []}\n",
    "best_valid_f1 = 0\n",
    "d_elmo_cells_list = {'cell0':[], 'cell1':[]}\n",
    "learning_rate = training_schedule[stage]['lr']\n",
    "train_op = training_schedule[stage]['train_op']\n",
    "print('Model saving path: {}'.format(MODEL_SAVE_PATH))\n",
    "for step in range(1, num_steps+1):\n",
    "    print('Step {}/{}'.format(step, num_steps))\n",
    "    if step > n_steps_prev_stages + training_schedule[stage]['n_steps']:\n",
    "        print('Moving to the next stage')\n",
    "        n_steps_prev_stages += training_schedule[stage]['n_steps']\n",
    "        stage += 1\n",
    "        learning_rate = training_schedule[stage]['lr']\n",
    "        train_op = training_schedule[stage]['train_op']\n",
    "    tokens_batch, tags_batch, mask_batch, y_batch = get_batch(support_set, batch_size)\n",
    "    feed = fill_feed_dict({tokens_input_ph: tokens_batch, mask_ph: mask_batch, y_ph: y_batch, learning_rate_ph: learning_rate})\n",
    "    if TRAIN_ALL_ELMO_PARAMS:\n",
    "        cell0_kernel_val1 = cell0_kernel.eval(session=sess)\n",
    "        cell1_kernel_val1 = cell1_kernel.eval(session=sess)\n",
    "    # Train\n",
    "    with tf.variable_scope('', reuse=tf.AUTO_REUSE):\n",
    "        loss_cur, _ = sess.run([loss, train_op], feed_dict=feed)\n",
    "    losses['train'].append(loss_cur)\n",
    "    if TRAIN_ALL_ELMO_PARAMS:\n",
    "        cell0_kernel_val2 = cell0_kernel.eval(session=sess)\n",
    "        cell1_kernel_val2 = cell1_kernel.eval(session=sess)\n",
    "        d_cell0_kernel = np.linalg.norm(cell0_kernel_val2 - cell0_kernel_val1)/np.linalg.norm(cell0_kernel_val1)\n",
    "        d_cell1_kernel = np.linalg.norm(cell1_kernel_val2 - cell1_kernel_val1)/np.linalg.norm(cell1_kernel_val1)\n",
    "        d_elmo_cells_list['cell0'].append(d_cell0_kernel)\n",
    "        d_elmo_cells_list['cell1'].append(d_cell1_kernel)\n",
    "    # Validate\n",
    "    with tf.variable_scope('', reuse=tf.AUTO_REUSE):\n",
    "        loss_valid = sess.run([loss], feed_dict=feed_valid)[0]\n",
    "        losses['valid'].append(loss_valid)\n",
    "        if use_crf:\n",
    "            pred = predict_crf(logits, transition_params, mask_ph, feed_dict=feed_valid)\n",
    "        else:\n",
    "            pred = predict_no_crf(y_pred, mask_ph, feed_dict=feed_valid)\n",
    "        f1_valid = f1_score(flatten_with_mask(y_valid, mask_valid), concatenate_arrays(pred))\n",
    "#         res = eval_dataset(dataset_iterator, tag2idx, data_type='valid')\n",
    "#         f1_valid = res['f1']\n",
    "#         loss_valid = res['loss']\n",
    "        if isinstance(f1_valid, list) or isinstance(f1_valid, np.ndarray):\n",
    "            f1_valid = np.mean(f1_valid)\n",
    "        f1_scores['valid'].append(f1_valid)\n",
    "        if f1_valid > best_valid_f1:\n",
    "            best_valid_f1 = f1_valid\n",
    "            save_path = saver.save(sess, MODEL_SAVE_PATH)\n",
    "            print(\"Model saved.\")\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience > patience_limit:\n",
    "                print('Running out of patience')\n",
    "                patience = 0\n",
    "                learning_rate *= lr_decay\n",
    "                print('New learning rate: {}'.format(learning_rate))\n",
    "                if learning_rate < lr_min:\n",
    "                    print('Learning rate below limit. Stop training.')\n",
    "                    break\n",
    "                print('Restoring best model ...')\n",
    "                saver.restore(sess, MODEL_SAVE_PATH)\n",
    "    # Get elmo params\n",
    "    with tf.variable_scope('', reuse=tf.AUTO_REUSE):\n",
    "        if TRAIN_ELMO:\n",
    "            layer_coeff, scale = sess.run([elmo_coef['layer_coefficients'], elmo_coef['scaling']])\n",
    "            if f1_valid == best_valid_f1:\n",
    "                elmo_params_best = {'layer_coefficients': layer_coeff, 'scaling': scale}\n",
    "    if step % display_step == 0 or step == 1:\n",
    "        print('Train loss = {}'.format(losses['train'][-1]))\n",
    "        if TRAIN_ELMO:\n",
    "            with tf.variable_scope('', reuse=tf.AUTO_REUSE):\n",
    "                print('ELMo weights:')\n",
    "                print('Coefficients = {}, scale = {}'.format(layer_coeff, scale))\n",
    "        if TRAIN_ALL_ELMO_PARAMS:\n",
    "            print('ELMo cells change per step: cell0: {:.2f}%, cell1: {:.2f}%'.format(d_cell0_kernel*100, d_cell1_kernel*100))\n",
    "        \n",
    "    if step % valid_step == 0 or step == 1:\n",
    "        print('Valid loss = {}'.format(losses['valid'][-1]))\n",
    "        print('Valid F1 score = {}'.format(f1_scores['valid'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 857,
     "status": "ok",
     "timestamp": 1535712912900,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "szSGnmYdPaCA",
    "outputId": "e617cf0e-be52-4528-bc36-f3e420d48e23"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-10 18:31:29.386 DEBUG in 'matplotlib.font_manager'['font_manager'] at line 1346: findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/clement/virtenv/env/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000\n",
      "2018-09-10 18:31:29.429 DEBUG in 'matplotlib.font_manager'['font_manager'] at line 1346: findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/home/clement/virtenv/env/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curve\n",
    "num_steps = len(losses['train'])\n",
    "plt.figure()\n",
    "steps = np.arange(1, num_steps+1, 1)\n",
    "plt.plot(steps, losses['train'], c='b', label='train')\n",
    "plt.plot(steps, losses['valid'], c='r', label='valid')\n",
    "plt.xlabel('iter')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.title('Learning curve')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 893,
     "status": "ok",
     "timestamp": 1535712913958,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "JzWORmJ3PaCE",
    "outputId": "961e64ce-5dc4-4977-c189-c3341ca5334e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot F1 scores\n",
    "plt.figure()\n",
    "steps = np.arange(1, num_steps+1, 1)\n",
    "# plt.plot(steps, losses['train'], c='b', label='train')\n",
    "plt.plot(steps, f1_scores['valid'], c='r', label='valid')\n",
    "plt.xlabel('iter')\n",
    "plt.ylabel('F1')\n",
    "plt.legend()\n",
    "plt.title('F1 score history')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6c6697CIGySa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score on validation: 86.67\n"
     ]
    }
   ],
   "source": [
    "print('Best F1 score on validation: {:.2f}'.format(best_valid_f1*100))\n",
    "if TRAIN_ELMO:\n",
    "    layer_coeff, scale = sess.run([elmo_coef['layer_coefficients'], elmo_coef['scaling']])\n",
    "    elmo_params = {'layer_coefficients': layer_coeff, 'scaling': scale}\n",
    "    elmo_layer_coeff = np.exp(elmo_params['layer_coefficients'])*elmo_params['scaling']\n",
    "    print('Learned ELMo layer combination weights:')\n",
    "    print(elmo_layer_coeff)\n",
    "    print('Normalized:')\n",
    "    print(np.exp(elmo_layer_coeff)/np.sum(np.exp(elmo_layer_coeff)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2v8VTscyPaCH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_params/lstm_fewshot.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-10 18:31:29.612 INFO in 'tensorflow'['tf_logging'] at line 115: Restoring parameters from ./model_params/lstm_fewshot.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver.restore(sess, MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss = 2.6316\n",
      "Test F1 score = 70.07\n"
     ]
    }
   ],
   "source": [
    "res = eval_dataset(dataset_iterator, tag2idx, data_type='test')\n",
    "f1_test = res['f1'][0]\n",
    "loss_test = res['loss']\n",
    "print('Test loss = {:.4f}'.format(loss_test))\n",
    "print('Test F1 score = {:.2f}'.format(f1_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "17. Finetune ELMo BIO-markup multiclass task.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
