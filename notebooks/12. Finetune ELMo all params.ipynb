{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TGMe-jsfltAb"
   },
   "outputs": [],
   "source": [
    "# For google colab\n",
    "# ! pip install deeppavlov\n",
    "# ! pip install pybind11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZAO73sarkVsk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-30 12:55:29.278 DEBUG in 'matplotlib.backends'['__init__'] at line 90: backend module://ipykernel.pylab.backend_inline version unknown\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from typing import *\n",
    "import copy\n",
    "from deeppavlov.dataset_readers.ontonotes_reader import OntonotesReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vp1-KZjakVs_"
   },
   "outputs": [],
   "source": [
    "TRAIN_ELMO = True\n",
    "TRAIN_ALL_ELMO_PARAMS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B-LqcN-EkVtF"
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    reader = OntonotesReader()\n",
    "    dataset = reader.read(data_path='data/')\n",
    "    # print(dataset.keys())\n",
    "    print('Num of train sentences: {}'.format(len(dataset['train'])))\n",
    "    print('Num of valid sentences: {}'.format(len(dataset['valid'])))\n",
    "    print('Num of test sentences: {}'.format(len(dataset['test'])))\n",
    "    print(dataset['train'][50:60])\n",
    "    return dataset\n",
    "\n",
    "def filter_data_by_ne_type(data:list, ne_types:list, tags2binary=False, preserveBIO=False, keepIfAny=True):\n",
    "    if ne_types == None or len(ne_types) == 0:\n",
    "        return data\n",
    "    data_filtered = []\n",
    "    for tokens,tags in data:\n",
    "        contains_all = True\n",
    "        contains_any = False\n",
    "        tags_norm = [getNeTagMainPart(t) for t in tags]\n",
    "        for ne_type in ne_types:\n",
    "            if not ne_type in tags_norm:\n",
    "                contains_all = False\n",
    "            if ne_type in tags_norm:\n",
    "                contains_any = True\n",
    "        if contains_all or (keepIfAny and contains_any):\n",
    "            if tags2binary:\n",
    "                if preserveBIO:\n",
    "                    tags = [tags[i][:2]+'T' if t in ne_types else 'O' for i,t in enumerate(tags_norm)]\n",
    "                else:\n",
    "                    tags = ['T' if t in ne_types else 'O' for t in tags_norm]\n",
    "            data_filtered.append((tokens,tags))\n",
    "    return data_filtered\n",
    "\n",
    "def filter_dataset_by_ne_types(dataset: list, ne_types, preserveBIO=False, keepIfAny=True):\n",
    "    dataset = copy.deepcopy(dataset)\n",
    "    if not isinstance(ne_types, list):\n",
    "        ne_types = [ne_types]\n",
    "    for dataset_type in ['train', 'valid', 'test']:\n",
    "        dataset[dataset_type] = filter_data_by_ne_type(dataset[dataset_type], ne_types, preserveBIO=preserveBIO, tags2binary=True)\n",
    "        print('Num of {} sentences: {}'.format(dataset_type, len(dataset[dataset_type])))\n",
    "    return dataset\n",
    "\n",
    "def get_data_sample(data, n_samples: int):\n",
    "    indices = np.random.choice(len(data), size=n_samples, replace=False)\n",
    "    return split_tokens_tags([data[i] for i in indices])\n",
    "\n",
    "def get_tokens_len(tokens):\n",
    "    if isinstance(tokens[0], str):\n",
    "        tokens = [tokens]\n",
    "    return [len(seq) for seq in tokens]\n",
    "\n",
    "def to_lower_case(tokens:list):\n",
    "    tokens_lower = []\n",
    "    for seq in tokens:\n",
    "        tokens_lower.append([])\n",
    "        for token in seq:\n",
    "            tokens_lower[-1].append(token.lower())\n",
    "    return tokens_lower\n",
    "\n",
    "def add_padding(tokens:list):\n",
    "    if isinstance(tokens[0], str):\n",
    "        return tokens, len(tokens)\n",
    "    elif isinstance(tokens[0], list):\n",
    "        tokens = copy.deepcopy(tokens)\n",
    "        max_len = 0\n",
    "        for seq in tokens:\n",
    "            if len(seq) > max_len:\n",
    "                max_len = len(seq)\n",
    "        for seq in tokens:\n",
    "            i = len(seq)\n",
    "            while i < max_len:\n",
    "                seq.append('')\n",
    "                i += 1\n",
    "        return tokens\n",
    "    else:\n",
    "        raise Exception('tokens should be either list of strings or list of lists of strings')\n",
    "  \n",
    "def getNeTagMainPart(tag:str):\n",
    "    return tag[2:] if tag != 'O' else tag\n",
    "\n",
    "def tags2binaryFlat(tags):\n",
    "    return np.array([1 if t == 'T' or (len(t) > 2 and t[2:] == 'T') else 0 for seq in tags for t in seq])\n",
    "\n",
    "def tags2binaryPadded(tags:list):\n",
    "    if isinstance(tags[0], str):\n",
    "        tags = [tags]\n",
    "    n_sentences = len(tags)\n",
    "    tokens_length = get_tokens_len(tags)\n",
    "    max_len = np.max(tokens_length)\n",
    "    tokens_length = np.tile(np.expand_dims(tokens_length, -1), (1,max_len))\n",
    "    y = np.zeros((n_sentences, max_len))\n",
    "    range_ar = np.tile(np.arange(1, max_len+1, 1), (n_sentences, 1))\n",
    "    for i, sen in enumerate(tags):\n",
    "        for j, tag in enumerate(sen):\n",
    "            if tags[i][j] != 'O':\n",
    "                y[i][j] = 1\n",
    "#     y[range_ar > tokens_length] = -1\n",
    "    return y\n",
    "\n",
    "def get_matrices(tokens, tags, embedder):\n",
    "    return (embeddings2feat_mat(embedder.embed(tokens), get_tokens_len(tokens)),\n",
    "           tags2binaryFlat(tags))\n",
    "  \n",
    "def split_tokens_tags(dataset: list):\n",
    "    tokens = []\n",
    "    tags = []\n",
    "    for sample in dataset:\n",
    "        tokens.append(sample[0])\n",
    "        tags.append(sample[1])\n",
    "    return tokens, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8745,
     "status": "ok",
     "timestamp": 1535541037250,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "n-ETiotSkVtL",
    "outputId": "865651e8-15df-49d5-f6f6-a4aadb87e405"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of train sentences: 75187\n",
      "Num of valid sentences: 9603\n",
      "Num of test sentences: 9479\n",
      "[(['Actions', 'had', 'to', 'be', 'taken', 'to', 'break', 'through', 'the', 'blockade', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['On', 'a', 'night', 'in', 'late', 'July', '1940', ',', 'the', 'atmosphere', 'in', 'Zhuanbi', 'Village', 'in', 'Shaanxi', 'was', 'unusual', '.'], ['O', 'B-DATE', 'I-DATE', 'I-DATE', 'I-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'B-GPE', 'O', 'O', 'O']), (['Villager', 'Xiao', 'Jianghe', 'has', 'a', 'vivid', 'memory', 'of', 'this', 'piece', 'of', 'history', '.'], ['O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['On', 'that', 'dark', 'night', ',', 'everyone', 'was', 'sleeping', 'when', 'human', 'voices', 'and', 'neighing', 'horses', 'were', 'heard', 'within', 'the', 'village', '.'], ['O', 'B-TIME', 'I-TIME', 'I-TIME', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['People', 'all', 'got', 'up', '.'], ['O', 'O', 'O', 'O', 'O']), (['Did', 'something', 'happen', '?'], ['O', 'O', 'O', 'O']), (['Some', 'folks', 'got', 'up', '.'], ['O', 'O', 'O', 'O', 'O']), (['Opening', 'the', 'street', 'gate', ',', 'they', 'saw', 'a', 'soldier', 'standing', 'by', 'the', 'gate', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['Folks', ',', 'go', 'back', ',', 'go', 'back', ',', 'nothing', 'is', 'wrong', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['Our', 'troops', 'are', 'just', 'going', 'to', 'stay', 'here', 'for', 'the', 'night', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'])]\n",
      "Num of train sentences: 28872\n",
      "Num of valid sentences: 3975\n",
      "Num of test sentences: 4026\n",
      "Number of sentences in filtered dataset: train: 28872, valid: 3975, test: 4026\n"
     ]
    }
   ],
   "source": [
    "dataset_orig = read_data()\n",
    "# ne_type = 'PERSON'\n",
    "# ne_types = ['GPE','DATE','ORG','EVENT','LOC','FAC','CARDINAL','QUANTITY','NORP','ORDINAL','WORK_OF_ART']\n",
    "ne_types = ['GPE','DATE','ORG','EVENT','LOC','FAC','CARDINAL','QUANTITY','NORP','ORDINAL','WORK_OF_ART', 'LANGUAGE', 'TIME', 'PRODUCT', 'MONEY', 'LAW', 'PERCENT']\n",
    "# dataset = {'train':[], 'valid':[], 'test':[]}\n",
    "# for ne_type in ne_types:\n",
    "#     print(ne_type)\n",
    "#     dataset_cur = filter_dataset_by_ne_types(dataset_orig, ne_type)\n",
    "#     for k in dataset.keys():\n",
    "#         dataset[k].extend(dataset_cur[k])\n",
    "dataset = filter_dataset_by_ne_types(dataset_orig, ne_types, keepIfAny=True)\n",
    "print('Number of sentences in filtered dataset: train: {}, valid: {}, test: {}'.format(len(dataset['train']), len(dataset['valid']), len(dataset['test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oVxkRgklET_Z"
   },
   "outputs": [],
   "source": [
    "# dataset_zipped = [list(zip(tokens, tags)) for tokens,tags in dataset['train']]\n",
    "# for sent in dataset_zipped:\n",
    "#   for token, tag in sent:\n",
    "#     print('{}\\t{}'.format(token, tag))\n",
    "#   print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GpR6E_l8kVtW"
   },
   "outputs": [],
   "source": [
    "INITIALIZER = tf.contrib.layers.xavier_initializer\n",
    "\n",
    "def bi_rnn(units: tf.Tensor,\n",
    "           n_hidden: List,\n",
    "           cell_type='gru',\n",
    "           seq_lengths=None,\n",
    "           trainable_initial_states=False,\n",
    "           use_peepholes=False,\n",
    "           name='Bi-'):\n",
    "    \"\"\" Bi directional recurrent neural network. GRU or LSTM\n",
    "\n",
    "        Args:\n",
    "            units: a tensorflow tensor with dimensionality [None, n_tokens, n_features]\n",
    "            n_hidden_list: list with number of hidden units at the ouput of each layer\n",
    "            seq_lengths: length of sequences for different length sequences in batch\n",
    "                can be None for maximum length as a length for every sample in the batch\n",
    "            cell_type: 'lstm' or 'gru'\n",
    "            trainable_initial_states: whether to create a special trainable variable\n",
    "                to initialize the hidden states of the network or use just zeros\n",
    "            use_peepholes: whether to use peephole connections (only 'lstm' case affected)\n",
    "            name: what variable_scope to use for the network parameters\n",
    "            add_l2_losses: whether to add l2 losses on network kernels to\n",
    "                tf.GraphKeys.REGULARIZATION_LOSSES or not\n",
    "        Returns:\n",
    "            units: tensor at the output of the last recurrent layer\n",
    "                with dimensionality [None, n_tokens, n_hidden_list[-1]]\n",
    "            last_units: tensor of last hidden states for GRU and tuple\n",
    "                of last hidden stated and last cell states for LSTM\n",
    "                dimensionality of cell states and hidden states are\n",
    "                similar and equal to [B x 2 * H], where B - batch\n",
    "                size and H is number of hidden units\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.variable_scope(name + '_' + cell_type.upper()):\n",
    "        if cell_type == 'gru':\n",
    "            forward_cell = tf.nn.rnn_cell.GRUCell(n_hidden, kernel_initializer=INITIALIZER())\n",
    "            backward_cell = tf.nn.rnn_cell.GRUCell(n_hidden, kernel_initializer=INITIALIZER())\n",
    "            if trainable_initial_states:\n",
    "                initial_state_fw = tf.tile(tf.get_variable('init_fw_h', [1, n_hidden]), (tf.shape(units)[0], 1))\n",
    "                initial_state_bw = tf.tile(tf.get_variable('init_bw_h', [1, n_hidden]), (tf.shape(units)[0], 1))\n",
    "            else:\n",
    "                initial_state_fw = initial_state_bw = None\n",
    "        elif cell_type == 'lstm':\n",
    "            forward_cell = tf.nn.rnn_cell.LSTMCell(n_hidden, use_peepholes=use_peepholes, initializer=INITIALIZER())\n",
    "            backward_cell = tf.nn.rnn_cell.LSTMCell(n_hidden, use_peepholes=use_peepholes, initializer=INITIALIZER())\n",
    "            if trainable_initial_states:\n",
    "                initial_state_fw = tf.nn.rnn_cell.LSTMStateTuple(\n",
    "                    tf.tile(tf.get_variable('init_fw_c', [1, n_hidden]), (tf.shape(units)[0], 1)),\n",
    "                    tf.tile(tf.get_variable('init_fw_h', [1, n_hidden]), (tf.shape(units)[0], 1)))\n",
    "                initial_state_bw = tf.nn.rnn_cell.LSTMStateTuple(\n",
    "                    tf.tile(tf.get_variable('init_bw_c', [1, n_hidden]), (tf.shape(units)[0], 1)),\n",
    "                    tf.tile(tf.get_variable('init_bw_h', [1, n_hidden]), (tf.shape(units)[0], 1)))\n",
    "            else:\n",
    "                initial_state_fw = initial_state_bw = None\n",
    "        else:\n",
    "            raise RuntimeError('cell_type must be either \"gru\" or \"lstm\"s')\n",
    "        (rnn_output_fw, rnn_output_bw), (fw, bw) = \\\n",
    "            tf.nn.bidirectional_dynamic_rnn(forward_cell,\n",
    "                                            backward_cell,\n",
    "                                            units,\n",
    "                                            dtype=tf.float32,\n",
    "                                            sequence_length=seq_lengths,\n",
    "                                            initial_state_fw=initial_state_fw,\n",
    "                                            initial_state_bw=initial_state_bw)\n",
    "    kernels = [var for var in forward_cell.trainable_variables +\n",
    "               backward_cell.trainable_variables if 'kernel' in var.name]\n",
    "    for kernel in kernels:\n",
    "        tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, tf.nn.l2_loss(kernel))\n",
    "    return (rnn_output_fw, rnn_output_bw), (fw, bw)\n",
    "\n",
    "def build_cudnn_rnn(units, mask, n_hidden_list:Tuple[int]=(128,), cell_type:str='lstm', intra_layer_dropout:bool=False, dropout_ph=None):\n",
    "    sequence_lengths = tf.to_int32(tf.reduce_sum(mask, axis=1))\n",
    "    for n, n_hidden in enumerate(n_hidden_list):\n",
    "        with tf.variable_scope(cell_type.upper() + '_' + str(n)):\n",
    "            if cell_type.lower() == 'lstm':\n",
    "                units, _ = cudnn_bi_lstm(units, n_hidden, sequence_lengths)\n",
    "            elif cell_type.lower() == 'gru':\n",
    "                units, _ = cudnn_bi_gru(units, n_hidden, sequence_lengths)\n",
    "            else:\n",
    "                raise RuntimeError('Wrong cell type \"{}\"! Only \"gru\" and \"lstm\"!'.format(cell_type))\n",
    "            units = tf.concat(units, -1)\n",
    "            if intra_layer_dropout and n != len(n_hidden_list) - 1:\n",
    "                units = variational_dropout(units, dropout_ph)\n",
    "    return units\n",
    "\n",
    "def build_rnn(units, n_hidden_list:Tuple[int]=(128,), cell_type:str='lstm', intra_layer_dropout:bool=False, dropout_ph=None):\n",
    "    for n, n_hidden in enumerate(n_hidden_list):\n",
    "        units, _ = bi_rnn(units, n_hidden, cell_type=cell_type, name='Layer_' + str(n))\n",
    "        units = tf.concat(units, -1)\n",
    "        if intra_layer_dropout and n != len(n_hidden_list) - 1:\n",
    "            units = variational_dropout(units, dropout_ph)\n",
    "    return units\n",
    "\n",
    "def build_top(units, n_tags=1, top_dropout:bool=False, two_dense_on_top:bool=False, n_hidden=128):\n",
    "    if top_dropout:\n",
    "        units = variational_dropout(units, dropout_ph)\n",
    "    if two_dense_on_top:\n",
    "        units = tf.layers.dense(units, n_hidden, activation=tf.nn.relu,\n",
    "                                kernel_initializer=INITIALIZER(),\n",
    "                                kernel_regularizer=tf.nn.l2_loss)\n",
    "    logits = tf.layers.dense(units, n_tags, activation=None,\n",
    "                             kernel_initializer=INITIALIZER(),\n",
    "                             kernel_regularizer=tf.nn.l2_loss)\n",
    "    return logits\n",
    "\n",
    "def build_train_predict(logits, n_tags, mask, y_ph, use_crf, learning_rate_ph, clip_grad_norm, l2_reg):\n",
    "    res = {}\n",
    "    if use_crf:\n",
    "        sequence_lengths = tf.reduce_sum(mask, axis=1)\n",
    "        log_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood(logits, y_ph, sequence_lengths)\n",
    "        loss_tensor = -log_likelihood\n",
    "        res['transition_params'] = transition_params\n",
    "    else:\n",
    "        ground_truth_labels = tf.one_hot(y_ph, n_tags)\n",
    "        loss_tensor = tf.nn.softmax_cross_entropy_with_logits(labels=ground_truth_labels, logits=logits)\n",
    "        loss_tensor = loss_tensor * mask\n",
    "        y_pred = tf.argmax(logits, axis=-1)\n",
    "        res['y_pred'] = y_pred\n",
    "\n",
    "    loss = tf.reduce_mean(loss_tensor)\n",
    "\n",
    "    # L2 regularization\n",
    "    if l2_reg > 0:\n",
    "        loss += l2_reg * tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "    res['loss'] = loss\n",
    "        \n",
    "    # optimizer = partial(tf.train.MomentumOptimizer, momentum=0.9, use_nesterov=True)\n",
    "    optimizer = tf.train.AdamOptimizer\n",
    "    train_op = get_train_op(loss, learning_rate_ph, optimizer, clip_norm=clip_grad_norm)\n",
    "    res['train_op'] = train_op\n",
    "    return res\n",
    "\n",
    "def predict_no_crf(y_pred, mask_ph, feed_dict):\n",
    "    pred_idxs, mask = sess.run([y_pred, mask_ph], feed_dict)\n",
    "\n",
    "    # Filter by sequece length\n",
    "    sequence_lengths = np.sum(mask, axis=1).astype(np.int32)\n",
    "    pred = []\n",
    "    for utt, l in zip(pred_idxs, sequence_lengths):\n",
    "        pred.append(utt[:l])\n",
    "    return pred\n",
    "\n",
    "def predict_crf(logits, transition_params, mask_ph, feed_dict):\n",
    "    logits, trans_params, mask = sess.run([logits,\n",
    "                                           transition_params,\n",
    "                                           mask_ph],\n",
    "                                           feed_dict=feed_dict)\n",
    "    sequence_lengths = np.maximum(np.sum(mask, axis=1).astype(np.int32), 1)\n",
    "    # iterate over the sentences because no batching in viterbi_decode\n",
    "    pred = []\n",
    "    for logit, sequence_length in zip(logits, sequence_lengths):\n",
    "        logit = logit[:int(sequence_length)]  # keep only the valid steps\n",
    "        viterbi_seq, viterbi_score = tf.contrib.crf.viterbi_decode(logit, trans_params)\n",
    "        pred += [viterbi_seq]\n",
    "    return pred\n",
    "\n",
    "def get_train_op(loss,\n",
    "                 learning_rate,\n",
    "                 optimizer=None,\n",
    "                 clip_norm=None,\n",
    "                 learnable_scopes=None,\n",
    "                 optimizer_scope_name=None,\n",
    "                 trainable_vars:list=None):\n",
    "    \"\"\" Get train operation for given loss\n",
    "\n",
    "    Args:\n",
    "        loss: loss, tf tensor or scalar\n",
    "        learning_rate: scalar or placeholder\n",
    "        clip_norm: clip gradients norm by clip_norm\n",
    "        learnable_scopes: which scopes are trainable (None for all)\n",
    "        optimizer: instance of tf.train.Optimizer, default Adam\n",
    "\n",
    "    Returns:\n",
    "        train_op\n",
    "    \"\"\"\n",
    "    if optimizer_scope_name is None:\n",
    "        opt_scope = tf.variable_scope('Optimizer')\n",
    "    else:\n",
    "        opt_scope = tf.variable_scope(optimizer_scope_name)\n",
    "    with opt_scope:\n",
    "        if learnable_scopes is None:\n",
    "            variables_to_train = tf.global_variables()\n",
    "        else:\n",
    "            variables_to_train = []\n",
    "            for scope_name in learnable_scopes:\n",
    "                for var in tf.global_variables():\n",
    "                    if scope_name in var.name:\n",
    "                        variables_to_train.append(var)\n",
    "        if trainable_vars:\n",
    "            variables_to_train = trainable_vars\n",
    "            \n",
    "        if optimizer is None:\n",
    "            optimizer = tf.train.AdamOptimizer\n",
    "\n",
    "        # For batch norm it is necessary to update running averages\n",
    "        extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(extra_update_ops):\n",
    "            opt = optimizer(learning_rate)\n",
    "            grads_and_vars = opt.compute_gradients(loss, var_list=variables_to_train)\n",
    "            if clip_norm is not None:\n",
    "                grads_and_vars = [(tf.clip_by_norm(grad, clip_norm), var)\n",
    "                                  for grad, var in grads_and_vars] #  if grad is not None\n",
    "            train_op = opt.apply_gradients(grads_and_vars)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o0RyP1tMkVtc"
   },
   "outputs": [],
   "source": [
    "def predict_labels(prob: np.ndarray, threshold=0.5):\n",
    "    labels = np.zeros(prob.shape)\n",
    "    labels[prob > threshold] = 1\n",
    "    return labels\n",
    "def flat_array(a: np.ndarray):\n",
    "#     return np.reshape(a, a.size)\n",
    "    return a.flatten()\n",
    "def calc_f1(y, pred_prob):\n",
    "    return f1_score(flat_array(y), flat_array(predict_labels(pred_prob)))\n",
    "def tags2binaryPadded(tags:list):\n",
    "    if isinstance(tags[0], str):\n",
    "        tags = [tags]\n",
    "    n_sentences = len(tags)\n",
    "    tokens_length = get_tokens_len(tags)\n",
    "    max_len = np.max(tokens_length)\n",
    "    tokens_length = np.tile(np.expand_dims(tokens_length, -1), (1,max_len))\n",
    "    y = np.zeros((n_sentences, max_len))\n",
    "    range_ar = np.tile(np.arange(1, max_len+1, 1), (n_sentences, 1))\n",
    "    for i, sen in enumerate(tags):\n",
    "        for j, tag in enumerate(sen):\n",
    "            if tags[i][j] != 'O':\n",
    "                y[i][j] = 1\n",
    "    return y\n",
    "def get_batch(dataset, batch_size=None):\n",
    "    if not batch_size:\n",
    "        batch_size = len(dataset)\n",
    "    tokens, tags = get_data_sample(dataset, batch_size)\n",
    "    mask = make_mask(tokens)\n",
    "    tokens_length = get_tokens_len(tokens)\n",
    "    tokens = add_padding(tokens)\n",
    "    y = tags2binaryPadded(tags)\n",
    "    return tokens, tags, mask, y\n",
    "\n",
    "def make_mask(seq_list):\n",
    "  seq_count = len(seq_list)\n",
    "  seq_length = [len(s) for s in seq_list]\n",
    "  max_len = np.max(seq_length)\n",
    "  mask = np.zeros((seq_count, max_len), dtype=int)\n",
    "  seq_length = np.tile(np.expand_dims(seq_length, axis=-1), (1, max_len))\n",
    "  range_ar = np.tile(np.arange(1, max_len+1, 1), (seq_count, 1))\n",
    "  mask[range_ar <= seq_length] = 1\n",
    "  return mask\n",
    "\n",
    "def flatten_with_mask(seq_mat, mask):\n",
    "  return seq_mat[mask == 1]\n",
    "\n",
    "def concatenate_arrays(ar_list):\n",
    "  return np.concatenate(ar_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SmlxreyYkVtk"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sa6asbyOkVtr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-30 12:55:36.20 INFO in 'tensorflow'['tf_logging'] at line 159: Using /tmp/tfhub_modules to cache modules.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Downloading TF-Hub Module 'https://tfhub.dev/google/elmo/1'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-30 12:55:36.23 INFO in 'tensorflow'['tf_logging'] at line 115: Downloading TF-Hub Module 'https://tfhub.dev/google/elmo/1'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Downloaded TF-Hub Module 'https://tfhub.dev/google/elmo/1'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-30 12:56:53.629 INFO in 'tensorflow'['tf_logging'] at line 115: Downloaded TF-Hub Module 'https://tfhub.dev/google/elmo/1'.\n"
     ]
    }
   ],
   "source": [
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/1\", trainable=TRAIN_ELMO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1063,
     "status": "ok",
     "timestamp": 1535541044601,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "DH-BhVEqkVt5",
    "outputId": "cd7eac43-dd68-474a-bc05-11080d33de42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0' shape=(1024, 16384) dtype=float32>, <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0' shape=(16384,) dtype=float32>, <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0' shape=(4096, 512) dtype=float32>, <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0' shape=(1024, 16384) dtype=float32>, <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0' shape=(16384,) dtype=float32>, <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0' shape=(4096, 512) dtype=float32>, <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0' shape=(1024, 16384) dtype=float32>, <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0' shape=(16384,) dtype=float32>, <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0' shape=(4096, 512) dtype=float32>, <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0' shape=(1024, 16384) dtype=float32>, <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0' shape=(16384,) dtype=float32>, <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0' shape=(4096, 512) dtype=float32>, <tf.Variable 'module/aggregation/weights:0' shape=(3,) dtype=float32>, <tf.Variable 'module/aggregation/scaling:0' shape=() dtype=float32>]\n",
      "{'layer_coefficients': <tf.Variable 'module/aggregation/weights:0' shape=(3,) dtype=float32>, 'scaling': <tf.Variable 'module/aggregation/scaling:0' shape=() dtype=float32>}\n"
     ]
    }
   ],
   "source": [
    "print(tf.trainable_variables())\n",
    "if(TRAIN_ELMO):\n",
    "    elmo_coef = {'layer_coefficients': tf.trainable_variables()[-2], 'scaling': tf.trainable_variables()[-1]}\n",
    "    print(elmo_coef)\n",
    "elmo_vars = tf.trainable_variables()\n",
    "elmo_vars_coef = list(elmo_coef.values())\n",
    "elmo_vars_cell_weights = [v for v in elmo_vars if v not in elmo_vars_coef]\n",
    "vars_dict = {v.name:v for v in tf.trainable_variables()}\n",
    "if TRAIN_ALL_ELMO_PARAMS:\n",
    "    cell0_kernel = vars_dict['module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0']\n",
    "    cell1_kernel = vars_dict['module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2f2m5Ud0kVuC"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "use_cudnn_rnn = False\n",
    "l2_reg = 0\n",
    "n_hidden_list = (128,)\n",
    "cell_type = 'lstm'\n",
    "n_tags = 2\n",
    "use_crf = True\n",
    "clip_grad_norm = 5.0\n",
    "learning_rate = 1e-3\n",
    "dropout_keep_prob = 0.5\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sr78klsHkVuI"
   },
   "source": [
    "### Build computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z51-uX6xkVuK"
   },
   "outputs": [],
   "source": [
    "# Placeholders\n",
    "tokens_input_ph = tf.placeholder(shape=[None, None], dtype=tf.string)\n",
    "# tokens_length_ph = tf.placeholder(shape=[None], dtype=tf.int32)\n",
    "mask_ph = tf.placeholder(tf.float32, [None, None], name='Mask_ph')\n",
    "y_ph = tf.placeholder(shape=[None, None], dtype=tf.int32, name='y_ph')\n",
    "learning_rate_ph = tf.placeholder_with_default(learning_rate, shape=[], name='learning_rate')\n",
    "dropout_ph = tf.placeholder_with_default(dropout_keep_prob, shape=[], name='dropout')\n",
    "training_ph = tf.placeholder_with_default(False, shape=[], name='is_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z1Q0wS-x-866"
   },
   "outputs": [],
   "source": [
    "def fill_feed_dict(inp: dict, train=True):\n",
    "  feed_dict = {learning_rate_ph: learning_rate, dropout_ph: dropout_keep_prob if train else 1.0, training_ph: train}\n",
    "  feed_dict.update(inp)\n",
    "  return feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7917,
     "status": "ok",
     "timestamp": 1535541055967,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "_jTTCTq1kVuQ",
    "outputId": "a990e768-3139-400e-e4dc-e8ca20ef794f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-30 12:56:54.371 INFO in 'tensorflow'['tf_logging'] at line 115: Saver not created because there are no variables in the graph to restore\n",
      "/home/clement/virtenv/env/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "y_pred = None\n",
    "transition_params = None\n",
    "tokens_length = tf.to_int32(tf.reduce_sum(mask_ph, axis=1))\n",
    "emb = elmo(inputs={\"tokens\": tokens_input_ph,\n",
    "                    \"sequence_len\": tokens_length},\n",
    "                  signature=\"tokens\",\n",
    "                  as_dict=True)['elmo']\n",
    "# mask = tf.sequence_mask(lengths=tokens_length_ph, dtype=tf.float32)\n",
    "features = emb\n",
    "if use_cudnn_rnn:\n",
    "    units = build_cudnn_rnn(features, mask_ph, n_hidden_list, cell_type)\n",
    "else:\n",
    "    units = build_rnn(features, n_hidden_list, cell_type)\n",
    "\n",
    "logits = build_top(units, n_tags=n_tags)\n",
    "\n",
    "out_dict = build_train_predict(logits, n_tags, mask_ph, y_ph, use_crf, learning_rate_ph, clip_grad_norm, l2_reg)\n",
    "train_op_all = out_dict['train_op']\n",
    "loss = out_dict['loss']\n",
    "if use_crf:\n",
    "    transition_params = out_dict['transition_params']\n",
    "else:\n",
    "    y_pred = out_dict['y_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 889,
     "status": "ok",
     "timestamp": 1535541056881,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "qgSrNRNRkVuZ",
    "outputId": "2b2cfea5-7bd0-4fe5-badb-8fdc5800838d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'Layer_0_LSTM/bidirectional_rnn/fw/lstm_cell/kernel:0' shape=(1152, 512) dtype=float32_ref>, <tf.Variable 'Layer_0_LSTM/bidirectional_rnn/fw/lstm_cell/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'Layer_0_LSTM/bidirectional_rnn/bw/lstm_cell/kernel:0' shape=(1152, 512) dtype=float32_ref>, <tf.Variable 'Layer_0_LSTM/bidirectional_rnn/bw/lstm_cell/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'dense/kernel:0' shape=(256, 2) dtype=float32_ref>, <tf.Variable 'dense/bias:0' shape=(2,) dtype=float32_ref>, <tf.Variable 'transitions:0' shape=(2, 2) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "all_vars = tf.trainable_variables()\n",
    "model_vars = [v for v in all_vars if v not in elmo_vars]\n",
    "print(model_vars)\n",
    "vars_dict = {v.name:v for v in tf.trainable_variables()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10776,
     "status": "ok",
     "timestamp": 1535541067726,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "ClB2ef3eEUAu",
    "outputId": "4d925ba9-6536-43f1-8a26-c892837548eb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clement/virtenv/env/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "# Optimizers for different parameters\n",
    "with tf.variable_scope('Optimizer', reuse=tf.AUTO_REUSE):\n",
    "    train_op_model = get_train_op(loss, learning_rate_ph, tf.train.AdamOptimizer, clip_norm=clip_grad_norm, trainable_vars=model_vars)\n",
    "    train_op_elmo = get_train_op(loss, learning_rate_ph, tf.train.AdamOptimizer, clip_norm=clip_grad_norm, trainable_vars=elmo_vars)\n",
    "    train_op_elmo_coef = get_train_op(loss, learning_rate_ph, tf.train.AdamOptimizer, clip_norm=clip_grad_norm, trainable_vars=elmo_vars_coef)\n",
    "    train_op_elmo_cell_weights = get_train_op(loss, learning_rate_ph, tf.train.AdamOptimizer, clip_norm=clip_grad_norm, trainable_vars=elmo_vars_cell_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4eTOpnQ9EUA4"
   },
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter('./graph/bilstm_crf_elmo', tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlqOMRZ_kVuf"
   },
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6648,
     "status": "ok",
     "timestamp": 1535541078103,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "YsCb3L9xkVui",
    "outputId": "b8301436-e9e2-4d2e-9193-438a3fabbd7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_op = tf.global_variables_initializer()\n",
    "sess.run([initialize_op])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCPpR5VpkVu_"
   },
   "outputs": [],
   "source": [
    "valid_sen_size = 100\n",
    "tokens_valid, tags_valid, mask_valid, y_valid = get_batch(dataset['valid'], valid_sen_size)\n",
    "feed_valid = fill_feed_dict({tokens_input_ph: tokens_valid, mask_ph: mask_valid, y_ph: y_valid, training_ph: False}, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eNl_ak0xLS2G"
   },
   "outputs": [],
   "source": [
    "# training_schedule = [{'train_op': train_op_model, 'n_steps': 100, 'lr': 1e-3}, {'train_op': train_op_elmo_cell_weights, 'n_steps': 100, 'lr': 1e-3}, {'train_op': train_op_elmo_coef, 'n_steps': 200, 'lr': 1e-2}, {'train_op': train_op_model, 'n_steps': 100, 'lr': 1e-3}, {'train_op': train_op_elmo_cell_weights, 'n_steps': 100, 'lr': 1e-3}, {'train_op': train_op_elmo_coef, 'n_steps': 200, 'lr': 1e-2}]\n",
    "training_schedule = [{'train_op': train_op_model, 'n_steps': 200, 'lr': 1e-3}, {'train_op': train_op_elmo_cell_weights, 'n_steps': 200, 'lr': 1e-3}, {'train_op': train_op_elmo_coef, 'n_steps': 200, 'lr': 1e-2}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 27319
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4503805,
     "status": "ok",
     "timestamp": 1535545584971,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "ab6-6mpDkVvF",
    "outputId": "e41555dc-c951-42cb-9fed-3f682300680a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1/600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clement/virtenv/env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss = 11.609489440917969\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 12.589993476867676\n",
      "Valid F1 score = 0.0\n",
      "Step 2/600\n",
      "Step 3/600\n",
      "Step 4/600\n",
      "Step 5/600\n",
      "Train loss = 7.0814056396484375\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 6/600\n",
      "Step 7/600\n",
      "Step 8/600\n",
      "Step 9/600\n",
      "Step 10/600\n",
      "Train loss = 4.866654396057129\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 5.2910637855529785\n",
      "Valid F1 score = 0.7671517671517671\n",
      "Step 11/600\n",
      "Step 12/600\n",
      "Step 13/600\n",
      "Step 14/600\n",
      "Step 15/600\n",
      "Train loss = 4.101593971252441\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 16/600\n",
      "Step 17/600\n",
      "Step 18/600\n",
      "Step 19/600\n",
      "Step 20/600\n",
      "Train loss = 3.3878061771392822\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 4.354440212249756\n",
      "Valid F1 score = 0.8192513368983958\n",
      "Step 21/600\n",
      "Step 22/600\n",
      "Step 23/600\n",
      "Step 24/600\n",
      "Step 25/600\n",
      "Train loss = 3.221724033355713\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 26/600\n",
      "Step 27/600\n",
      "Step 28/600\n",
      "Step 29/600\n",
      "Step 30/600\n",
      "Train loss = 2.5294580459594727\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 3.861691951751709\n",
      "Valid F1 score = 0.8556593977154726\n",
      "Step 31/600\n",
      "Step 32/600\n",
      "Step 33/600\n",
      "Step 34/600\n",
      "Step 35/600\n",
      "Train loss = 3.763423204421997\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 36/600\n",
      "Step 37/600\n",
      "Step 38/600\n",
      "Step 39/600\n",
      "Step 40/600\n",
      "Train loss = 2.1975646018981934\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 3.342865228652954\n",
      "Valid F1 score = 0.8895463510848125\n",
      "Step 41/600\n",
      "Step 42/600\n",
      "Step 43/600\n",
      "Step 44/600\n",
      "Step 45/600\n",
      "Train loss = 2.3221282958984375\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 46/600\n",
      "Step 47/600\n",
      "Step 48/600\n",
      "Step 49/600\n",
      "Step 50/600\n",
      "Train loss = 3.284886360168457\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 3.051809072494507\n",
      "Valid F1 score = 0.8932419196865817\n",
      "Step 51/600\n",
      "Step 52/600\n",
      "Step 53/600\n",
      "Step 54/600\n",
      "Step 55/600\n",
      "Train loss = 2.9722397327423096\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 56/600\n",
      "Step 57/600\n",
      "Step 58/600\n",
      "Step 59/600\n",
      "Step 60/600\n",
      "Train loss = 3.2372512817382812\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 3.206754207611084\n",
      "Valid F1 score = 0.8766839378238342\n",
      "Step 61/600\n",
      "Step 62/600\n",
      "Step 63/600\n",
      "Step 64/600\n",
      "Step 65/600\n",
      "Train loss = 1.825864315032959\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 66/600\n",
      "Step 67/600\n",
      "Step 68/600\n",
      "Step 69/600\n",
      "Step 70/600\n",
      "Train loss = 2.1451234817504883\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.6075050830841064\n",
      "Valid F1 score = 0.9020368574199806\n",
      "Step 71/600\n",
      "Step 72/600\n",
      "Step 73/600\n",
      "Step 74/600\n",
      "Step 75/600\n",
      "Train loss = 2.3113820552825928\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 76/600\n",
      "Step 77/600\n",
      "Step 78/600\n",
      "Step 79/600\n",
      "Step 80/600\n",
      "Train loss = 1.5134183168411255\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.673293113708496\n",
      "Valid F1 score = 0.8982035928143713\n",
      "Step 81/600\n",
      "Step 82/600\n",
      "Step 83/600\n",
      "Step 84/600\n",
      "Step 85/600\n",
      "Train loss = 1.323489785194397\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 86/600\n",
      "Step 87/600\n",
      "Step 88/600\n",
      "Step 89/600\n",
      "Step 90/600\n",
      "Train loss = 1.5040452480316162\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.6901679039001465\n",
      "Valid F1 score = 0.915615906886518\n",
      "Step 91/600\n",
      "Step 92/600\n",
      "Step 93/600\n",
      "Step 94/600\n",
      "Step 95/600\n",
      "Train loss = 2.081324577331543\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 96/600\n",
      "Step 97/600\n",
      "Step 98/600\n",
      "Step 99/600\n",
      "Step 100/600\n",
      "Train loss = 2.1451783180236816\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.7326292991638184\n",
      "Valid F1 score = 0.9166666666666666\n",
      "Step 101/600\n",
      "Step 102/600\n",
      "Step 103/600\n",
      "Step 104/600\n",
      "Step 105/600\n",
      "Train loss = 1.2960940599441528\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 106/600\n",
      "Step 107/600\n",
      "Step 108/600\n",
      "Step 109/600\n",
      "Step 110/600\n",
      "Train loss = 1.048997402191162\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.5702855587005615\n",
      "Valid F1 score = 0.9218595450049455\n",
      "Step 111/600\n",
      "Step 112/600\n",
      "Step 113/600\n",
      "Step 114/600\n",
      "Step 115/600\n",
      "Train loss = 1.7126853466033936\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 116/600\n",
      "Step 117/600\n",
      "Step 118/600\n",
      "Step 119/600\n",
      "Step 120/600\n",
      "Train loss = 1.4729048013687134\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.558173656463623\n",
      "Valid F1 score = 0.9209486166007905\n",
      "Step 121/600\n",
      "Step 122/600\n",
      "Step 123/600\n",
      "Step 124/600\n",
      "Step 125/600\n",
      "Train loss = 2.3966147899627686\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 126/600\n",
      "Step 127/600\n",
      "Step 128/600\n",
      "Step 129/600\n",
      "Step 130/600\n",
      "Train loss = 1.5638021230697632\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.3913135528564453\n",
      "Valid F1 score = 0.9242871189773845\n",
      "Step 131/600\n",
      "Step 132/600\n",
      "Step 133/600\n",
      "Step 134/600\n",
      "Step 135/600\n",
      "Train loss = 1.052192211151123\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 136/600\n",
      "Step 137/600\n",
      "Step 138/600\n",
      "Step 139/600\n",
      "Step 140/600\n",
      "Train loss = 1.8162720203399658\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.44010066986084\n",
      "Valid F1 score = 0.9152542372881356\n",
      "Step 141/600\n",
      "Step 142/600\n",
      "Step 143/600\n",
      "Step 144/600\n",
      "Step 145/600\n",
      "Train loss = 1.480263590812683\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 146/600\n",
      "Step 147/600\n",
      "Step 148/600\n",
      "Step 149/600\n",
      "Step 150/600\n",
      "Train loss = 1.625544786453247\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.3262135982513428\n",
      "Valid F1 score = 0.9245647969052223\n",
      "Step 151/600\n",
      "Step 152/600\n",
      "Step 153/600\n",
      "Step 154/600\n",
      "Step 155/600\n",
      "Train loss = 1.9677727222442627\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 156/600\n",
      "Step 157/600\n",
      "Step 158/600\n",
      "Step 159/600\n",
      "Step 160/600\n",
      "Train loss = 1.4261646270751953\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.22956919670105\n",
      "Valid F1 score = 0.9190243902439024\n",
      "Step 161/600\n",
      "Step 162/600\n",
      "Step 163/600\n",
      "Step 164/600\n",
      "Step 165/600\n",
      "Train loss = 1.4496333599090576\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 166/600\n",
      "Step 167/600\n",
      "Step 168/600\n",
      "Step 169/600\n",
      "Step 170/600\n",
      "Train loss = 2.4617350101470947\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.353569269180298\n",
      "Valid F1 score = 0.9241245136186769\n",
      "Step 171/600\n",
      "Step 172/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 173/600\n",
      "Step 174/600\n",
      "Step 175/600\n",
      "Train loss = 1.5446181297302246\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 176/600\n",
      "Step 177/600\n",
      "Step 178/600\n",
      "Step 179/600\n",
      "Step 180/600\n",
      "Train loss = 1.2356600761413574\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.3000569343566895\n",
      "Valid F1 score = 0.9154518950437318\n",
      "Step 181/600\n",
      "Step 182/600\n",
      "Step 183/600\n",
      "Step 184/600\n",
      "Step 185/600\n",
      "Train loss = 1.974875807762146\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 186/600\n",
      "Step 187/600\n",
      "Step 188/600\n",
      "Step 189/600\n",
      "Step 190/600\n",
      "Train loss = 1.9161064624786377\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.2969963550567627\n",
      "Valid F1 score = 0.9226305609284332\n",
      "Step 191/600\n",
      "Step 192/600\n",
      "Step 193/600\n",
      "Step 194/600\n",
      "Step 195/600\n",
      "Train loss = 1.0464587211608887\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 196/600\n",
      "Step 197/600\n",
      "Step 198/600\n",
      "Step 199/600\n",
      "Step 200/600\n",
      "Train loss = 1.394897699356079\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.367637872695923\n",
      "Valid F1 score = 0.9212598425196851\n",
      "Step 201/600\n",
      "Step 202/600\n",
      "Step 203/600\n",
      "Step 204/600\n",
      "Step 205/600\n",
      "Train loss = 3.6279003620147705\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.59%, cell1: 0.67%\n",
      "Step 206/600\n",
      "Step 207/600\n",
      "Step 208/600\n",
      "Step 209/600\n",
      "Step 210/600\n",
      "Train loss = 2.8133249282836914\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.41%, cell1: 0.43%\n",
      "Valid loss = 3.081239700317383\n",
      "Valid F1 score = 0.8948412698412699\n",
      "Step 211/600\n",
      "Step 212/600\n",
      "Step 213/600\n",
      "Step 214/600\n",
      "Step 215/600\n",
      "Train loss = 1.4899544715881348\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.31%, cell1: 0.31%\n",
      "Step 216/600\n",
      "Step 217/600\n",
      "Step 218/600\n",
      "Step 219/600\n",
      "Step 220/600\n",
      "Train loss = 1.6244055032730103\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.30%, cell1: 0.25%\n",
      "Valid loss = 2.98382568359375\n",
      "Valid F1 score = 0.8839556004036327\n",
      "Step 221/600\n",
      "Step 222/600\n",
      "Step 223/600\n",
      "Step 224/600\n",
      "Step 225/600\n",
      "Train loss = 1.6686816215515137\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.26%, cell1: 0.21%\n",
      "Step 226/600\n",
      "Step 227/600\n",
      "Step 228/600\n",
      "Step 229/600\n",
      "Step 230/600\n",
      "Train loss = 1.7534537315368652\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.25%, cell1: 0.19%\n",
      "Valid loss = 2.2812716960906982\n",
      "Valid F1 score = 0.9101229895931882\n",
      "Step 231/600\n",
      "Step 232/600\n",
      "Step 233/600\n",
      "Step 234/600\n",
      "Step 235/600\n",
      "Train loss = 1.8135061264038086\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.23%, cell1: 0.16%\n",
      "Step 236/600\n",
      "Step 237/600\n",
      "Step 238/600\n",
      "Step 239/600\n",
      "Step 240/600\n",
      "Train loss = 0.9917184114456177\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.24%, cell1: 0.14%\n",
      "Valid loss = 2.213979721069336\n",
      "Valid F1 score = 0.9149952244508118\n",
      "Step 241/600\n",
      "Step 242/600\n",
      "Step 243/600\n",
      "Step 244/600\n",
      "Step 245/600\n",
      "Train loss = 1.1993263959884644\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.20%, cell1: 0.12%\n",
      "Step 246/600\n",
      "Step 247/600\n",
      "Step 248/600\n",
      "Step 249/600\n",
      "Step 250/600\n",
      "Train loss = 1.8589516878128052\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.23%, cell1: 0.13%\n",
      "Valid loss = 2.0808000564575195\n",
      "Valid F1 score = 0.9273084479371316\n",
      "Step 251/600\n",
      "Step 252/600\n",
      "Step 253/600\n",
      "Step 254/600\n",
      "Step 255/600\n",
      "Train loss = 1.1854774951934814\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.21%, cell1: 0.12%\n",
      "Step 256/600\n",
      "Step 257/600\n",
      "Step 258/600\n",
      "Step 259/600\n",
      "Step 260/600\n",
      "Train loss = 1.1908354759216309\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.22%, cell1: 0.12%\n",
      "Valid loss = 2.02304744720459\n",
      "Valid F1 score = 0.9311023622047243\n",
      "Step 261/600\n",
      "Step 262/600\n",
      "Step 263/600\n",
      "Step 264/600\n",
      "Step 265/600\n",
      "Train loss = 1.8118757009506226\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.24%, cell1: 0.12%\n",
      "Step 266/600\n",
      "Step 267/600\n",
      "Step 268/600\n",
      "Step 269/600\n",
      "Step 270/600\n",
      "Train loss = 2.265380859375\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.22%, cell1: 0.11%\n",
      "Valid loss = 2.3808701038360596\n",
      "Valid F1 score = 0.9206349206349206\n",
      "Step 271/600\n",
      "Step 272/600\n",
      "Step 273/600\n",
      "Step 274/600\n",
      "Step 275/600\n",
      "Train loss = 4.296224594116211\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.25%, cell1: 0.16%\n",
      "Step 276/600\n",
      "Step 277/600\n",
      "Step 278/600\n",
      "Step 279/600\n",
      "Step 280/600\n",
      "Train loss = 1.4640504121780396\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.21%, cell1: 0.13%\n",
      "Valid loss = 1.759735107421875\n",
      "Valid F1 score = 0.9241114313160423\n",
      "Step 281/600\n",
      "Step 282/600\n",
      "Step 283/600\n",
      "Step 284/600\n",
      "Step 285/600\n",
      "Train loss = 1.6437418460845947\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.23%, cell1: 0.14%\n",
      "Step 286/600\n",
      "Step 287/600\n",
      "Step 288/600\n",
      "Step 289/600\n",
      "Step 290/600\n",
      "Train loss = 1.2290866374969482\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.20%, cell1: 0.13%\n",
      "Valid loss = 1.9125666618347168\n",
      "Valid F1 score = 0.9291949563530554\n",
      "Step 291/600\n",
      "Step 292/600\n",
      "Step 293/600\n",
      "Step 294/600\n",
      "Step 295/600\n",
      "Train loss = 1.7589505910873413\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.20%, cell1: 0.16%\n",
      "Step 296/600\n",
      "Step 297/600\n",
      "Step 298/600\n",
      "Step 299/600\n",
      "Step 300/600\n",
      "Train loss = 1.9768435955047607\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.20%, cell1: 0.15%\n",
      "Valid loss = 2.2409119606018066\n",
      "Valid F1 score = 0.93488824101069\n",
      "Step 301/600\n",
      "Step 302/600\n",
      "Step 303/600\n",
      "Step 304/600\n",
      "Step 305/600\n",
      "Train loss = 1.8419902324676514\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.23%, cell1: 0.19%\n",
      "Step 306/600\n",
      "Step 307/600\n",
      "Step 308/600\n",
      "Step 309/600\n",
      "Step 310/600\n",
      "Train loss = 1.4341224431991577\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.23%, cell1: 0.18%\n",
      "Valid loss = 2.53410267829895\n",
      "Valid F1 score = 0.9269717624148004\n",
      "Step 311/600\n",
      "Step 312/600\n",
      "Step 313/600\n",
      "Step 314/600\n",
      "Step 315/600\n",
      "Train loss = 2.2137417793273926\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.22%, cell1: 0.17%\n",
      "Step 316/600\n",
      "Step 317/600\n",
      "Step 318/600\n",
      "Step 319/600\n",
      "Step 320/600\n",
      "Train loss = 1.1699471473693848\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.23%, cell1: 0.16%\n",
      "Valid loss = 2.4495201110839844\n",
      "Valid F1 score = 0.9263565891472868\n",
      "Step 321/600\n",
      "Step 322/600\n",
      "Step 323/600\n",
      "Step 324/600\n",
      "Step 325/600\n",
      "Train loss = 1.1420748233795166\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.22%, cell1: 0.18%\n",
      "Step 326/600\n",
      "Step 327/600\n",
      "Step 328/600\n",
      "Step 329/600\n",
      "Step 330/600\n",
      "Train loss = 0.7578175067901611\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.23%, cell1: 0.16%\n",
      "Valid loss = 2.271953821182251\n",
      "Valid F1 score = 0.9293320425943853\n",
      "Step 331/600\n",
      "Step 332/600\n",
      "Step 333/600\n",
      "Step 334/600\n",
      "Step 335/600\n",
      "Train loss = 1.5526165962219238\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.24%, cell1: 0.17%\n",
      "Step 336/600\n",
      "Step 337/600\n",
      "Step 338/600\n",
      "Step 339/600\n",
      "Step 340/600\n",
      "Train loss = 1.6373271942138672\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.28%, cell1: 0.16%\n",
      "Valid loss = 2.3229663372039795\n",
      "Valid F1 score = 0.9284332688588008\n",
      "Step 341/600\n",
      "Step 342/600\n",
      "Step 343/600\n",
      "Step 344/600\n",
      "Step 345/600\n",
      "Train loss = 1.4144392013549805\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.28%, cell1: 0.15%\n",
      "Step 346/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 347/600\n",
      "Step 348/600\n",
      "Step 349/600\n",
      "Step 350/600\n",
      "Train loss = 1.4531630277633667\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.24%, cell1: 0.13%\n",
      "Valid loss = 2.152223825454712\n",
      "Valid F1 score = 0.9283611383709519\n",
      "Step 351/600\n",
      "Step 352/600\n",
      "Step 353/600\n",
      "Step 354/600\n",
      "Step 355/600\n",
      "Train loss = 1.2708507776260376\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.23%, cell1: 0.14%\n",
      "Step 356/600\n",
      "Step 357/600\n",
      "Step 358/600\n",
      "Step 359/600\n",
      "Step 360/600\n",
      "Train loss = 1.1820069551467896\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.23%, cell1: 0.13%\n",
      "Valid loss = 2.4129726886749268\n",
      "Valid F1 score = 0.9320388349514563\n",
      "Step 361/600\n",
      "Step 362/600\n",
      "Step 363/600\n",
      "Step 364/600\n",
      "Step 365/600\n",
      "Train loss = 1.0538253784179688\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.23%, cell1: 0.14%\n",
      "Step 366/600\n",
      "Step 367/600\n",
      "Step 368/600\n",
      "Step 369/600\n",
      "Step 370/600\n",
      "Train loss = 1.251594066619873\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.25%, cell1: 0.16%\n",
      "Valid loss = 2.4415323734283447\n",
      "Valid F1 score = 0.924901185770751\n",
      "Step 371/600\n",
      "Step 372/600\n",
      "Step 373/600\n",
      "Step 374/600\n",
      "Step 375/600\n",
      "Train loss = 1.0485241413116455\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.22%, cell1: 0.15%\n",
      "Step 376/600\n",
      "Step 377/600\n",
      "Step 378/600\n",
      "Step 379/600\n",
      "Step 380/600\n",
      "Train loss = 1.4404983520507812\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.28%, cell1: 0.17%\n",
      "Valid loss = 2.355011224746704\n",
      "Valid F1 score = 0.9223300970873787\n",
      "Step 381/600\n",
      "Step 382/600\n",
      "Step 383/600\n",
      "Step 384/600\n",
      "Step 385/600\n",
      "Train loss = 1.701160192489624\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.27%, cell1: 0.17%\n",
      "Step 386/600\n",
      "Step 387/600\n",
      "Step 388/600\n",
      "Step 389/600\n",
      "Step 390/600\n",
      "Train loss = 1.6159417629241943\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.25%, cell1: 0.15%\n",
      "Valid loss = 2.416896343231201\n",
      "Valid F1 score = 0.924401913875598\n",
      "Step 391/600\n",
      "Step 392/600\n",
      "Step 393/600\n",
      "Step 394/600\n",
      "Step 395/600\n",
      "Train loss = 1.3675284385681152\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.25%, cell1: 0.15%\n",
      "Step 396/600\n",
      "Step 397/600\n",
      "Step 398/600\n",
      "Step 399/600\n",
      "Step 400/600\n",
      "Train loss = 0.9696075916290283\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.27%, cell1: 0.17%\n",
      "Valid loss = 2.5387442111968994\n",
      "Valid F1 score = 0.9103448275862068\n",
      "Step 401/600\n",
      "Step 402/600\n",
      "Step 403/600\n",
      "Step 404/600\n",
      "Step 405/600\n",
      "Train loss = 0.7420132160186768\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.04170293  0.00650392 -0.03968297], scale = 0.989460289478302\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 406/600\n",
      "Step 407/600\n",
      "Step 408/600\n",
      "Step 409/600\n",
      "Step 410/600\n",
      "Train loss = 1.5590004920959473\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.06090205  0.04010062 -0.07883848], scale = 1.0118002891540527\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.5149025917053223\n",
      "Valid F1 score = 0.9114173228346456\n",
      "Step 411/600\n",
      "Step 412/600\n",
      "Step 413/600\n",
      "Step 414/600\n",
      "Step 415/600\n",
      "Train loss = 1.1112349033355713\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.07629332  0.07056148 -0.11294675], scale = 1.0332694053649902\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 416/600\n",
      "Step 417/600\n",
      "Step 418/600\n",
      "Step 419/600\n",
      "Step 420/600\n",
      "Train loss = 1.1168212890625\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.08407344  0.08753867 -0.13112338], scale = 1.0501127243041992\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.5129647254943848\n",
      "Valid F1 score = 0.9147894221351616\n",
      "Step 421/600\n",
      "Step 422/600\n",
      "Step 423/600\n",
      "Step 424/600\n",
      "Step 425/600\n",
      "Train loss = 0.7354394197463989\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.09096977  0.10002398 -0.14516647], scale = 1.0606391429901123\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 426/600\n",
      "Step 427/600\n",
      "Step 428/600\n",
      "Step 429/600\n",
      "Step 430/600\n",
      "Train loss = 0.8330416679382324\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.09964174  0.11737791 -0.16493165], scale = 1.0690884590148926\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.5119311809539795\n",
      "Valid F1 score = 0.9138943248532289\n",
      "Step 431/600\n",
      "Step 432/600\n",
      "Step 433/600\n",
      "Step 434/600\n",
      "Step 435/600\n",
      "Train loss = 1.4932231903076172\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.12364008  0.12898496 -0.1924306 ], scale = 1.05729079246521\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 436/600\n",
      "Step 437/600\n",
      "Step 438/600\n",
      "Step 439/600\n",
      "Step 440/600\n",
      "Train loss = 0.5649925470352173\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.14834845  0.14762887 -0.22622618], scale = 1.0504924058914185\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.49051570892334\n",
      "Valid F1 score = 0.9158512720156555\n",
      "Step 441/600\n",
      "Step 442/600\n",
      "Step 443/600\n",
      "Step 444/600\n",
      "Step 445/600\n",
      "Train loss = 1.0477272272109985\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.16807866  0.16947538 -0.25938815], scale = 1.0539268255233765\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 446/600\n",
      "Step 447/600\n",
      "Step 448/600\n",
      "Step 449/600\n",
      "Step 450/600\n",
      "Train loss = 0.7646981477737427\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.18223263  0.19963159 -0.29507235], scale = 1.0670424699783325\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.4856834411621094\n",
      "Valid F1 score = 0.9190243902439024\n",
      "Step 451/600\n",
      "Step 452/600\n",
      "Step 453/600\n",
      "Step 454/600\n",
      "Step 455/600\n",
      "Train loss = 1.6940995454788208\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.19418071  0.22306164 -0.32308033], scale = 1.0795133113861084\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 456/600\n",
      "Step 457/600\n",
      "Step 458/600\n",
      "Step 459/600\n",
      "Step 460/600\n",
      "Train loss = 0.6488245725631714\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.19747075  0.24394341 -0.34318364], scale = 1.0871906280517578\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.49027681350708\n",
      "Valid F1 score = 0.923226433430515\n",
      "Step 461/600\n",
      "Step 462/600\n",
      "Step 463/600\n",
      "Step 464/600\n",
      "Step 465/600\n",
      "Train loss = 0.6786784529685974\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.18557067  0.27515927 -0.36176696], scale = 1.1035205125808716\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 466/600\n",
      "Step 467/600\n",
      "Step 468/600\n",
      "Step 469/600\n",
      "Step 470/600\n",
      "Train loss = 1.2509543895721436\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.1758795   0.30636287 -0.38248438], scale = 1.1193822622299194\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.5138602256774902\n",
      "Valid F1 score = 0.9264990328820117\n",
      "Step 471/600\n",
      "Step 472/600\n",
      "Step 473/600\n",
      "Step 474/600\n",
      "Step 475/600\n",
      "Train loss = 0.9896082878112793\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.17205226  0.33155558 -0.4023171 ], scale = 1.1365091800689697\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 476/600\n",
      "Step 477/600\n",
      "Step 478/600\n",
      "Step 479/600\n",
      "Step 480/600\n",
      "Train loss = 1.6639931201934814\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.17083946  0.34155157 -0.4104788 ], scale = 1.140166997909546\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.528057813644409\n",
      "Valid F1 score = 0.9264990328820117\n",
      "Step 481/600\n",
      "Step 482/600\n",
      "Step 483/600\n",
      "Step 484/600\n",
      "Step 485/600\n",
      "Train loss = 0.4337601065635681\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.18408848  0.33176833 -0.4119613 ], scale = 1.1333842277526855\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 486/600\n",
      "Step 487/600\n",
      "Step 488/600\n",
      "Step 489/600\n",
      "Step 490/600\n",
      "Train loss = 1.5037939548492432\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.19025289  0.32475924 -0.41029826], scale = 1.128835916519165\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.5159711837768555\n",
      "Valid F1 score = 0.9264990328820117\n",
      "Step 491/600\n",
      "Step 492/600\n",
      "Step 493/600\n",
      "Step 494/600\n",
      "Step 495/600\n",
      "Train loss = 1.264021396636963\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.19047354  0.3216795  -0.4075591 ], scale = 1.1209303140640259\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 496/600\n",
      "Step 497/600\n",
      "Step 498/600\n",
      "Step 499/600\n",
      "Step 500/600\n",
      "Train loss = 1.5464481115341187\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.18635215  0.31468102 -0.39771917], scale = 1.1135822534561157\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.509779214859009\n",
      "Valid F1 score = 0.9264990328820117\n",
      "Step 501/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 502/600\n",
      "Step 503/600\n",
      "Step 504/600\n",
      "Step 505/600\n",
      "Train loss = 1.2459635734558105\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.18411393  0.30757502 -0.38932532], scale = 1.1124820709228516\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 506/600\n",
      "Step 507/600\n",
      "Step 508/600\n",
      "Step 509/600\n",
      "Step 510/600\n",
      "Train loss = 1.2987754344940186\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.18407996  0.2891263  -0.3717035 ], scale = 1.1020244359970093\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.5032620429992676\n",
      "Valid F1 score = 0.9264990328820117\n",
      "Step 511/600\n",
      "Step 512/600\n",
      "Step 513/600\n",
      "Step 514/600\n",
      "Step 515/600\n",
      "Train loss = 1.6133664846420288\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.18668717  0.2621336  -0.3477414 ], scale = 1.090394377708435\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 516/600\n",
      "Step 517/600\n",
      "Step 518/600\n",
      "Step 519/600\n",
      "Step 520/600\n",
      "Train loss = 1.6805404424667358\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.19403125  0.24932215 -0.34082654], scale = 1.0858323574066162\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.4915225505828857\n",
      "Valid F1 score = 0.923226433430515\n",
      "Step 521/600\n",
      "Step 522/600\n",
      "Step 523/600\n",
      "Step 524/600\n",
      "Step 525/600\n",
      "Train loss = 1.1052980422973633\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.20050101  0.24224862 -0.3387671 ], scale = 1.0824018716812134\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 526/600\n",
      "Step 527/600\n",
      "Step 528/600\n",
      "Step 529/600\n",
      "Step 530/600\n",
      "Train loss = 2.485525608062744\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.20163861  0.24462236 -0.34210512], scale = 1.091786503791809\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.4911293983459473\n",
      "Valid F1 score = 0.923226433430515\n",
      "Step 531/600\n",
      "Step 532/600\n",
      "Step 533/600\n",
      "Step 534/600\n",
      "Step 535/600\n",
      "Train loss = 0.8156183958053589\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.20440677  0.24749945 -0.34720656], scale = 1.0943025350570679\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 536/600\n",
      "Step 537/600\n",
      "Step 538/600\n",
      "Step 539/600\n",
      "Step 540/600\n",
      "Train loss = 1.2538557052612305\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.21216393  0.24961954 -0.3555903 ], scale = 1.0951621532440186\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.489572525024414\n",
      "Valid F1 score = 0.9263565891472868\n",
      "Step 541/600\n",
      "Step 542/600\n",
      "Step 543/600\n",
      "Step 544/600\n",
      "Step 545/600\n",
      "Train loss = 1.0728249549865723\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.21562983  0.258082   -0.3667453 ], scale = 1.094611406326294\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 546/600\n",
      "Step 547/600\n",
      "Step 548/600\n",
      "Step 549/600\n",
      "Step 550/600\n",
      "Train loss = 0.8839434385299683\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.21707107  0.27004763 -0.37977138], scale = 1.1036564111709595\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.49280047416687\n",
      "Valid F1 score = 0.9273959341723137\n",
      "Step 551/600\n",
      "Step 552/600\n",
      "Step 553/600\n",
      "Step 554/600\n",
      "Step 555/600\n",
      "Train loss = 1.6063852310180664\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.2128989   0.2882209  -0.39442554], scale = 1.1101902723312378\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 556/600\n",
      "Step 557/600\n",
      "Step 558/600\n",
      "Step 559/600\n",
      "Step 560/600\n",
      "Train loss = 0.7224547863006592\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.2187505  0.3045595 -0.4153751], scale = 1.1105637550354004\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.4984183311462402\n",
      "Valid F1 score = 0.9264990328820117\n",
      "Step 561/600\n",
      "Step 562/600\n",
      "Step 563/600\n",
      "Step 564/600\n",
      "Step 565/600\n",
      "Train loss = 1.0264990329742432\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.23269212  0.3090998  -0.43119898], scale = 1.1050868034362793\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 566/600\n",
      "Step 567/600\n",
      "Step 568/600\n",
      "Step 569/600\n",
      "Step 570/600\n",
      "Train loss = 1.1052392721176147\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.24578421  0.3011655  -0.43404683], scale = 1.1000547409057617\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.486492872238159\n",
      "Valid F1 score = 0.9273959341723137\n",
      "Step 571/600\n",
      "Step 572/600\n",
      "Step 573/600\n",
      "Step 574/600\n",
      "Step 575/600\n",
      "Train loss = 1.32561457157135\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.26104632  0.27405596 -0.4195883 ], scale = 1.0761151313781738\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 576/600\n",
      "Step 577/600\n",
      "Step 578/600\n",
      "Step 579/600\n",
      "Step 580/600\n",
      "Train loss = 1.1113948822021484\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.2743938   0.24578665 -0.4023281 ], scale = 1.0450669527053833\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.4542300701141357\n",
      "Valid F1 score = 0.923226433430515\n",
      "Step 581/600\n",
      "Step 582/600\n",
      "Step 583/600\n",
      "Step 584/600\n",
      "Step 585/600\n",
      "Train loss = 0.6068696975708008\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.27095672  0.24007496 -0.39354888], scale = 1.0226445198059082\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 586/600\n",
      "Step 587/600\n",
      "Step 588/600\n",
      "Step 589/600\n",
      "Step 590/600\n",
      "Train loss = 1.3544039726257324\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.2672818   0.24178195 -0.39221293], scale = 1.0019423961639404\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.4426512718200684\n",
      "Valid F1 score = 0.9200779727095517\n",
      "Step 591/600\n",
      "Step 592/600\n",
      "Step 593/600\n",
      "Step 594/600\n",
      "Step 595/600\n",
      "Train loss = 0.8802889585494995\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.27043077  0.24681741 -0.40008038], scale = 0.9966632127761841\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 596/600\n",
      "Step 597/600\n",
      "Step 598/600\n",
      "Step 599/600\n",
      "Step 600/600\n",
      "Train loss = 1.816155195236206\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.2645646   0.26467493 -0.41366944], scale = 1.0198299884796143\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.449735641479492\n",
      "Valid F1 score = 0.923226433430515\n"
     ]
    }
   ],
   "source": [
    "num_steps = 300\n",
    "num_steps = np.sum([s['n_steps'] for s in training_schedule])\n",
    "stage = 0\n",
    "n_steps_prev_stages = 0\n",
    "n_steps_freeze_elmo = 100\n",
    "display_step = 5\n",
    "valid_step = 10\n",
    "losses = {'train': [], 'valid': []}\n",
    "f1_scores = {'train': [], 'valid': []}\n",
    "best_valid_f1 = 0\n",
    "d_elmo_cells_list = {'cell0':[], 'cell1':[]}\n",
    "for step in range(1, num_steps+1):\n",
    "    print('Step {}/{}'.format(step, num_steps))\n",
    "    #     train_op = train_op_all\n",
    "#     if step <= 100:\n",
    "#       train_op = train_op_model\n",
    "#     elif step > 100:\n",
    "#       train_op = train_op_elmo_coef\n",
    "#       learning_rate = 1e-2\n",
    "    if step > n_steps_prev_stages + training_schedule[stage]['n_steps']:\n",
    "      n_steps_prev_stages += training_schedule[stage]['n_steps']\n",
    "      stage += 1\n",
    "    train_op = training_schedule[stage]['train_op']\n",
    "    learning_rate = training_schedule[stage]['lr']\n",
    "    tokens_batch, tags_batch, mask_batch, y_batch = get_batch(dataset['train'], batch_size)\n",
    "    feed = fill_feed_dict({tokens_input_ph: tokens_batch, mask_ph: mask_batch, y_ph: y_batch, learning_rate_ph: learning_rate})\n",
    "    if TRAIN_ALL_ELMO_PARAMS:\n",
    "        cell0_kernel_val1 = cell0_kernel.eval(session=sess)\n",
    "        cell1_kernel_val1 = cell1_kernel.eval(session=sess)\n",
    "    # Train\n",
    "    with tf.variable_scope('', reuse=tf.AUTO_REUSE):\n",
    "        loss_cur, _ = sess.run([loss, train_op], feed_dict=feed)\n",
    "    losses['train'].append(loss_cur)\n",
    "    if TRAIN_ALL_ELMO_PARAMS:\n",
    "        cell0_kernel_val2 = cell0_kernel.eval(session=sess)\n",
    "        cell1_kernel_val2 = cell1_kernel.eval(session=sess)\n",
    "        d_cell0_kernel = np.linalg.norm(cell0_kernel_val2 - cell0_kernel_val1)/np.linalg.norm(cell0_kernel_val1)\n",
    "        d_cell1_kernel = np.linalg.norm(cell1_kernel_val2 - cell1_kernel_val1)/np.linalg.norm(cell1_kernel_val1)\n",
    "        d_elmo_cells_list['cell0'].append(d_cell0_kernel)\n",
    "        d_elmo_cells_list['cell1'].append(d_cell1_kernel)\n",
    "#     print('ELMo cells change per step: cell0: {}, cell1: {}'.format(d_cell0_kernel, d_cell1_kernel))\n",
    "    # Validate\n",
    "    with tf.variable_scope('', reuse=tf.AUTO_REUSE):\n",
    "        loss_valid = sess.run([loss], feed_dict=feed_valid)[0]\n",
    "        if use_crf:\n",
    "          pred = predict_crf(logits, transition_params, mask_ph, feed_dict=feed_valid)\n",
    "        else:\n",
    "          pred = predict_no_crf(y_pred, mask_ph, feed_dict=feed_valid)\n",
    "#         print(pred)\n",
    "        f1_valid = f1_score(flatten_with_mask(y_valid, mask_valid), concatenate_arrays(pred))\n",
    "        f1_scores['valid'].append(f1_valid)\n",
    "        if f1_valid > best_valid_f1:\n",
    "                best_valid_f1 = f1_valid\n",
    "    # Get elmo params\n",
    "    with tf.variable_scope('', reuse=tf.AUTO_REUSE):\n",
    "        if TRAIN_ELMO:\n",
    "            layer_coeff, scale = sess.run([elmo_coef['layer_coefficients'], elmo_coef['scaling']])\n",
    "            if f1_valid == best_valid_f1:\n",
    "                elmo_params_best = {'layer_coefficients': layer_coeff, 'scaling': scale}\n",
    "    losses['valid'].append(loss_valid)\n",
    "    if step % display_step == 0 or step == 1:\n",
    "        print('Train loss = {}'.format(losses['train'][-1]))\n",
    "#         print('Train F1 score = {}'.format(f1_scores['train'][-1]))\n",
    "        if TRAIN_ELMO:\n",
    "            with tf.variable_scope('', reuse=tf.AUTO_REUSE):\n",
    "                print('ELMo weights:')\n",
    "                print('Coefficients = {}, scale = {}'.format(layer_coeff, scale))\n",
    "        if TRAIN_ALL_ELMO_PARAMS:\n",
    "            print('ELMo cells change per step: cell0: {:.2f}%, cell1: {:.2f}%'.format(d_cell0_kernel*100, d_cell1_kernel*100))\n",
    "        \n",
    "    if step % valid_step == 0 or step == 1:\n",
    "        print('Valid loss = {}'.format(losses['valid'][-1]))\n",
    "        print('Valid F1 score = {}'.format(f1_scores['valid'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1753,
     "status": "ok",
     "timestamp": 1535545586777,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "FQ7egrqCkVvP",
    "outputId": "b8dd0ea6-0abd-41d9-c96a-2cfd58a3a62d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-30 13:22:03.427 DEBUG in 'matplotlib.font_manager'['font_manager'] at line 1346: findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/clement/virtenv/env/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000\n",
      "2018-08-30 13:22:03.456 DEBUG in 'matplotlib.font_manager'['font_manager'] at line 1346: findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/home/clement/virtenv/env/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curve\n",
    "plt.figure()\n",
    "steps = np.arange(1, num_steps+1, 1)\n",
    "plt.plot(steps, losses['train'], c='b', label='train')\n",
    "plt.plot(steps, losses['valid'], c='r', label='valid')\n",
    "plt.xlabel('iter')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.title('Learning curve')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1166,
     "status": "ok",
     "timestamp": 1535545588034,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "HP6PEVP2kVvX",
    "outputId": "eac6c929-5474-405b-a6bd-a79f004eebf6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot F1 scores\n",
    "plt.figure()\n",
    "steps = np.arange(1, num_steps+1, 1)\n",
    "# plt.plot(steps, losses['train'], c='b', label='train')\n",
    "plt.plot(steps, f1_scores['valid'], c='r', label='valid')\n",
    "plt.xlabel('iter')\n",
    "plt.ylabel('F1')\n",
    "plt.legend()\n",
    "plt.title('F1 score history')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17215,
     "status": "ok",
     "timestamp": 1535546169160,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "-gjNTl5a30Kq",
    "outputId": "d105c4ee-9d2a-4781-9ac3-8ce6668fbc1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: ./model_params/elmo.ckpt\n",
      "Whole model saved in path: ./model_params/model_all.ckpt\n"
     ]
    }
   ],
   "source": [
    "elmo_vars_dict = {v.name: v for v in elmo_vars}\n",
    "saver_elmo = tf.train.Saver(elmo_vars_dict)\n",
    "save_path = saver_elmo.save(sess, \"./model_params/elmo.ckpt\")\n",
    "print(\"Model saved in path: %s\" % save_path)\n",
    "saver_all = tf.train.Saver()\n",
    "save_path = saver_all.save(sess, \"./model_params/model_all.ckpt\")\n",
    "print(\"Whole model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 770,
     "status": "ok",
     "timestamp": 1535545690575,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "K0rCZm5-EUCF",
    "outputId": "fe32d684-2e3b-4d78-f2e8-b6a288b1c8c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score on validation: 93.90\n",
      "Learned ELMo layer combination weights:\n",
      "[1.3286994 1.328846  0.6743314]\n",
      "Normalized:\n",
      "[0.39683846 0.39689666 0.20626491]\n"
     ]
    }
   ],
   "source": [
    "print('Best F1 score on validation: {:.2f}'.format(best_valid_f1*100))\n",
    "if TRAIN_ELMO:\n",
    "    layer_coeff, scale = sess.run([elmo_coef['layer_coefficients'], elmo_coef['scaling']])\n",
    "    elmo_params = {'layer_coefficients': layer_coeff, 'scaling': scale}\n",
    "    elmo_layer_coeff = np.exp(elmo_params['layer_coefficients'])*elmo_params['scaling']\n",
    "    print('Learned ELMo layer combination weights:')\n",
    "    print(elmo_layer_coeff)\n",
    "    print('Normalized:')\n",
    "    print(np.exp(elmo_layer_coeff)/np.sum(np.exp(elmo_layer_coeff)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 998,
     "status": "ok",
     "timestamp": 1535545607928,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "CBYNbQdkIo5B",
    "outputId": "3120e7be-0703-4fe5-b7b2-b46ccd32f63e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0' shape=(1024, 16384) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0' shape=(16384,) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0' shape=(4096, 512) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0' shape=(1024, 16384) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0' shape=(16384,) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0' shape=(4096, 512) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0' shape=(1024, 16384) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0' shape=(16384,) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0' shape=(4096, 512) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0' shape=(1024, 16384) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0' shape=(16384,) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0' shape=(4096, 512) dtype=float32>,\n",
       " <tf.Variable 'module/aggregation/weights:0' shape=(3,) dtype=float32>,\n",
       " <tf.Variable 'module/aggregation/scaling:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0' shape=(1024, 16384) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0' shape=(16384,) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0' shape=(4096, 512) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0' shape=(1024, 16384) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0' shape=(16384,) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0' shape=(4096, 512) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0' shape=(1024, 16384) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0' shape=(16384,) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0' shape=(4096, 512) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0' shape=(1024, 16384) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0' shape=(16384,) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0' shape=(4096, 512) dtype=float32>,\n",
       " <tf.Variable 'module/aggregation/weights:0' shape=(3,) dtype=float32>,\n",
       " <tf.Variable 'module/aggregation/scaling:0' shape=() dtype=float32>,\n",
       " <tf.Variable 'Layer_0_LSTM/bidirectional_rnn/fw/lstm_cell/kernel:0' shape=(1152, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'Layer_0_LSTM/bidirectional_rnn/fw/lstm_cell/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Layer_0_LSTM/bidirectional_rnn/bw/lstm_cell/kernel:0' shape=(1152, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'Layer_0_LSTM/bidirectional_rnn/bw/lstm_cell/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/kernel:0' shape=(256, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/bias:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'transitions:0' shape=(2, 2) dtype=float32_ref>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_dict = {v.name:v for v in tf.trainable_variables()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions_var = vars_dict['transitions:0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions_val = transitions_var.eval(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6304114  0.36958855]\n",
      " [0.3566413  0.6433587 ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.exp(transitions_val)/np.sum(np.exp(transitions_val), axis=1).reshape((transitions_val.shape[0],1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4837615 , 0.8698784 ],\n",
       "       [0.33391827, 0.6023678 ]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(transitions_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.35364  , 0.9362861], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.exp(transitions_val), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "12. Finetune ELMo all params.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
