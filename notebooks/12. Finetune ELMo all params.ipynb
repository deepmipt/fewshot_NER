{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4827,
     "status": "ok",
     "timestamp": 1535232984250,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "TGMe-jsfltAb",
    "outputId": "32c4ed95-8ed6-4081-be43-27745032c6c5"
   },
   "outputs": [],
   "source": [
    "# For google colab\n",
    "# ! pip install deeppavlov\n",
    "# ! pip install pybind11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZAO73sarkVsk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-27 15:41:24.465 DEBUG in 'matplotlib.backends'['__init__'] at line 90: backend module://ipykernel.pylab.backend_inline version unknown\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from typing import *\n",
    "import copy\n",
    "from deeppavlov.dataset_readers.ontonotes_reader import OntonotesReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vp1-KZjakVs_"
   },
   "outputs": [],
   "source": [
    "TRAIN_ELMO = True\n",
    "TRAIN_ALL_ELMO_PARAMS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B-LqcN-EkVtF"
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    reader = OntonotesReader()\n",
    "    dataset = reader.read(data_path='data/')\n",
    "    # print(dataset.keys())\n",
    "    print('Num of train sentences: {}'.format(len(dataset['train'])))\n",
    "    print('Num of valid sentences: {}'.format(len(dataset['valid'])))\n",
    "    print('Num of test sentences: {}'.format(len(dataset['test'])))\n",
    "    print(dataset['train'][50:60])\n",
    "    return dataset\n",
    "\n",
    "def filter_data_by_ne_type(data:list, ne_types:list, tags2binary=False, preserveBIO=False, keepIfAny=True):\n",
    "    if ne_types == None or len(ne_types) == 0:\n",
    "        return data\n",
    "    data_filtered = []\n",
    "    for tokens,tags in data:\n",
    "        contains_all = True\n",
    "        contains_any = False\n",
    "        tags_norm = [getNeTagMainPart(t) for t in tags]\n",
    "        for ne_type in ne_types:\n",
    "            if not ne_type in tags_norm:\n",
    "                contains_all = False\n",
    "            if ne_type in tags_norm:\n",
    "                contains_any = True\n",
    "        if contains_all or (keepIfAny and contains_any):\n",
    "            if tags2binary:\n",
    "                if preserveBIO:\n",
    "                    tags = [tags[i][:2]+'T' if t in ne_types else 'O' for i,t in enumerate(tags_norm)]\n",
    "                else:\n",
    "                    tags = ['T' if t in ne_types else 'O' for t in tags_norm]\n",
    "            data_filtered.append((tokens,tags))\n",
    "    return data_filtered\n",
    "\n",
    "def filter_dataset_by_ne_types(dataset: list, ne_types, preserveBIO=False, keepIfAny=True):\n",
    "    dataset = copy.deepcopy(dataset)\n",
    "    if not isinstance(ne_types, list):\n",
    "        ne_types = [ne_types]\n",
    "    for dataset_type in ['train', 'valid', 'test']:\n",
    "        dataset[dataset_type] = filter_data_by_ne_type(dataset[dataset_type], ne_types, preserveBIO=preserveBIO, tags2binary=True)\n",
    "        print('Num of {} sentences: {}'.format(dataset_type, len(dataset[dataset_type])))\n",
    "    return dataset\n",
    "\n",
    "def get_data_sample(data, n_samples: int):\n",
    "    indices = np.random.choice(len(data), size=n_samples, replace=False)\n",
    "    return split_tokens_tags([data[i] for i in indices])\n",
    "\n",
    "def get_tokens_len(tokens):\n",
    "    if isinstance(tokens[0], str):\n",
    "        tokens = [tokens]\n",
    "    return [len(seq) for seq in tokens]\n",
    "\n",
    "def to_lower_case(tokens:list):\n",
    "    tokens_lower = []\n",
    "    for seq in tokens:\n",
    "        tokens_lower.append([])\n",
    "        for token in seq:\n",
    "            tokens_lower[-1].append(token.lower())\n",
    "    return tokens_lower\n",
    "\n",
    "def add_padding(tokens:list):\n",
    "    if isinstance(tokens[0], str):\n",
    "        return tokens, len(tokens)\n",
    "    elif isinstance(tokens[0], list):\n",
    "        tokens = copy.deepcopy(tokens)\n",
    "        max_len = 0\n",
    "        for seq in tokens:\n",
    "            if len(seq) > max_len:\n",
    "                max_len = len(seq)\n",
    "        for seq in tokens:\n",
    "            i = len(seq)\n",
    "            while i < max_len:\n",
    "                seq.append('')\n",
    "                i += 1\n",
    "        return tokens\n",
    "    else:\n",
    "        raise Exception('tokens should be either list of strings or list of lists of strings')\n",
    "  \n",
    "def getNeTagMainPart(tag:str):\n",
    "    return tag[2:] if tag != 'O' else tag\n",
    "\n",
    "def tags2binaryFlat(tags):\n",
    "    return np.array([1 if t == 'T' or (len(t) > 2 and t[2:] == 'T') else 0 for seq in tags for t in seq])\n",
    "\n",
    "def tags2binaryPadded(tags:list):\n",
    "    if isinstance(tags[0], str):\n",
    "        tags = [tags]\n",
    "    n_sentences = len(tags)\n",
    "    tokens_length = get_tokens_len(tags)\n",
    "    max_len = np.max(tokens_length)\n",
    "    tokens_length = np.tile(np.expand_dims(tokens_length, -1), (1,max_len))\n",
    "    y = np.zeros((n_sentences, max_len))\n",
    "    range_ar = np.tile(np.arange(1, max_len+1, 1), (n_sentences, 1))\n",
    "    for i, sen in enumerate(tags):\n",
    "        for j, tag in enumerate(sen):\n",
    "            if tags[i][j] != 'O':\n",
    "                y[i][j] = 1\n",
    "#     y[range_ar > tokens_length] = -1\n",
    "    return y\n",
    "\n",
    "def get_matrices(tokens, tags, embedder):\n",
    "    return (embeddings2feat_mat(embedder.embed(tokens), get_tokens_len(tokens)),\n",
    "           tags2binaryFlat(tags))\n",
    "  \n",
    "def split_tokens_tags(dataset: list):\n",
    "    tokens = []\n",
    "    tags = []\n",
    "    for sample in dataset:\n",
    "        tokens.append(sample[0])\n",
    "        tags.append(sample[1])\n",
    "    return tokens, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7851,
     "status": "ok",
     "timestamp": 1535232994629,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "n-ETiotSkVtL",
    "outputId": "eef374a8-8cc3-401b-aeb4-3762483049ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of train sentences: 75187\n",
      "Num of valid sentences: 9603\n",
      "Num of test sentences: 9479\n",
      "[(['Actions', 'had', 'to', 'be', 'taken', 'to', 'break', 'through', 'the', 'blockade', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['On', 'a', 'night', 'in', 'late', 'July', '1940', ',', 'the', 'atmosphere', 'in', 'Zhuanbi', 'Village', 'in', 'Shaanxi', 'was', 'unusual', '.'], ['O', 'B-DATE', 'I-DATE', 'I-DATE', 'I-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'B-GPE', 'O', 'O', 'O']), (['Villager', 'Xiao', 'Jianghe', 'has', 'a', 'vivid', 'memory', 'of', 'this', 'piece', 'of', 'history', '.'], ['O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['On', 'that', 'dark', 'night', ',', 'everyone', 'was', 'sleeping', 'when', 'human', 'voices', 'and', 'neighing', 'horses', 'were', 'heard', 'within', 'the', 'village', '.'], ['O', 'B-TIME', 'I-TIME', 'I-TIME', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['People', 'all', 'got', 'up', '.'], ['O', 'O', 'O', 'O', 'O']), (['Did', 'something', 'happen', '?'], ['O', 'O', 'O', 'O']), (['Some', 'folks', 'got', 'up', '.'], ['O', 'O', 'O', 'O', 'O']), (['Opening', 'the', 'street', 'gate', ',', 'they', 'saw', 'a', 'soldier', 'standing', 'by', 'the', 'gate', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['Folks', ',', 'go', 'back', ',', 'go', 'back', ',', 'nothing', 'is', 'wrong', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['Our', 'troops', 'are', 'just', 'going', 'to', 'stay', 'here', 'for', 'the', 'night', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'])]\n",
      "Num of train sentences: 27582\n",
      "Num of valid sentences: 3826\n",
      "Num of test sentences: 3836\n",
      "Number of sentences in filtered dataset: train: 27582, valid: 3826, test: 3836\n"
     ]
    }
   ],
   "source": [
    "dataset_orig = read_data()\n",
    "# ne_type = 'PERSON'\n",
    "ne_types = ['GPE','DATE','ORG','EVENT','LOC','FAC','CARDINAL','QUANTITY','NORP','ORDINAL','WORK_OF_ART']\n",
    "# dataset = {'train':[], 'valid':[], 'test':[]}\n",
    "# for ne_type in ne_types:\n",
    "#     print(ne_type)\n",
    "#     dataset_cur = filter_dataset_by_ne_types(dataset_orig, ne_type)\n",
    "#     for k in dataset.keys():\n",
    "#         dataset[k].extend(dataset_cur[k])\n",
    "dataset = filter_dataset_by_ne_types(dataset_orig, ne_types, keepIfAny=True)\n",
    "print('Number of sentences in filtered dataset: train: {}, valid: {}, test: {}'.format(len(dataset['train']), len(dataset['valid']), len(dataset['test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dataset['train'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GpR6E_l8kVtW"
   },
   "outputs": [],
   "source": [
    "INITIALIZER = tf.contrib.layers.xavier_initializer\n",
    "\n",
    "def bi_rnn(units: tf.Tensor,\n",
    "           n_hidden: List,\n",
    "           cell_type='gru',\n",
    "           seq_lengths=None,\n",
    "           trainable_initial_states=False,\n",
    "           use_peepholes=False,\n",
    "           name='Bi-'):\n",
    "    \"\"\" Bi directional recurrent neural network. GRU or LSTM\n",
    "\n",
    "        Args:\n",
    "            units: a tensorflow tensor with dimensionality [None, n_tokens, n_features]\n",
    "            n_hidden_list: list with number of hidden units at the ouput of each layer\n",
    "            seq_lengths: length of sequences for different length sequences in batch\n",
    "                can be None for maximum length as a length for every sample in the batch\n",
    "            cell_type: 'lstm' or 'gru'\n",
    "            trainable_initial_states: whether to create a special trainable variable\n",
    "                to initialize the hidden states of the network or use just zeros\n",
    "            use_peepholes: whether to use peephole connections (only 'lstm' case affected)\n",
    "            name: what variable_scope to use for the network parameters\n",
    "            add_l2_losses: whether to add l2 losses on network kernels to\n",
    "                tf.GraphKeys.REGULARIZATION_LOSSES or not\n",
    "        Returns:\n",
    "            units: tensor at the output of the last recurrent layer\n",
    "                with dimensionality [None, n_tokens, n_hidden_list[-1]]\n",
    "            last_units: tensor of last hidden states for GRU and tuple\n",
    "                of last hidden stated and last cell states for LSTM\n",
    "                dimensionality of cell states and hidden states are\n",
    "                similar and equal to [B x 2 * H], where B - batch\n",
    "                size and H is number of hidden units\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.variable_scope(name + '_' + cell_type.upper()):\n",
    "        if cell_type == 'gru':\n",
    "            forward_cell = tf.nn.rnn_cell.GRUCell(n_hidden, kernel_initializer=INITIALIZER())\n",
    "            backward_cell = tf.nn.rnn_cell.GRUCell(n_hidden, kernel_initializer=INITIALIZER())\n",
    "            if trainable_initial_states:\n",
    "                initial_state_fw = tf.tile(tf.get_variable('init_fw_h', [1, n_hidden]), (tf.shape(units)[0], 1))\n",
    "                initial_state_bw = tf.tile(tf.get_variable('init_bw_h', [1, n_hidden]), (tf.shape(units)[0], 1))\n",
    "            else:\n",
    "                initial_state_fw = initial_state_bw = None\n",
    "        elif cell_type == 'lstm':\n",
    "            forward_cell = tf.nn.rnn_cell.LSTMCell(n_hidden, use_peepholes=use_peepholes, initializer=INITIALIZER())\n",
    "            backward_cell = tf.nn.rnn_cell.LSTMCell(n_hidden, use_peepholes=use_peepholes, initializer=INITIALIZER())\n",
    "            if trainable_initial_states:\n",
    "                initial_state_fw = tf.nn.rnn_cell.LSTMStateTuple(\n",
    "                    tf.tile(tf.get_variable('init_fw_c', [1, n_hidden]), (tf.shape(units)[0], 1)),\n",
    "                    tf.tile(tf.get_variable('init_fw_h', [1, n_hidden]), (tf.shape(units)[0], 1)))\n",
    "                initial_state_bw = tf.nn.rnn_cell.LSTMStateTuple(\n",
    "                    tf.tile(tf.get_variable('init_bw_c', [1, n_hidden]), (tf.shape(units)[0], 1)),\n",
    "                    tf.tile(tf.get_variable('init_bw_h', [1, n_hidden]), (tf.shape(units)[0], 1)))\n",
    "            else:\n",
    "                initial_state_fw = initial_state_bw = None\n",
    "        else:\n",
    "            raise RuntimeError('cell_type must be either \"gru\" or \"lstm\"s')\n",
    "        (rnn_output_fw, rnn_output_bw), (fw, bw) = \\\n",
    "            tf.nn.bidirectional_dynamic_rnn(forward_cell,\n",
    "                                            backward_cell,\n",
    "                                            units,\n",
    "                                            dtype=tf.float32,\n",
    "                                            sequence_length=seq_lengths,\n",
    "                                            initial_state_fw=initial_state_fw,\n",
    "                                            initial_state_bw=initial_state_bw)\n",
    "    kernels = [var for var in forward_cell.trainable_variables +\n",
    "               backward_cell.trainable_variables if 'kernel' in var.name]\n",
    "    for kernel in kernels:\n",
    "        tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, tf.nn.l2_loss(kernel))\n",
    "    return (rnn_output_fw, rnn_output_bw), (fw, bw)\n",
    "\n",
    "def build_cudnn_rnn(units, mask, n_hidden_list:Tuple[int]=(128,), cell_type:str='lstm', intra_layer_dropout:bool=False, dropout_ph=None):\n",
    "    sequence_lengths = tf.to_int32(tf.reduce_sum(mask, axis=1))\n",
    "    for n, n_hidden in enumerate(n_hidden_list):\n",
    "        with tf.variable_scope(cell_type.upper() + '_' + str(n)):\n",
    "            if cell_type.lower() == 'lstm':\n",
    "                units, _ = cudnn_bi_lstm(units, n_hidden, sequence_lengths)\n",
    "            elif cell_type.lower() == 'gru':\n",
    "                units, _ = cudnn_bi_gru(units, n_hidden, sequence_lengths)\n",
    "            else:\n",
    "                raise RuntimeError('Wrong cell type \"{}\"! Only \"gru\" and \"lstm\"!'.format(cell_type))\n",
    "            units = tf.concat(units, -1)\n",
    "            if intra_layer_dropout and n != len(n_hidden_list) - 1:\n",
    "                units = variational_dropout(units, dropout_ph)\n",
    "    return units\n",
    "\n",
    "def build_rnn(units, n_hidden_list:Tuple[int]=(128,), cell_type:str='lstm', intra_layer_dropout:bool=False, dropout_ph=None):\n",
    "    for n, n_hidden in enumerate(n_hidden_list):\n",
    "        units, _ = bi_rnn(units, n_hidden, cell_type=cell_type, name='Layer_' + str(n))\n",
    "        units = tf.concat(units, -1)\n",
    "        if intra_layer_dropout and n != len(n_hidden_list) - 1:\n",
    "            units = variational_dropout(units, dropout_ph)\n",
    "    return units\n",
    "\n",
    "def build_top(units, n_tags=1, top_dropout:bool=False, two_dense_on_top:bool=False, n_hidden=128):\n",
    "    if top_dropout:\n",
    "        units = variational_dropout(units, dropout_ph)\n",
    "    if two_dense_on_top:\n",
    "        units = tf.layers.dense(units, n_hidden, activation=tf.nn.relu,\n",
    "                                kernel_initializer=INITIALIZER(),\n",
    "                                kernel_regularizer=tf.nn.l2_loss)\n",
    "    logits = tf.layers.dense(units, n_tags, activation=None,\n",
    "                             kernel_initializer=INITIALIZER(),\n",
    "                             kernel_regularizer=tf.nn.l2_loss)\n",
    "    return logits\n",
    "\n",
    "def build_train_predict(logits, n_tags, mask, y_ph, use_crf, learning_rate_ph, clip_grad_norm, l2_reg):\n",
    "    res = {}\n",
    "    if use_crf:\n",
    "        sequence_lengths = tf.reduce_sum(mask, axis=1)\n",
    "        log_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood(logits, y_ph, sequence_lengths)\n",
    "        loss_tensor = -log_likelihood\n",
    "        res['transition_params'] = transition_params\n",
    "    else:\n",
    "        ground_truth_labels = tf.one_hot(y_ph, n_tags)\n",
    "        loss_tensor = tf.nn.softmax_cross_entropy_with_logits(labels=ground_truth_labels, logits=logits)\n",
    "        loss_tensor = loss_tensor * mask\n",
    "        y_pred = tf.argmax(logits, axis=-1)\n",
    "        res['y_pred'] = y_pred\n",
    "\n",
    "    loss = tf.reduce_mean(loss_tensor)\n",
    "\n",
    "    # L2 regularization\n",
    "    if l2_reg > 0:\n",
    "        loss += l2_reg * tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "    res['loss'] = loss\n",
    "        \n",
    "    # optimizer = partial(tf.train.MomentumOptimizer, momentum=0.9, use_nesterov=True)\n",
    "    optimizer = tf.train.AdamOptimizer\n",
    "    train_op = get_train_op(loss, learning_rate_ph, optimizer, clip_norm=clip_grad_norm)\n",
    "    res['train_op'] = train_op\n",
    "    return res\n",
    "\n",
    "def predict_no_crf(y_pred, mask_ph, feed_dict):\n",
    "    pred_idxs, mask = sess.run([y_pred, mask_ph], feed_dict)\n",
    "\n",
    "    # Filter by sequece length\n",
    "    sequence_lengths = np.sum(mask, axis=1).astype(np.int32)\n",
    "    pred = []\n",
    "    for utt, l in zip(pred_idxs, sequence_lengths):\n",
    "        pred.append(utt[:l])\n",
    "    return pred\n",
    "\n",
    "def predict_crf(logits, transition_params, mask_ph, feed_dict):\n",
    "    logits, trans_params, mask = sess.run([logits,\n",
    "                                           transition_params,\n",
    "                                           mask_ph],\n",
    "                                           feed_dict=feed_dict)\n",
    "    sequence_lengths = np.maximum(np.sum(mask, axis=1).astype(np.int32), 1)\n",
    "    # iterate over the sentences because no batching in viterbi_decode\n",
    "    pred = []\n",
    "    for logit, sequence_length in zip(logits, sequence_lengths):\n",
    "        logit = logit[:int(sequence_length)]  # keep only the valid steps\n",
    "        viterbi_seq, viterbi_score = tf.contrib.crf.viterbi_decode(logit, trans_params)\n",
    "        pred += [viterbi_seq]\n",
    "    return pred\n",
    "\n",
    "def get_train_op(loss,\n",
    "                 learning_rate,\n",
    "                 optimizer=None,\n",
    "                 clip_norm=None,\n",
    "                 learnable_scopes=None,\n",
    "                 optimizer_scope_name=None,\n",
    "                 trainable_vars:list=None):\n",
    "    \"\"\" Get train operation for given loss\n",
    "\n",
    "    Args:\n",
    "        loss: loss, tf tensor or scalar\n",
    "        learning_rate: scalar or placeholder\n",
    "        clip_norm: clip gradients norm by clip_norm\n",
    "        learnable_scopes: which scopes are trainable (None for all)\n",
    "        optimizer: instance of tf.train.Optimizer, default Adam\n",
    "\n",
    "    Returns:\n",
    "        train_op\n",
    "    \"\"\"\n",
    "    if optimizer_scope_name is None:\n",
    "        opt_scope = tf.variable_scope('Optimizer')\n",
    "    else:\n",
    "        opt_scope = tf.variable_scope(optimizer_scope_name)\n",
    "    with opt_scope:\n",
    "        if learnable_scopes is None:\n",
    "            variables_to_train = tf.global_variables()\n",
    "        else:\n",
    "            variables_to_train = []\n",
    "            for scope_name in learnable_scopes:\n",
    "                for var in tf.global_variables():\n",
    "                    if scope_name in var.name:\n",
    "                        variables_to_train.append(var)\n",
    "        if trainable_vars:\n",
    "            variables_to_train = trainable_vars\n",
    "            \n",
    "        if optimizer is None:\n",
    "            optimizer = tf.train.AdamOptimizer\n",
    "\n",
    "        # For batch norm it is necessary to update running averages\n",
    "        extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(extra_update_ops):\n",
    "            opt = optimizer(learning_rate)\n",
    "            grads_and_vars = opt.compute_gradients(loss, var_list=variables_to_train)\n",
    "            if clip_norm is not None:\n",
    "                grads_and_vars = [(tf.clip_by_norm(grad, clip_norm), var)\n",
    "                                  for grad, var in grads_and_vars] #  if grad is not None\n",
    "            train_op = opt.apply_gradients(grads_and_vars)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o0RyP1tMkVtc"
   },
   "outputs": [],
   "source": [
    "def predict_labels(prob: np.ndarray, threshold=0.5):\n",
    "    labels = np.zeros(prob.shape)\n",
    "    labels[prob > threshold] = 1\n",
    "    return labels\n",
    "def flat_array(a: np.ndarray):\n",
    "#     return np.reshape(a, a.size)\n",
    "    return a.flatten()\n",
    "def calc_f1(y, pred_prob):\n",
    "    return f1_score(flat_array(y), flat_array(predict_labels(pred_prob)))\n",
    "def tags2binaryPadded(tags:list):\n",
    "    if isinstance(tags[0], str):\n",
    "        tags = [tags]\n",
    "    n_sentences = len(tags)\n",
    "    tokens_length = get_tokens_len(tags)\n",
    "    max_len = np.max(tokens_length)\n",
    "    tokens_length = np.tile(np.expand_dims(tokens_length, -1), (1,max_len))\n",
    "    y = np.zeros((n_sentences, max_len))\n",
    "    range_ar = np.tile(np.arange(1, max_len+1, 1), (n_sentences, 1))\n",
    "    for i, sen in enumerate(tags):\n",
    "        for j, tag in enumerate(sen):\n",
    "            if tags[i][j] != 'O':\n",
    "                y[i][j] = 1\n",
    "    return y\n",
    "def get_batch(dataset, batch_size=None):\n",
    "    if not batch_size:\n",
    "        batch_size = len(dataset)\n",
    "    tokens, tags = get_data_sample(dataset, batch_size)\n",
    "    mask = make_mask(tokens)\n",
    "    tokens_length = get_tokens_len(tokens)\n",
    "    tokens = add_padding(tokens)\n",
    "    y = tags2binaryPadded(tags)\n",
    "    return tokens, tags, mask, y\n",
    "\n",
    "def make_mask(seq_list):\n",
    "  seq_count = len(seq_list)\n",
    "  seq_length = [len(s) for s in seq_list]\n",
    "  max_len = np.max(seq_length)\n",
    "  mask = np.zeros((seq_count, max_len), dtype=int)\n",
    "  seq_length = np.tile(np.expand_dims(seq_length, axis=-1), (1, max_len))\n",
    "  range_ar = np.tile(np.arange(1, max_len+1, 1), (seq_count, 1))\n",
    "  mask[range_ar <= seq_length] = 1\n",
    "  return mask\n",
    "\n",
    "def flatten_with_mask(seq_mat, mask):\n",
    "  return seq_mat[mask == 1]\n",
    "\n",
    "def concatenate_arrays(ar_list):\n",
    "  return np.concatenate(ar_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SmlxreyYkVtk"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sa6asbyOkVtr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-27 15:41:29.952 INFO in 'tensorflow'['tf_logging'] at line 159: Using /tmp/tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/1\", trainable=TRAIN_ELMO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 479,
     "status": "ok",
     "timestamp": 1535232999916,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "DH-BhVEqkVt5",
    "outputId": "a90b1378-0f79-447b-c958-09f9bab2a328"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0' shape=(1024, 16384) dtype=float32>, <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0' shape=(16384,) dtype=float32>, <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0' shape=(4096, 512) dtype=float32>, <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0' shape=(1024, 16384) dtype=float32>, <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0' shape=(16384,) dtype=float32>, <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0' shape=(4096, 512) dtype=float32>, <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0' shape=(1024, 16384) dtype=float32>, <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0' shape=(16384,) dtype=float32>, <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0' shape=(4096, 512) dtype=float32>, <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0' shape=(1024, 16384) dtype=float32>, <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0' shape=(16384,) dtype=float32>, <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0' shape=(4096, 512) dtype=float32>, <tf.Variable 'module/aggregation/weights:0' shape=(3,) dtype=float32>, <tf.Variable 'module/aggregation/scaling:0' shape=() dtype=float32>]\n",
      "{'layer_coefficients': <tf.Variable 'module/aggregation/weights:0' shape=(3,) dtype=float32>, 'scaling': <tf.Variable 'module/aggregation/scaling:0' shape=() dtype=float32>}\n"
     ]
    }
   ],
   "source": [
    "print(tf.trainable_variables())\n",
    "if(TRAIN_ELMO):\n",
    "    elmo_coef = {'layer_coefficients': tf.trainable_variables()[-2], 'scaling': tf.trainable_variables()[-1]}\n",
    "    print(elmo_coef)\n",
    "elmo_vars = tf.trainable_variables()\n",
    "elmo_vars_coef = list(elmo_coef.values())\n",
    "elmo_vars_cell_weights = [v for v in elmo_vars if v not in elmo_vars_coef]\n",
    "vars_dict = {v.name:v for v in tf.trainable_variables()}\n",
    "if TRAIN_ALL_ELMO_PARAMS:\n",
    "    cell0_kernel = vars_dict['module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0']\n",
    "    cell1_kernel = vars_dict['module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2f2m5Ud0kVuC"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "use_cudnn_rnn = False\n",
    "l2_reg = 0\n",
    "n_hidden_list = (128,)\n",
    "cell_type = 'lstm'\n",
    "n_tags = 2\n",
    "use_crf = True\n",
    "clip_grad_norm = 5.0\n",
    "learning_rate = 1e-3\n",
    "dropout_keep_prob = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sr78klsHkVuI"
   },
   "source": [
    "### Build computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z51-uX6xkVuK"
   },
   "outputs": [],
   "source": [
    "# Placeholders\n",
    "tokens_input_ph = tf.placeholder(shape=[None, None], dtype=tf.string)\n",
    "# tokens_length_ph = tf.placeholder(shape=[None], dtype=tf.int32)\n",
    "mask_ph = tf.placeholder(tf.float32, [None, None], name='Mask_ph')\n",
    "y_ph = tf.placeholder(shape=[None, None], dtype=tf.int32, name='y_ph')\n",
    "learning_rate_ph = tf.placeholder_with_default(learning_rate, shape=[], name='learning_rate')\n",
    "dropout_ph = tf.placeholder_with_default(dropout_keep_prob, shape=[], name='dropout')\n",
    "training_ph = tf.placeholder_with_default(False, shape=[], name='is_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z1Q0wS-x-866"
   },
   "outputs": [],
   "source": [
    "def fill_feed_dict(inp: dict, train=True):\n",
    "  feed_dict = {learning_rate_ph: learning_rate, dropout_ph: dropout_keep_prob if train else 1.0, training_ph: train}\n",
    "  feed_dict.update(inp)\n",
    "  return feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7912,
     "status": "ok",
     "timestamp": 1535233010343,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "_jTTCTq1kVuQ",
    "outputId": "46a4fa47-9432-488a-a4db-265de8e2c1e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-27 15:41:30.671 INFO in 'tensorflow'['tf_logging'] at line 115: Saver not created because there are no variables in the graph to restore\n",
      "/home/clement/virtenv/env/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "y_pred = None\n",
    "transition_params = None\n",
    "tokens_length = tf.to_int32(tf.reduce_sum(mask_ph, axis=1))\n",
    "emb = elmo(inputs={\"tokens\": tokens_input_ph,\n",
    "                    \"sequence_len\": tokens_length},\n",
    "                  signature=\"tokens\",\n",
    "                  as_dict=True)['elmo']\n",
    "# mask = tf.sequence_mask(lengths=tokens_length_ph, dtype=tf.float32)\n",
    "features = emb\n",
    "if use_cudnn_rnn:\n",
    "    units = build_cudnn_rnn(features, mask_ph, n_hidden_list, cell_type)\n",
    "else:\n",
    "    units = build_rnn(features, n_hidden_list, cell_type)\n",
    "\n",
    "logits = build_top(units, n_tags=n_tags)\n",
    "\n",
    "out_dict = build_train_predict(logits, n_tags, mask_ph, y_ph, use_crf, learning_rate_ph, clip_grad_norm, l2_reg)\n",
    "train_op_all = out_dict['train_op']\n",
    "loss = out_dict['loss']\n",
    "if use_crf:\n",
    "    transition_params = out_dict['transition_params']\n",
    "else:\n",
    "    y_pred = out_dict['y_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 510,
     "status": "ok",
     "timestamp": 1535233011008,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "qgSrNRNRkVuZ",
    "outputId": "bcbbc40d-c7ae-4223-b296-97f5bb00db32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'Layer_0_LSTM/bidirectional_rnn/fw/lstm_cell/kernel:0' shape=(1152, 512) dtype=float32_ref>, <tf.Variable 'Layer_0_LSTM/bidirectional_rnn/fw/lstm_cell/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'Layer_0_LSTM/bidirectional_rnn/bw/lstm_cell/kernel:0' shape=(1152, 512) dtype=float32_ref>, <tf.Variable 'Layer_0_LSTM/bidirectional_rnn/bw/lstm_cell/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'dense/kernel:0' shape=(256, 2) dtype=float32_ref>, <tf.Variable 'dense/bias:0' shape=(2,) dtype=float32_ref>, <tf.Variable 'transitions:0' shape=(2, 2) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "all_vars = tf.trainable_variables()\n",
    "model_vars = [v for v in all_vars if v not in elmo_vars]\n",
    "print(model_vars)\n",
    "vars_dict = {v.name:v for v in tf.trainable_variables()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clement/virtenv/env/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "# Optimizers for different parameters\n",
    "with tf.variable_scope('Optimizer', reuse=tf.AUTO_REUSE):\n",
    "    train_op_model = get_train_op(loss, learning_rate_ph, tf.train.AdamOptimizer, clip_norm=clip_grad_norm, trainable_vars=model_vars)\n",
    "    train_op_elmo = get_train_op(loss, learning_rate_ph, tf.train.AdamOptimizer, clip_norm=clip_grad_norm, trainable_vars=elmo_vars)\n",
    "    train_op_elmo_coef = get_train_op(loss, learning_rate_ph, tf.train.AdamOptimizer, clip_norm=clip_grad_norm, trainable_vars=elmo_vars_coef)\n",
    "    train_op_elmo_cell_weights = get_train_op(loss, learning_rate_ph, tf.train.AdamOptimizer, clip_norm=clip_grad_norm, trainable_vars=elmo_vars_cell_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter('./graph/bilstm_crf_elmo', tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlqOMRZ_kVuf"
   },
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3858,
     "status": "ok",
     "timestamp": 1535233015221,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "YsCb3L9xkVui",
    "outputId": "b22fbb63-128a-4323-8168-427037448019"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_op = tf.global_variables_initializer()\n",
    "sess.run([initialize_op])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCPpR5VpkVu_"
   },
   "outputs": [],
   "source": [
    "valid_sen_size = 100\n",
    "tokens_valid, tags_valid, mask_valid, y_valid = get_batch(dataset['valid'], valid_sen_size)\n",
    "feed_valid = fill_feed_dict({tokens_input_ph: tokens_valid, mask_ph: mask_valid, y_ph: y_valid, training_ph: False}, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7103
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1573232,
     "status": "ok",
     "timestamp": 1535234589826,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "ab6-6mpDkVvF",
    "outputId": "39027a9a-1050-4e3d-cad0-7ee2d5ce450f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1/400\n",
      "Train loss = 14.164755821228027\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 10.263768196105957\n",
      "Valid F1 score = 0.0\n",
      "Step 2/400\n",
      "Step 3/400\n",
      "Step 4/400\n",
      "Step 5/400\n",
      "Train loss = 6.202993392944336\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 6/400\n",
      "Step 7/400\n",
      "Step 8/400\n",
      "Step 9/400\n",
      "Step 10/400\n",
      "Train loss = 4.369597434997559\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 5.823630332946777\n",
      "Valid F1 score = 0.5884413309982487\n",
      "Step 11/400\n",
      "Step 12/400\n",
      "Step 13/400\n",
      "Step 14/400\n",
      "Step 15/400\n",
      "Train loss = 3.201353073120117\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 16/400\n",
      "Step 17/400\n",
      "Step 18/400\n",
      "Step 19/400\n",
      "Step 20/400\n",
      "Train loss = 5.733007431030273\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 4.764493465423584\n",
      "Valid F1 score = 0.749034749034749\n",
      "Step 21/400\n",
      "Step 22/400\n",
      "Step 23/400\n",
      "Step 24/400\n",
      "Step 25/400\n",
      "Train loss = 2.999767780303955\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 26/400\n",
      "Step 27/400\n",
      "Step 28/400\n",
      "Step 29/400\n",
      "Step 30/400\n",
      "Train loss = 3.9429569244384766\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 3.8347513675689697\n",
      "Valid F1 score = 0.7761627906976745\n",
      "Step 31/400\n",
      "Step 32/400\n",
      "Step 33/400\n",
      "Step 34/400\n",
      "Step 35/400\n",
      "Train loss = 2.7038774490356445\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 36/400\n",
      "Step 37/400\n",
      "Step 38/400\n",
      "Step 39/400\n",
      "Step 40/400\n",
      "Train loss = 2.2036232948303223\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 3.467288017272949\n",
      "Valid F1 score = 0.7936962750716331\n",
      "Step 41/400\n",
      "Step 42/400\n",
      "Step 43/400\n",
      "Step 44/400\n",
      "Step 45/400\n",
      "Train loss = 2.600839614868164\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 46/400\n",
      "Step 47/400\n",
      "Step 48/400\n",
      "Step 49/400\n",
      "Step 50/400\n",
      "Train loss = 3.139993667602539\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 3.198371171951294\n",
      "Valid F1 score = 0.8146067415730337\n",
      "Step 51/400\n",
      "Step 52/400\n",
      "Step 53/400\n",
      "Step 54/400\n",
      "Step 55/400\n",
      "Train loss = 3.1619677543640137\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 56/400\n",
      "Step 57/400\n",
      "Step 58/400\n",
      "Step 59/400\n",
      "Step 60/400\n",
      "Train loss = 1.589641809463501\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 3.072568416595459\n",
      "Valid F1 score = 0.8446866485013624\n",
      "Step 61/400\n",
      "Step 62/400\n",
      "Step 63/400\n",
      "Step 64/400\n",
      "Step 65/400\n",
      "Train loss = 3.574899673461914\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 66/400\n",
      "Step 67/400\n",
      "Step 68/400\n",
      "Step 69/400\n",
      "Step 70/400\n",
      "Train loss = 2.052523136138916\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 3.1688404083251953\n",
      "Valid F1 score = 0.8237037037037037\n",
      "Step 71/400\n",
      "Step 72/400\n",
      "Step 73/400\n",
      "Step 74/400\n",
      "Step 75/400\n",
      "Train loss = 1.8882490396499634\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 76/400\n",
      "Step 77/400\n",
      "Step 78/400\n",
      "Step 79/400\n",
      "Step 80/400\n",
      "Train loss = 3.029888153076172\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.9620087146759033\n",
      "Valid F1 score = 0.8541114058355438\n",
      "Step 81/400\n",
      "Step 82/400\n",
      "Step 83/400\n",
      "Step 84/400\n",
      "Step 85/400\n",
      "Train loss = 2.0893163681030273\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 86/400\n",
      "Step 87/400\n",
      "Step 88/400\n",
      "Step 89/400\n",
      "Step 90/400\n",
      "Train loss = 5.109041213989258\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.817345380783081\n",
      "Valid F1 score = 0.8567375886524822\n",
      "Step 91/400\n",
      "Step 92/400\n",
      "Step 93/400\n",
      "Step 94/400\n",
      "Step 95/400\n",
      "Train loss = 1.7578107118606567\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 96/400\n",
      "Step 97/400\n",
      "Step 98/400\n",
      "Step 99/400\n",
      "Step 100/400\n",
      "Train loss = 3.0613560676574707\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.6914498805999756\n",
      "Valid F1 score = 0.8599167822468794\n",
      "Step 101/400\n",
      "Step 102/400\n",
      "Step 103/400\n",
      "Step 104/400\n",
      "Step 105/400\n",
      "Train loss = 1.5670855045318604\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 106/400\n",
      "Step 107/400\n",
      "Step 108/400\n",
      "Step 109/400\n",
      "Step 110/400\n",
      "Train loss = 2.343752384185791\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.687222957611084\n",
      "Valid F1 score = 0.8563300142247511\n",
      "Step 111/400\n",
      "Step 112/400\n",
      "Step 113/400\n",
      "Step 114/400\n",
      "Step 115/400\n",
      "Train loss = 2.503722667694092\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 116/400\n",
      "Step 117/400\n",
      "Step 118/400\n",
      "Step 119/400\n",
      "Step 120/400\n",
      "Train loss = 1.0334320068359375\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.5762927532196045\n",
      "Valid F1 score = 0.873469387755102\n",
      "Step 121/400\n",
      "Step 122/400\n",
      "Step 123/400\n",
      "Step 124/400\n",
      "Step 125/400\n",
      "Train loss = 1.4158746004104614\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 126/400\n",
      "Step 127/400\n",
      "Step 128/400\n",
      "Step 129/400\n",
      "Step 130/400\n",
      "Train loss = 2.892350435256958\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.6513214111328125\n",
      "Valid F1 score = 0.8579626972740315\n",
      "Step 131/400\n",
      "Step 132/400\n",
      "Step 133/400\n",
      "Step 134/400\n",
      "Step 135/400\n",
      "Train loss = 2.4721286296844482\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 136/400\n",
      "Step 137/400\n",
      "Step 138/400\n",
      "Step 139/400\n",
      "Step 140/400\n",
      "Train loss = 2.1836998462677\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.587207078933716\n",
      "Valid F1 score = 0.871584699453552\n",
      "Step 141/400\n",
      "Step 142/400\n",
      "Step 143/400\n",
      "Step 144/400\n",
      "Step 145/400\n",
      "Train loss = 1.2324910163879395\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 146/400\n",
      "Step 147/400\n",
      "Step 148/400\n",
      "Step 149/400\n",
      "Step 150/400\n",
      "Train loss = 1.6206376552581787\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.6788275241851807\n",
      "Valid F1 score = 0.8611898016997166\n",
      "Step 151/400\n",
      "Step 152/400\n",
      "Step 153/400\n",
      "Step 154/400\n",
      "Step 155/400\n",
      "Train loss = 1.6281540393829346\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 156/400\n",
      "Step 157/400\n",
      "Step 158/400\n",
      "Step 159/400\n",
      "Step 160/400\n",
      "Train loss = 2.945674419403076\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.609842538833618\n",
      "Valid F1 score = 0.8683853459972863\n",
      "Step 161/400\n",
      "Step 162/400\n",
      "Step 163/400\n",
      "Step 164/400\n",
      "Step 165/400\n",
      "Train loss = 1.7171584367752075\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 166/400\n",
      "Step 167/400\n",
      "Step 168/400\n",
      "Step 169/400\n",
      "Step 170/400\n",
      "Train loss = 1.2069084644317627\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.3962082862854004\n",
      "Valid F1 score = 0.876595744680851\n",
      "Step 171/400\n",
      "Step 172/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 173/400\n",
      "Step 174/400\n",
      "Step 175/400\n",
      "Train loss = 1.9884134531021118\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 176/400\n",
      "Step 177/400\n",
      "Step 178/400\n",
      "Step 179/400\n",
      "Step 180/400\n",
      "Train loss = 1.5505428314208984\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.3788721561431885\n",
      "Valid F1 score = 0.8732394366197184\n",
      "Step 181/400\n",
      "Step 182/400\n",
      "Step 183/400\n",
      "Step 184/400\n",
      "Step 185/400\n",
      "Train loss = 1.6757614612579346\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 186/400\n",
      "Step 187/400\n",
      "Step 188/400\n",
      "Step 189/400\n",
      "Step 190/400\n",
      "Train loss = 1.6026629209518433\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.3716349601745605\n",
      "Valid F1 score = 0.8781163434903047\n",
      "Step 191/400\n",
      "Step 192/400\n",
      "Step 193/400\n",
      "Step 194/400\n",
      "Step 195/400\n",
      "Train loss = 1.4987293481826782\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Step 196/400\n",
      "Step 197/400\n",
      "Step 198/400\n",
      "Step 199/400\n",
      "Step 200/400\n",
      "Train loss = 3.2049412727355957\n",
      "ELMo weights:\n",
      "Coefficients = [0. 0. 0.], scale = 1.0\n",
      "ELMo cells change per step: cell0: 0.00%, cell1: 0.00%\n",
      "Valid loss = 2.374614953994751\n",
      "Valid F1 score = 0.8775790921595599\n",
      "Step 201/400\n",
      "Step 202/400\n",
      "Step 203/400\n",
      "Step 204/400\n",
      "Step 205/400\n",
      "Train loss = 8.96074104309082\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.0021667   0.00418913 -0.00431213], scale = 0.9982705116271973\n",
      "ELMo cells change per step: cell0: 0.59%, cell1: 0.67%\n",
      "Step 206/400\n",
      "Step 207/400\n",
      "Step 208/400\n",
      "Step 209/400\n",
      "Step 210/400\n",
      "Train loss = 2.1062889099121094\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.00512305  0.00775681 -0.00777246], scale = 0.9951404333114624\n",
      "ELMo cells change per step: cell0: 0.41%, cell1: 0.42%\n",
      "Valid loss = 3.7311997413635254\n",
      "Valid F1 score = 0.8243064729194188\n",
      "Step 211/400\n",
      "Step 212/400\n",
      "Step 213/400\n",
      "Step 214/400\n",
      "Step 215/400\n",
      "Train loss = 2.062018394470215\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.00660345  0.01006632 -0.00980354], scale = 0.9937403202056885\n",
      "ELMo cells change per step: cell0: 0.33%, cell1: 0.32%\n",
      "Step 216/400\n",
      "Step 217/400\n",
      "Step 218/400\n",
      "Step 219/400\n",
      "Step 220/400\n",
      "Train loss = 1.5980629920959473\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.00829169  0.01164689 -0.01158157], scale = 0.9931550621986389\n",
      "ELMo cells change per step: cell0: 0.29%, cell1: 0.26%\n",
      "Valid loss = 3.132077217102051\n",
      "Valid F1 score = 0.8416666666666667\n",
      "Step 221/400\n",
      "Step 222/400\n",
      "Step 223/400\n",
      "Step 224/400\n",
      "Step 225/400\n",
      "Train loss = 2.4072673320770264\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.009802    0.01302039 -0.01316931], scale = 0.9924136996269226\n",
      "ELMo cells change per step: cell0: 0.27%, cell1: 0.22%\n",
      "Step 226/400\n",
      "Step 227/400\n",
      "Step 228/400\n",
      "Step 229/400\n",
      "Step 230/400\n",
      "Train loss = 3.442690372467041\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01016244  0.01430898 -0.01407224], scale = 0.9922329187393188\n",
      "ELMo cells change per step: cell0: 0.26%, cell1: 0.20%\n",
      "Valid loss = 2.7756900787353516\n",
      "Valid F1 score = 0.8613333333333333\n",
      "Step 231/400\n",
      "Step 232/400\n",
      "Step 233/400\n",
      "Step 234/400\n",
      "Step 235/400\n",
      "Train loss = 2.416290760040283\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01071974  0.01511952 -0.0148322 ], scale = 0.9921543002128601\n",
      "ELMo cells change per step: cell0: 0.25%, cell1: 0.18%\n",
      "Step 236/400\n",
      "Step 237/400\n",
      "Step 238/400\n",
      "Step 239/400\n",
      "Step 240/400\n",
      "Train loss = 2.4033138751983643\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01110106  0.01588459 -0.01546489], scale = 0.99219810962677\n",
      "ELMo cells change per step: cell0: 0.26%, cell1: 0.18%\n",
      "Valid loss = 3.04189395904541\n",
      "Valid F1 score = 0.8469241773962806\n",
      "Step 241/400\n",
      "Step 242/400\n",
      "Step 243/400\n",
      "Step 244/400\n",
      "Step 245/400\n",
      "Train loss = 2.2549753189086914\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01156611  0.01648692 -0.01606074], scale = 0.9921771287918091\n",
      "ELMo cells change per step: cell0: 0.23%, cell1: 0.16%\n",
      "Step 246/400\n",
      "Step 247/400\n",
      "Step 248/400\n",
      "Step 249/400\n",
      "Step 250/400\n",
      "Train loss = 1.6934089660644531\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01111582  0.01679442 -0.01595636], scale = 0.9926417469978333\n",
      "ELMo cells change per step: cell0: 0.20%, cell1: 0.12%\n",
      "Valid loss = 2.7100307941436768\n",
      "Valid F1 score = 0.8688293370944993\n",
      "Step 251/400\n",
      "Step 252/400\n",
      "Step 253/400\n",
      "Step 254/400\n",
      "Step 255/400\n",
      "Train loss = 1.9546722173690796\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01042886  0.01725596 -0.01579152], scale = 0.9932569861412048\n",
      "ELMo cells change per step: cell0: 0.20%, cell1: 0.11%\n",
      "Step 256/400\n",
      "Step 257/400\n",
      "Step 258/400\n",
      "Step 259/400\n",
      "Step 260/400\n",
      "Train loss = 1.6252774000167847\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01022913  0.01741253 -0.01575548], scale = 0.9933750629425049\n",
      "ELMo cells change per step: cell0: 0.24%, cell1: 0.13%\n",
      "Valid loss = 3.0085861682891846\n",
      "Valid F1 score = 0.8730385164051355\n",
      "Step 261/400\n",
      "Step 262/400\n",
      "Step 263/400\n",
      "Step 264/400\n",
      "Step 265/400\n",
      "Train loss = 0.7735167741775513\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01038665  0.01768792 -0.01599777], scale = 0.9936844706535339\n",
      "ELMo cells change per step: cell0: 0.25%, cell1: 0.17%\n",
      "Step 266/400\n",
      "Step 267/400\n",
      "Step 268/400\n",
      "Step 269/400\n",
      "Step 270/400\n",
      "Train loss = 1.9198402166366577\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01076636  0.01804644 -0.01642176], scale = 0.9939131140708923\n",
      "ELMo cells change per step: cell0: 0.22%, cell1: 0.14%\n",
      "Valid loss = 2.914046049118042\n",
      "Valid F1 score = 0.8699186991869918\n",
      "Step 271/400\n",
      "Step 272/400\n",
      "Step 273/400\n",
      "Step 274/400\n",
      "Step 275/400\n",
      "Train loss = 1.9521996974945068\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01113486  0.01822141 -0.01674071], scale = 0.9942155480384827\n",
      "ELMo cells change per step: cell0: 0.22%, cell1: 0.14%\n",
      "Step 276/400\n",
      "Step 277/400\n",
      "Step 278/400\n",
      "Step 279/400\n",
      "Step 280/400\n",
      "Train loss = 3.46075177192688\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01116287  0.0188302  -0.01708614], scale = 0.9943384528160095\n",
      "ELMo cells change per step: cell0: 0.22%, cell1: 0.15%\n",
      "Valid loss = 3.072561740875244\n",
      "Valid F1 score = 0.8522875816993465\n",
      "Step 281/400\n",
      "Step 282/400\n",
      "Step 283/400\n",
      "Step 284/400\n",
      "Step 285/400\n",
      "Train loss = 1.1144542694091797\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01236588  0.01871388 -0.01778569], scale = 0.9938187599182129\n",
      "ELMo cells change per step: cell0: 0.22%, cell1: 0.18%\n",
      "Step 286/400\n",
      "Step 287/400\n",
      "Step 288/400\n",
      "Step 289/400\n",
      "Step 290/400\n",
      "Train loss = 1.2648272514343262\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01238296  0.01975279 -0.0183607 ], scale = 0.9936614632606506\n",
      "ELMo cells change per step: cell0: 0.24%, cell1: 0.22%\n",
      "Valid loss = 2.548307418823242\n",
      "Valid F1 score = 0.8748317631224766\n",
      "Step 291/400\n",
      "Step 292/400\n",
      "Step 293/400\n",
      "Step 294/400\n",
      "Step 295/400\n",
      "Train loss = 1.8846608400344849\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01162629  0.02085808 -0.01847837], scale = 0.9936052560806274\n",
      "ELMo cells change per step: cell0: 0.25%, cell1: 0.22%\n",
      "Step 296/400\n",
      "Step 297/400\n",
      "Step 298/400\n",
      "Step 299/400\n",
      "Step 300/400\n",
      "Train loss = 1.9409072399139404\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01125489  0.02178586 -0.01874747], scale = 0.994194746017456\n",
      "ELMo cells change per step: cell0: 0.24%, cell1: 0.20%\n",
      "Valid loss = 2.8063950538635254\n",
      "Valid F1 score = 0.8586810228802153\n",
      "Step 301/400\n",
      "Step 302/400\n",
      "Step 303/400\n",
      "Step 304/400\n",
      "Step 305/400\n",
      "Train loss = 2.137054920196533\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01101954  0.0226665  -0.0190789 ], scale = 0.9942832589149475\n",
      "ELMo cells change per step: cell0: 0.27%, cell1: 0.20%\n",
      "Step 306/400\n",
      "Step 307/400\n",
      "Step 308/400\n",
      "Step 309/400\n",
      "Step 310/400\n",
      "Train loss = 1.8779864311218262\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01111828  0.02297599 -0.01931386], scale = 0.9937974214553833\n",
      "ELMo cells change per step: cell0: 0.27%, cell1: 0.20%\n",
      "Valid loss = 2.636507511138916\n",
      "Valid F1 score = 0.8633093525179856\n",
      "Step 311/400\n",
      "Step 312/400\n",
      "Step 313/400\n",
      "Step 314/400\n",
      "Step 315/400\n",
      "Train loss = 0.9636090397834778\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01111646  0.02377272 -0.01975277], scale = 0.9937052726745605\n",
      "ELMo cells change per step: cell0: 0.24%, cell1: 0.18%\n",
      "Step 316/400\n",
      "Step 317/400\n",
      "Step 318/400\n",
      "Step 319/400\n",
      "Step 320/400\n",
      "Train loss = 2.7778162956237793\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01102676  0.0236529  -0.01962762], scale = 0.9936937689781189\n",
      "ELMo cells change per step: cell0: 0.24%, cell1: 0.17%\n",
      "Valid loss = 2.9261322021484375\n",
      "Valid F1 score = 0.8441176470588235\n",
      "Step 321/400\n",
      "Step 322/400\n",
      "Step 323/400\n",
      "Step 324/400\n",
      "Step 325/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss = 2.6474547386169434\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01165415  0.02448906 -0.02049945], scale = 0.9939621090888977\n",
      "ELMo cells change per step: cell0: 0.24%, cell1: 0.16%\n",
      "Step 326/400\n",
      "Step 327/400\n",
      "Step 328/400\n",
      "Step 329/400\n",
      "Step 330/400\n",
      "Train loss = 1.1901695728302002\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01234025  0.02540443 -0.02145235], scale = 0.9931159019470215\n",
      "ELMo cells change per step: cell0: 0.20%, cell1: 0.14%\n",
      "Valid loss = 2.6502928733825684\n",
      "Valid F1 score = 0.879120879120879\n",
      "Step 331/400\n",
      "Step 332/400\n",
      "Step 333/400\n",
      "Step 334/400\n",
      "Step 335/400\n",
      "Train loss = 1.0494179725646973\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01269467  0.02583912 -0.02192397], scale = 0.9920271039009094\n",
      "ELMo cells change per step: cell0: 0.20%, cell1: 0.11%\n",
      "Step 336/400\n",
      "Step 337/400\n",
      "Step 338/400\n",
      "Step 339/400\n",
      "Step 340/400\n",
      "Train loss = 1.8318825960159302\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01352164  0.02621191 -0.02267028], scale = 0.9919055104255676\n",
      "ELMo cells change per step: cell0: 0.22%, cell1: 0.14%\n",
      "Valid loss = 2.9370081424713135\n",
      "Valid F1 score = 0.8745046235138705\n",
      "Step 341/400\n",
      "Step 342/400\n",
      "Step 343/400\n",
      "Step 344/400\n",
      "Step 345/400\n",
      "Train loss = 2.0302376747131348\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01371197  0.02607781 -0.02272095], scale = 0.9915005564689636\n",
      "ELMo cells change per step: cell0: 0.36%, cell1: 0.25%\n",
      "Step 346/400\n",
      "Step 347/400\n",
      "Step 348/400\n",
      "Step 349/400\n",
      "Step 350/400\n",
      "Train loss = 1.859769582748413\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01438076  0.02609062 -0.02316689], scale = 0.9913623929023743\n",
      "ELMo cells change per step: cell0: 0.29%, cell1: 0.20%\n",
      "Valid loss = 2.6139774322509766\n",
      "Valid F1 score = 0.8743169398907105\n",
      "Step 351/400\n",
      "Step 352/400\n",
      "Step 353/400\n",
      "Step 354/400\n",
      "Step 355/400\n",
      "Train loss = 2.254587411880493\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01487931  0.02655616 -0.02374977], scale = 0.9908052682876587\n",
      "ELMo cells change per step: cell0: 0.28%, cell1: 0.18%\n",
      "Step 356/400\n",
      "Step 357/400\n",
      "Step 358/400\n",
      "Step 359/400\n",
      "Step 360/400\n",
      "Train loss = 2.5913901329040527\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01604196  0.02683779 -0.0246692 ], scale = 0.9903249144554138\n",
      "ELMo cells change per step: cell0: 0.23%, cell1: 0.21%\n",
      "Valid loss = 2.4208905696868896\n",
      "Valid F1 score = 0.8786279683377309\n",
      "Step 361/400\n",
      "Step 362/400\n",
      "Step 363/400\n",
      "Step 364/400\n",
      "Step 365/400\n",
      "Train loss = 1.468948245048523\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01640838  0.02651345 -0.02473413], scale = 0.9898940324783325\n",
      "ELMo cells change per step: cell0: 0.20%, cell1: 0.30%\n",
      "Step 366/400\n",
      "Step 367/400\n",
      "Step 368/400\n",
      "Step 369/400\n",
      "Step 370/400\n",
      "Train loss = 1.7491222620010376\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01763448  0.02657074 -0.02557562], scale = 0.9891954660415649\n",
      "ELMo cells change per step: cell0: 0.28%, cell1: 0.60%\n",
      "Valid loss = 2.5622568130493164\n",
      "Valid F1 score = 0.8852459016393442\n",
      "Step 371/400\n",
      "Step 372/400\n",
      "Step 373/400\n",
      "Step 374/400\n",
      "Step 375/400\n",
      "Train loss = 1.8570365905761719\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01849888  0.02711611 -0.02644276], scale = 0.9889822602272034\n",
      "ELMo cells change per step: cell0: 0.24%, cell1: 0.42%\n",
      "Step 376/400\n",
      "Step 377/400\n",
      "Step 378/400\n",
      "Step 379/400\n",
      "Step 380/400\n",
      "Train loss = 1.5314016342163086\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.01948609  0.02750888 -0.02730949], scale = 0.9886982440948486\n",
      "ELMo cells change per step: cell0: 0.23%, cell1: 0.38%\n",
      "Valid loss = 2.461000919342041\n",
      "Valid F1 score = 0.884297520661157\n",
      "Step 381/400\n",
      "Step 382/400\n",
      "Step 383/400\n",
      "Step 384/400\n",
      "Step 385/400\n",
      "Train loss = 1.3520774841308594\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.0214816   0.02795242 -0.0288753 ], scale = 0.9876760840415955\n",
      "ELMo cells change per step: cell0: 0.24%, cell1: 0.33%\n",
      "Step 386/400\n",
      "Step 387/400\n",
      "Step 388/400\n",
      "Step 389/400\n",
      "Step 390/400\n",
      "Train loss = 2.8328285217285156\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.02267958  0.02852028 -0.02997829], scale = 0.9867759346961975\n",
      "ELMo cells change per step: cell0: 0.23%, cell1: 0.25%\n",
      "Valid loss = 2.491591691970825\n",
      "Valid F1 score = 0.8780487804878049\n",
      "Step 391/400\n",
      "Step 392/400\n",
      "Step 393/400\n",
      "Step 394/400\n",
      "Step 395/400\n",
      "Train loss = 1.4895368814468384\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.02352066  0.02895535 -0.030773  ], scale = 0.9864059090614319\n",
      "ELMo cells change per step: cell0: 0.21%, cell1: 0.19%\n",
      "Step 396/400\n",
      "Step 397/400\n",
      "Step 398/400\n",
      "Step 399/400\n",
      "Step 400/400\n",
      "Train loss = 2.5085790157318115\n",
      "ELMo weights:\n",
      "Coefficients = [ 0.02382131  0.02946747 -0.03124984], scale = 0.9860243201255798\n",
      "ELMo cells change per step: cell0: 0.21%, cell1: 0.18%\n",
      "Valid loss = 2.6717300415039062\n",
      "Valid F1 score = 0.8753462603878117\n"
     ]
    }
   ],
   "source": [
    "num_steps = 400\n",
    "n_steps_freeze_elmo = 200\n",
    "batch_size = 16\n",
    "display_step = 5\n",
    "valid_step = 10\n",
    "losses = {'train': [], 'valid': []}\n",
    "f1_scores = {'train': [], 'valid': []}\n",
    "best_valid_f1 = 0\n",
    "d_elmo_cells_list = {'cell0':[], 'cell1':[]}\n",
    "for step in range(1, num_steps+1):\n",
    "    print('Step {}/{}'.format(step, num_steps))\n",
    "    tokens_batch, tags_batch, mask_batch, y_batch = get_batch(dataset['train'], batch_size)\n",
    "    feed = fill_feed_dict({tokens_input_ph: tokens_batch, mask_ph: mask_batch, y_ph: y_batch})\n",
    "    if TRAIN_ALL_ELMO_PARAMS:\n",
    "        cell0_kernel_val1 = cell0_kernel.eval(session=sess)\n",
    "        cell1_kernel_val1 = cell1_kernel.eval(session=sess)\n",
    "    train_op = train_op_all\n",
    "    if step <= n_steps_freeze_elmo:\n",
    "        train_op = train_op_model\n",
    "    # Train\n",
    "    with tf.variable_scope('', reuse=tf.AUTO_REUSE):\n",
    "        loss_cur, _ = sess.run([loss, train_op], feed_dict=feed)\n",
    "    losses['train'].append(loss_cur)\n",
    "    if TRAIN_ALL_ELMO_PARAMS:\n",
    "        cell0_kernel_val2 = cell0_kernel.eval(session=sess)\n",
    "        cell1_kernel_val2 = cell1_kernel.eval(session=sess)\n",
    "        d_cell0_kernel = np.linalg.norm(cell0_kernel_val2 - cell0_kernel_val1)/np.linalg.norm(cell0_kernel_val1)\n",
    "        d_cell1_kernel = np.linalg.norm(cell1_kernel_val2 - cell1_kernel_val1)/np.linalg.norm(cell1_kernel_val1)\n",
    "        d_elmo_cells_list['cell0'].append(d_cell0_kernel)\n",
    "        d_elmo_cells_list['cell1'].append(d_cell1_kernel)\n",
    "#     print('ELMo cells change per step: cell0: {}, cell1: {}'.format(d_cell0_kernel, d_cell1_kernel))\n",
    "    # Validate\n",
    "    with tf.variable_scope('', reuse=tf.AUTO_REUSE):\n",
    "        loss_valid = sess.run([loss], feed_dict=feed_valid)[0]\n",
    "        if use_crf:\n",
    "          pred = predict_crf(logits, transition_params, mask_ph, feed_dict=feed_valid)\n",
    "        else:\n",
    "          pred = predict_no_crf(y_pred, mask_ph, feed_dict=feed_valid)\n",
    "#         print(pred)\n",
    "        f1_valid = f1_score(flatten_with_mask(y_valid, mask_valid), concatenate_arrays(pred))\n",
    "        f1_scores['valid'].append(f1_valid)\n",
    "        if f1_valid > best_valid_f1:\n",
    "                best_valid_f1 = f1_valid\n",
    "    # Get elmo params\n",
    "    with tf.variable_scope('', reuse=tf.AUTO_REUSE):\n",
    "        if TRAIN_ELMO:\n",
    "            layer_coeff, scale = sess.run([elmo_coef['layer_coefficients'], elmo_coef['scaling']])\n",
    "            if f1_valid == best_valid_f1:\n",
    "                elmo_params_best = {'layer_coefficients': layer_coeff, 'scaling': scale}\n",
    "    losses['valid'].append(loss_valid)\n",
    "    if step % display_step == 0 or step == 1:\n",
    "        print('Train loss = {}'.format(losses['train'][-1]))\n",
    "#         print('Train F1 score = {}'.format(f1_scores['train'][-1]))\n",
    "        if TRAIN_ELMO:\n",
    "            with tf.variable_scope('', reuse=tf.AUTO_REUSE):\n",
    "                print('ELMo weights:')\n",
    "                print('Coefficients = {}, scale = {}'.format(layer_coeff, scale))\n",
    "        if TRAIN_ALL_ELMO_PARAMS:\n",
    "            print('ELMo cells change per step: cell0: {:.2f}%, cell1: {:.2f}%'.format(d_cell0_kernel*100, d_cell1_kernel*100))\n",
    "        \n",
    "    if step % valid_step == 0 or step == 1:\n",
    "        print('Valid loss = {}'.format(losses['valid'][-1]))\n",
    "        print('Valid F1 score = {}'.format(f1_scores['valid'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 891,
     "status": "ok",
     "timestamp": 1535234590955,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "FQ7egrqCkVvP",
    "outputId": "579cd4d5-4c8e-49b0-aadb-13cc296c7d09"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-27 15:55:25.342 DEBUG in 'matplotlib.font_manager'['font_manager'] at line 1346: findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/clement/virtenv/env/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000\n",
      "2018-08-27 15:55:25.365 DEBUG in 'matplotlib.font_manager'['font_manager'] at line 1346: findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/home/clement/virtenv/env/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzsnXd4FNX6xz8nPYEkhAChShBUkCIICuoVsWNBFEWwcEXlYu/96lV/Kl57w4rl2gXFQhELaGIBRKpIF6T3GpKQnvf3x9nJzG5mk92Qzaacz/PsMzv9nZkz53ve95RRIoLBYDAYGi4R4TbAYDAYDOHFCIHBYDA0cIwQGAwGQwPHCIHBYDA0cIwQGAwGQwPHCIHBYDA0cIwQGAwuKKW+UUpdEW47DIaaQJl+BIbahFJqHTBKRGaE2xaDoaFgPAJDg0MpFRVuGw6W+nANhtqDEQJDnUEpda5SapFSap9SapZSqodj3b1KqTVKqWyl1DKl1AWOdSOVUjOVUs8rpXYDD3uW/aqUekYptVcptVYpdZZjn0yl1CjH/hVt20Ep9bPn3DOUUq8opT6s4DoGe65jv8fmgZ7l65RSpzm2e9g6jlIqXSklSqmrlVIbgB894asbfY79h1JqiOd/Z6XUdKXUHqXUSqXUxVW/+4b6jBECQ51AKdULeAe4BkgF3gAmK6ViPZusAU4EkoH/Az5USrVyHKIv8DeQBoxxLFsJNAOeAt5WSik/JlS07cfA7x67HgZGVHAdxwLvA3cBTYD+wLrKrt/BSUAX4EzgE+ASx7GPBNoDXyulGgHTPba1AIYDr3q2MRi8MEJgqCuMBt4QkTkiUiIi7wEFQD8AEflMRLaISKmITAD+Ao517L9FRMaKSLGI5HmWrReRN0WkBHgPaIUWCjdct1VKHQIcAzwoIoUi8iswuYLruBp4R0Sme2zdLCIrgrgPD4tIrucavgR6KqXae9ZdBnwhIgXAucA6Efmf55oXAp8DQ4M4l6GBYITAUFdoD9zhCQvtU0rtA9oBrQGUUv90hI32Ad3QpXeLjS7H3Gb9EZEDnr+N/Zzf37atgT2OZf7OZdEO7b1UlbJji0g28DW6tA/aO/jI87890Nfnfl0GtDyIcxvqKabCyVBX2AiMEZExvis8JeI3gVOB2SJSopRaBDjDPKFqHrcVaKqUSnCIQbsKtt8IdPSzLhdIcMy7Zdq+1/EJ8JBS6mcgDshwnOcnETm9IuMNBjAegaF2Eq2UinP8otAZ/bVKqb5K00gpdY5SKhFohM4gdwIopa5EewQhR0TWA/PQFdAxSqnjgEEV7PI2cKVS6lSlVIRSqo1SqrNn3SJguFIqWinVB7goABOmoUv/jwATRKTUs3wqcLhSaoTneNFKqWOUUl2qcp2G+o0RAkNtZBqQ5/g9LCLzgH8BLwN7gdXASAARWQY8C8wGtgPdgZk1aO9lwHHAbuAxYAK6/qIcIvI7cCXwPJAF/ITOyAH+g/YW9qIrvD+u7MSe+oAvgNOc23vCRmegw0Zb0KGtJ4FYl8MYGjimQ5nBUM0opSYAK0TkoXDbYjAEgvEIDIaDxBNy6egJ9QwEBgNfhdsugyFQTGWxwXDwtESHZ1KBTcB1nuaaBkOdwISGDAaDoYFjQkMGg8HQwKkToaFmzZpJenp60Pvl5ubSqFGj6jeoGqitthm7gsPYFRzGruA5GNvmz5+/S0SaV7qhiNT6X+/evaUqZGRkVGm/mqC22mbsCg5jV3AYu4LnYGwD5kkAeawJDRkMBkMDxwiBwWAwNHCMEBgMBkMDp05UFhsMBkOwFBUVsWnTJvLz8yvdNjk5meXLl9eAVcETiG1xcXG0bduW6OjoKp3DCIHBYKiXbNq0icTERNLT0/H/vSFNdnY2iYmJNWRZcFRmm4iwe/duNm3aRIcOHap0DhMaMhgM9ZL8/HxSU1MrFYG6jlKK1NTUgDwffxghMBgM9Zb6LgIWB3ud9VoIZs9O5Yknwm2FwWAw1G5CJgRKqXeUUjuUUktc1t2hlBKlVDO3fauLOXOa8swzoTyDwWAwuLNv3z5effXVoPc7++yz2bdvXwgs8k8oPYJ3gYG+C5VS7dAfzNgQwnMDEBEhlJSE+iwGg8FQHn9CUFxcXOF+06ZNo0mTJqEyy5WQtRoSkZ+VUukuq54H7gYmhercFpGRRggMBkN4uPfee1mzZg09e/YkOjqauLg4UlJSWLFiBatWreL8889n48aN5Ofnc8sttzB69GgA0tPTmTdvHjk5OZx11ln07duXuXPn0qZNGyZNmkR8fHy12xrSYag9QjBVRLp55gcDp4jILUqpdUAfEdnlZ9/RwGiAtLS03uPHjw/6/C++2I5vv03nm29+qdoFhJCcnBwaN24cbjPKYewKDmNXcNSkXcnJyXTq1AmAe+6J5c8//QdARCDY+tbu3Ut58knXL5ICsH79ei6++GLmzJnDL7/8wtChQ/ntt9+wBtDcs2cPTZs2JS8vjwEDBjBt2jRSU1Pp1q0bP/30Ezk5OfTs2ZOMjAx69uzJFVdcwVlnncXw4cNdz7d69WqysrK8lp188snzRaRPZddSY/0IlFIJwL/RYaFKEZFxwDiAPn36yIABA4I+5+uvbwAiqcq+oSYzM9PYFQTGruAwdsHy5cvL2t/HxEBkpP9tS0qKiYwMLjuMiYHExBi/6xs3bkxERASJiYkkJCRw7LHH0r1797L1zz77LF9++SUAmzdvZtu2bWV9Hiyx7NChAz179iQxMZG+ffuyfft2v30K4uLi6NWrV1DXYFGTHco6Ah2APzxNndoCC5RSx4rItlCc0ISGDAYDwAsvVLw+Ozsv5B3KnENJZ2ZmMmPGDGbPnk1CQgIDBgxw7QcQGxtb9j8yMpK8vLyQ2FZjQiAifwItrPnKQkPVQUQERggMBkNYSExMJDs723VdVlYWKSkpJCQksGLFCn777bcats6bkAmBUuoTYADQTCm1CXhIRN4O1fnciIgQSkurFv8zGAyGgyE1NZUTTjiBbt26ER8fT1paWtm6gQMH8vrrr9OlSxeOOOII+vXrF0ZLQ9tq6JJK1qeH6twWERG6Iry0tOL4oMFgMISCjz/+2HV5bGws33zzjeu6devWAdCsWTOWLFlS5lXceeedIbER6nnP4shIWwgMBoPB4E69FgIrHGTqCQwGg8E/9VoIrNCQEQKDwWDwT70WAis0ZITAYDAY/FOvhSDCc3VGCAwGg8E/9VwIjEdgMBgMlWGEwGAwGGoB1rASW7Zs4aKLLnLdZsCAAcybN6/az90ghMA0HzUYDHWF1q1bM3HixBo9Z73+eL2pIzAYDOHi3nvvpV27dtxwww0APPzww0RFRZGRkcHevXspKiriscceY/DgwV77rVu3jnPPPZclS5aQl5fHyJEjWbZsGZ07d677Yw2FAxMaMhgMANx6Kyxa5Hd1fElJ8MMP9OxZ4Wh2w4YN49Zbby0Tgk8//ZTvvvuOm2++maSkJHbt2kW/fv0477zz/H5z+LXXXiMhIYHly5ezePFijj766OBsDBAjBAaDwRACevXqxY4dO9iyZQs7d+4kJSWFli1bctttt/Hzzz8TERHB5s2b2b59Oy1btnQ9xs8//8yoUaMA6NGjBz169AiJrfVaCCyBN0JgMDRwKhmHOi87OyTDUA8dOpSJEyeybds2hg0bxkcffcTOnTuZP38+0dHRpKenuw4/XdM0iMpiIwQGgyEcDBs2jPHjxzNx4kSGDh1KVlYWLVq0IDo6moyMDNavX1/h/v379+ezzz4DYMmSJSxevDgkdtZrj8AIgcFgCCddu3YlOzubNm3a0KpVKy677DIGDRpE9+7d6dOnD507d65w/+uuu47LL7+cLl260KVLF3r37h0SOxuEEJjmowaDIVz8+eefZf+bNWvG7NmzXbfLyckB9MfrlyxZAkB8fDzvvvtuyL+eVs9DQ3pqPAKDwWDwTz0XAhMaMhgMhsowQmAwGOotIhJuE2qEg73Oei0EpvmowdBwiYuLY/fu3fVeDESE3bt3ExcXV+VjNIjKYiMEBkPDo23btmzatImdO3dWum1+fv5BZaShJBDb4uLiaNu2bZXPETIhUEq9A5wL7BCRbp5lTwODgEJgDXCliOwLlQ1GCAyGhkt0dDQdOnQIaNvMzEx69eoVYouqRk3YFsrQ0LvAQJ9l04FuItIDWAXcF8Lzl7UaMs1HDQaDwT8hEwIR+RnY47PsexEp9sz+BlTdlwkA4xEYDAZD5YSzjuAqYIK/lUqp0cBogLS0NDIzM4M+QUFBNAALFvxBVNTeKhkZKnJycqp0TaHG2BUcxq7gMHYFT43YJiIh+wHpwBKX5fcDXwIqkOP07t1bqsIrr8wTEPn66yrtHlIyMjLCbYIrxq7gMHYFh7EreA7GNmCeBJDH1rhHoJQaia5EPtVjaMgwzUcNBoOhcmpUCJRSA4G7gZNE5ECoz2fqCAwGg6FyQlZZrJT6BJgNHKGU2qSUuhp4GUgEpiulFimlXg/V+cEIgcFgMARCyDwCEbnEZfHboTqfG6b5qMFgMFROvR5iwngEBoPBUDlGCAwGg6GBY4TAYDAYGjj1WghM81GDwWConHotBMYjMBgMhsppEEKweDHk54fZGIPBYKil1HMh0NOxY2HUqPDaYjAYDLWVei4E9ggWv/wSRkMMBoOhFtNghMCqODYYDAaDN0YIDAaDoYFTr4XAmflH1OsrNRgMhqpTr7NHp0cQFc5P8BgMBkMtpsEIgQkNGQwGgzv1XAjc/xsMBoPBpl5nj8YjMBgMhsqp10KglP3feAQGg8HgToPJHo1HYDAYDO4YITAYDIYGTr0Wgrht2+jLb4AJDRkMBoM/6nX22O6TT5jCIMD0IzAYDAZ/hEwIlFLvKKV2KKWWOJY1VUpNV0r95ZmmhOr8AMVJSTRlD4pSr4pjg8FgMNiE0iN4Fxjos+xe4AcROQz4wTMfMooSE4mklCT2U1QUyjMZDAZD3SVkQiAiPwN7fBYPBt7z/H8POD9U5wcoSkoCoCl7jBAYDAaDH5SIVL5VVQ+uVDowVUS6eeb3iUgTz38F7LXmXfYdDYwGSEtL6z1+/Pigz5/w448c++ij9GEu+w87gsGDNxMdLZxxxvaqXVA1kpOTQ+PGjcNtRjmMXcFh7AoOY1fwHIxtJ5988nwR6VPphiISsh+QDixxzO/zWb83kOP07t1bqsL8l14SATmDb6VbNxHQv9pARkZGuE1wxdgVHMau4DB2Bc/B2AbMkwDy2JpuNbRdKdUKwDPdEcqTFZvQkMFgMFRKTQvBZOAKz/8rgEmhPJmzjqCwMJRnMhgMhrpLKJuPfgLMBo5QSm1SSl0NPAGcrpT6CzjNMx8yihMTAUhlt/EIDAaDwQ8h62YlIpf4WXVqqM5ZzoaoKPaTaEJDBoPBUAH1umcxwG5STWjIYDAYKqBBCEFzdhqPwGAwGPxQ74Wg2ykt6NLMCIHBYDD4o94LQdwhaaQUbDehIYPBYPBDvRcCWrSg0YEdVgc2g8FgMPhQ/4UgLY2okkKSyQq3JQaDwVArqf9C0KKFnoS2E7PBYDDUWeq/EKSl6QnhH2jOYDAYaiP1XwiMR2AwGAwVUv+FwHgEhhpCKbjuunBbYTAET/0XghT9NcwU9pYtKikJlzGG+s7rr4fbAoMheOq/EMTGUhId69VqyHQuMxgMBpv6LwRAUUKylxAUF4fRGIPBYKhlNAghKG6UbDwCQ0gx/RUNdZkGIQQljZJJYn/ZvBECQ3VjhMBQl2kYQtDYhIYMoaW0NNwWGAxVp0EIQWmiCQ0ZQosRAkNdpoEIQZIRAkNIMUJgqMs0CCGQJBMaMoQWIwSGukyDEAKSkkkimwh0TzLjERiqGyMEhrpMwxCCJskAJJINGCEwVD9GCAx1mbAIgVLqNqXUUqXUEqXUJ0qpuJCeL1kLgRUeMqEhQ3Vjhi0x1GVqXAiUUm2Am4E+ItINiASGh/KcESneQmA8AkN1YzwCQ10mXKGhKCBeKRUFJABbQnmyiBbNAGjOTsAIgaH6MUJgqMtE1fQJRWSzUuoZYAOQB3wvIt/7bqeUGg2MBkhLSyMzMzPoc+Xk5JCZmUnJ9i2cCrT26M38+X+AYzTScGDZVtswdgWHZdeePdHACQC1ws7afr9qG7XVLqgh20SkRn9ACvAj0ByIBr4CLq9on969e0tVyMjIEBGR/VtzREDu4b8CItOmVelw1YplW23D2BUcll1btojogSbCa49Fbb9ftY3aapfIwdkGzJMA8uWAQkNKqVuUUklK87ZSaoFS6owqas9pwFoR2SkiRcAXwPFVPFZARDdpxD6SyzwCExoyVDcmNGSoywRaR3CViOwHzkCX6EcAT1TxnBuAfkqpBKWUAk4FllfxWAERHQ1baE0bNgOm1ZCh+jFCYKjLBCoEyjM9G/hARJY6lgWFiMwBJgILgD89NoyryrECJTISttCmTAiMR2CobowQGOoygQrBfKXU92gh+E4plQhUOemLyEMi0llEuonICBEpqOqxAmVbRGsTGjKEDCMEhrpMoK2GrgZ6An+LyAGlVFPgytCZVf1sjWpH68ItRFNIcXFMuM0x1DOMEBjqMoF6BMcBK0Vkn1LqcuABcIziVgdYHd2FKEo4jL+MR2CodowQGOoygQrBa8ABpdRRwB3AGuD9kFkVAtbEHgnAkSyrshB8+KH+GQy+GCEw1GUCFYJiT5vUwcDLIvIKkBg6s6qf9fGdKUXRlaVVbjU0YoT+GQy+GCEw1GUCFYJspdR96GajXyulItCdweoMpbHx/M2hB+URGAy+lJQoXnsNCgvDbYnBUHUCFYJhQAG6P8E2oC3wdMisCgExMbCUrnRlKePHm9EiDdXDF1+04frr4ZVXwm2JwVB1AhICT+b/EZCslDoXyBeROlVHEB0NyziSw1nFonlFTJ4cbosM9YGcHN3wbteuMBtiMBwEgQ4xcTHwOzAUuBiYo5S6KJSGVTfR0dojiKaYTqxm1qxwW2SoDyhPt0rTW91Qlwm0H8H9wDEisgNAKdUcmIHuIVwniInRHgHAkMOX8tPsLmG2yFAfUEoAE2o01G0CrSOIsETAw+4g9q0VREfDCjoD8I/U5cybZ15ew8FjeQQmLRnqMoF6BN8qpb4DPvHMDwOmhcak0BAdDXkkUNKyNW0K11JQoFt6xMeH2zJDXcaEhgz1gYCEQETuUkpdiPXlDRgnIl+GzqzqJ8YzqkRJu3Sa7F0HwJo10KEDNGoUPrsMdRsrNGSEwFCXCfgLZSLyOfB5CG0JKdGeXg9ySDrJf88GoHt3OO44TMWxocqY0JChPlChECilsgFxW4X+FFNSSKwKAWVCkJ5O472fEkkxJUQxe3Z47TLUbYwQGOoDFQqBiNSpYSQqwgoN0T6dyNJiWrOFjRwSVpsMdR/TashQH6hTLX8OBssjiOjYAYB01gW1vxlLxuBGhOcNMnUEhrpMgxECyyNQHdIB6MDaoPY34xMZ3DCVxYb6QIMRAssjiExvhygVtEdghMBQESY0ZKjLNCghUAoi4mPJb9raCIGhWjCVxYb6QIMRgpgYiPJUjeenpRshMFQLJjRkqA+ERQiUUk2UUhOVUiuUUsuVUseF+pz9+8OFF+r/+a0OTghMxbHBwqosNh6BoS4TLo/gReBbEekMHAUsD/UJzzsPPvEMkFHUOp12bCQa/TURcesp4YNTCEzpz2Bhhpgw1AdqXAiUUslAf+BtABEpFJF9NWlDfseuRFFCF4/+5OVVvo/zC1TmpTfYmH4EhrpPwENMVCMdgJ3A/5RSRwHzgVtEJNe5kVJqNDAaIC0tjczMzKBPlJOT47rfdqI5HOjFQhZzFN99N5OUlIorAdauTQCOBSAj4xcaNTq4N9+fbeHG2BUchYWpAOTlFQK6jXJtsLO23i9jV/DUiG0iUqM/oA9QDPT1zL8IPFrRPr1795aqkJGR4br8jwXFkkOCvMDNAiKrV1d+rIULRXQQSWT37iqZE5Bt4cbYFRz3XDNP3uZKaZ+SVZY+agO19X4Zu4LnYGwD5kkA+XI46gg2AZtEZI5nfiJwdE0aEB0XyWJ60Jv5AOTkVL6Ps47AhAEMFqfOfYOr+B+X570ZblMMhipT40Ig+vvHG5VSR3gWnQosq0kboqPhZ/pzLL/TmGyys73Xl5bCXXfB33/by0xlscGNuAJdisgV82ELQ90lXK2GbgI+UkotBnoCj9fkyWNi4DvOJIYiTuKnckKwcCE88wyMHGkvM0JgcCO2UFdt7S+tN+MzGhogYRECEVkkIn1EpIeInC8ie2vy/NHRMJMTOEA8pzGDOXO812dl6WmE4+6YVkMGNywhyC+NqWRLg6H20mB6FjuJjoZCYplDX06KmslHH3n3JdizR08THYU84xEY3IgtOgBAZKnpem6ouzRYIQCYxfH0KFnIltW57Nxpr9++XU+NEBgqI8YjBNFSEGZLDIaq0yCFwBqSehbHEyklHMNc9u+312/bpqcJCfYy02rI4EZckQ4NxWKEwFB3aZBCYHkEv3s6iPVmvleFsSUEzh7HxiMwuBFXaITAUPdpkEIQGamnu2jOgaZt6cXCMo+goACWLtX/cx19nY0QGNyILdaJJIbCSrY0NHRWrIAbbqidg1Y2SCGwBgoDyD28F0ezoMwjuO8+yj5o7xQC02rIUA4RExoyBMzgwfDqq7BqVbgtKU+DFAInxT2OpjMryN2hX+i//rLX1TePYP58qKXDqdRNCgqIFF1hZITAUBmWJ+AsiNYWGrwQRB17NBEIMSsWA7ql0GGHafX2JwR1tbK4Tx84+eRwW1GPcJQIjBAYAsUIQS0k4R96mKPEvxYA+t2OioJGjeqfR2CoZhyJwgiBoS5jhOCwNuykGSlrtRAUFUFMZAmNEsQIgaFiHInCVBYbKsPqtGo8glqIilAsjjyatut/hdJS4g7s4YvV3bnyt2uMEBgqxngEhipgWg3VUiYnXU7avlVwyim8P70lh+Yv57glb9Iq568yFTethgzlMHUEhiCw8pLaWMdohADIaHkJq1P6wE8/Mb/pGTx02McAXCSfUuB5v92EoLgYHnoI9tbokHl1jzvvhG+/DbcVIcB4BIYqYISglpKQFMVNfX6DTZu4t+sUMltdwp60LvTjt7LwUH6+vb31IKdPh0cegZtuqnmb6xLPPgtnnRVuK0KAqSMwBIHlEdTGiIIRAiApCTZsjqTrGW34fa4iOhp2deqnhSBHP70CR4HPepDxnm+RrF9fwwbXci6/HK64ItxW1ADGIzAEgQkN1XISE2HZMv3Ly9PNR/d1OY7m7KJome5h5iYE1vcKdu2qYYNrOR99BO+/H24ragBTR2CoAsYjqKU0auQ9HxUFef10z6vIH6cDOjQUG6vXWw/SEgcjBP5xfueh3mE8AkMQGI+gluMcbhr06KQxR3ZiNR1J+EXXchYU2ILhKwS7d9eQoXWQ2pjoqw2PEBwg3quOoF6Ln+GgqY3vRIMVghdfhEcf1f99hSAqCpKT4WvOIXX+9zB5MlcsuIVRvEk8B8oepFWBbF58/9RGN7ja8FxcLo2IpYDGZPMmo5DNW8JsmKE2YiqLayE33wwPPKD/uwlBkybwFHdTEhULgwczeP1LPLlnNJM5r5xHALXz4dYG6vV98XgEOTQmlgLOYzKjeBtuudlrMxF48EHYtCkcRhpqCyY05IJSKlIptVApNTVcNli4hYaaNIEttOHjf2XCM89wUe+1jG3zBKfxAy3+mgl4C4EJD7nTUIQgif0cw1wA1MxfvbqPLlyovc9LLgmLlfWSuvy+1cZ3IpwewS3A8jCevww3jyA+Xk9XNT4a7riDdaTzdYcb2UcyXWeNA7yF4MCB4M970knwwgsHYXgVqcku7kX1+ZvunovLpRHN2cWtvAiA2r4d5s0rix1a97sqaaQ2UlIC48aF79nOmwfNmsH48eE5f1UxHoEPSqm2wDnAW+E4vy9uQqCU9gr27dPLCgogMqkRX3E+HZdOhsJCLyFwftYyUH7+GW67DR5/HAYNqrr9geCsx6jJhFgbSz/Vhufi8okrW7SNNP2nb1+4+GLAHmSsvtQl/e9/cM01uqNgOJg/X09/+CE85z9YaqMQRIXpvC8AdwOJ/jZQSo0GRgOkpaWRWYUvquTk5AS03/r1aUCXsvkdOzaTmfkXsbHHsnJlNpmZy9m791iaNcthIhcxMv89Pr/hTZZHDAQ6AvDLL/PYsSMnKNss7r9fT6tyjW6UlsI99/Rg+PCN9O6tx78oLlbASQBkZPxMTIy7WxDoPauYAYC+nh07YoHjyuarSvXYVb20+OMPjgTao3sUfsJwHuFBlnOk3mDKFDIzM1m1qjHQh+zsbDIz55ftv3VrHEoJLVtWf9PTUN6vBQvaAp2YP38jmZlratyuZctaA4eXvafVQU2kr/z844BYFi1aQnJy4G3OayTti0iN/oBzgVc9/wcAUyvbp3fv3lIVMjIyAtru889FdHlN/26+WS/v00fkrLP0/3btREaOFIkhX7JIlDe5Wu64w97n11+Ds23GjAyvc0Jw+1fEzp36eCkp9rKcHPs82dn+9w30nlWE83r+/rt6rq867Kp23n9fBCSXeBGQDqzR1+nzUOfP13979NC7LV8u0qqVvcnEiSJHHilSXFx9poXyfr3wgrb7ppuC37c67HrxRX3+G2446EOVURPpq3VrbfeECcHtdzC2AfMkgHw5HKGhE4DzlFLrgPHAKUqpD8NgRxluoSHQTUidoaHYWEhuHstkzuMCvmTHmuyyfYINDRUWhu7WW+GYyEh7WU19Yc332PU6NOS5qZfyMWP4N2vpAEBpWkt7m5ycsntghYbGjoWtW+1NRo7UvdpzAncow4r1foTr2VrnjQpXPOMgqY3vRI0LgYjcJyJtRSQdGA78KCKX17QdTqwxgyysBOasI8jPh7g4OPNMeJkbSWEvT07rznoO4XWuoWhXVlDnDKUQWKLkTwhCmRALfKIctTHRVxuei5vLMTzAGEBXBuz/9U+7FcCqVWX3oLJKet97V1sJtxBYhY26JgSmsriW49Z8FLQQZHnyd8sjuOwymEM/buN5VqrOzKEvV/EOx91zYlBFusLCyHLLqqsy0RIC54tSUx5bMlO8AAAgAElEQVRBoc8gnPVaCDw3tYhor8UlKc3g1FP1zMqVZffe3xeqrPmqNDgIB1a6CleGZnXkjCz/CtUJjBD4ICKZInJuOG0A/6Ghtm1h2zYtBgUF2iMYOBBmzYKXuIWTC77lYj7jPCaTtHEpXH11wLl5QUH5W+/MRDdurHrzvHB6BBUJQX1pNVOGHyEoLQU6ddI5vIsQ+GIJgXOo89qMP4/g++9h5crQn98qb9W1QobpWVzL8ScEJ56oX+qMDD1vDTrXq5e9bVwcfMtZzB38GHz6KVx/ffnc0AW30JAVGsjLg86d4d134R//gFNOCe56KhMCtxLJ11/Db78Fdx43KhKCuhL6CBjPxfkKgQg6YaSnByUEdcUjsEbd9c3QzjxTp9tQYwlBXblfFiY0VMvxFxo67jj9/7vv9LwlBHFxeuhq0BXKALP73wt33QWvvw4nnABffllhkd7NI7BKhPv3685HGzbAzJm2EAVKoB7Bvn06E/r6azj3XH29B4tTCETquRB4bmqxTyvssrqAww+HFStImT2NQ1kTVGiotnpPmzbZ398IV8k229NG42CEICcnfF/NMx5BLcWfR5CQAD176swYtABYtGihp02a6GlevoKnntLdHXfuhCFD9EaXXAIffwxrvNtbuwmB0yMAu34iWAKtI1iyRE8ff7xq53HDKQQlJQ1DCFxDQ6DDQ4sW0e/Rc3iff/rN3K3nYT03EV3qvvlm9+3DSbt28J//6P/hCvtVh0dw1VX6q3l//109NgWC8QhqOf5aDQF07AgrVuj/lkcAthAkJ+sS3ebNnoQ5bBisXg1ffQUXXAA//qhrmDt1gv/+t2z/ikJDlmdQnULg9s1lfyXUg8GZ2RcVeQtQbRKCv/6CyZMP8iBFRZSiKMW71rJMCLp10/MRkZzALFoUuo86Zz0va2rF2ceOPUj7QowzQwvls92zx269B9XjESxbpqfWp2hrEiMEtRTfZmjRjgJehw52ZuYmBLGx2lN45RVdp1B2wMGD4Z13dIPxuXPhwgvh3/+GMWMA91ZD1e0RVFZH4FaKc/NUgsFXcJylxtpUGdq5s35EB0VxMSWqfBvGAwd0unkt/0qYO5dJT66kmEi+3tBNp4PyhwHs5/b993raseNB2hdinM82lOMopaZCSoo9Xx0eQThCb6ayuI7hFIYOHez/ztBQ27Z6GhtrexTz7dEDbCIioE8f3j9nApMSL9djX196KSkbVgHeqdFXCOxSkMCkSXDNNZS+OJb/jiktKxW5EWgdgZtHsGuXQ+2qQEVCUJs8guoYeG/d6iIKJbrc8iOOgHXr4JW3YqFPH/Y27cjZTCO+NBe++IKU3Io9g9mz9dSqf6qIAwfghhtg794qXkRF5OfroVMtZs7kSe7GSrfOZ1vVkvVRR8HTTwe3T3V4BBYBtOuoNkxoqA7gbO3gFIL0dPu/0yOwhKC4OLBmnldcFcmQ7HfJu/3fFEyczA1vXshienA9r9ABHaj05xGM4AM4/3x47z0ibr2Ztg9cwQP/9p+TBeoR+AoCwM6dVReCsWN1yMWiKkLw11/wxhtVNiFoDualnDSxiCKi/bZn79pVT4uKYDpncH5rPUz1pTOuZBCTGcZ42rOOU5mBorTMY7IKAHv2+D/3smX640rjxsGrrwafmVZKVpZO5EcfDQsW6GXnnMPdPM3R6PnqEILFi+Huu4Pbpzo9gnC0PDIeQS1m+XLo3l3/9w0NWbh5BDt3UmHp3EkpkTybMoZWRRu4JWosBcTyCjfyNx35gx4cfts5cPbZdLtvEGO5kVY7F9OZ5TzLHbpJT04OC4c8ygg+ZND3NyKl7v5tZZXFvh/WcWbQO3fGBHYxPuzerSs3r7zS+zzBhoaOOQauvbbmSk1V8VJKS3W0L4piiogmKan8Nj172pmjde+XRfUAoPPGGUxmMOO5hHV0YAanM4wJbNumt7UyOr9CIMLLPd+i5a3DiPh7NVB99Tzr13syyddeswf9//57XXT2lExu5QUiKDno0FBVn3F1egRVPcbmzfpjQ8F4lsYjqCNYL5MzA23f3v4f48gjLSEI9sP127bBXpryUvGNHMNcurOYe3iCTbQletdW2LaNuK1/M4q3mLb5KJZzJFEU67F/o6JYMvh+nuRuTlv1Go9FPWwfePt21o75mGNbbmDdOr3IWdJ38wjchGDPnqp5BG4vRFFR8B6Bsyd3TVCVeouXXoJjj4VoiigmqqwpsZPERFsIyoaYIAImTOCLE5/nDp5hH8nspikAoxnHgw/qKgRLCPbv9+NtTprEq0X/YhifcsH4YYB3IaVC8vK0Yr/yineOVFrKst9zSE+HV54+AM89p3tPduumGzzMmgXAWtIZwYfcz5iD9ggC2cctdGOJTnV4BFWtt7riCv2xoXnzAt/HekeMENRy3ITA6kfQtatuFm7hJgSxfvJQZ4bsbP0AiiV05ynu4RymkfncAliwgMmPL6UtmxjFm9zJ0xzHbIo7HqH3iFDcyxO8zVX8Rx6B666De++Fjh3p8MBl/LT9CFJ++grQmcgxx2hPx80jsF4C58uQm+s+9MX48RWHwNxe2IOpIwh02+3bdQvdQL0yX6qSEfzxh55GU+TXI2jUqLxHIAJcfDE/dL+V57iDdNaRzjru4QlOJpPTmM6UKd4jlXill+XLYdo0eOwx/qIT9/AE7XYuoD3r/A+3kJ0Na9fClCm6n8tJJ+kY3o03avdt+3a9vlcvjuybyCcM59Bx92pX99//htNPh59+go8+gqgoerCYqZzDjbyM5Nk3L1ghePfdwOpAsrJAUcpbXA13343syyoXQq2UjAy4/HJd+/7tt7B2Lccc+IkISgI+xqJF3vUwviIfCNa2tTE0VMeGbQotbkIAcMYZdpt7izZt9NSp7m4lQ/B28b2FwBtnAt9NM95mlNe6qCgrw1VcwxuUEMnot97SRY1Bg3ih4Dr6ffsQj/91Ebm8yG/5o5i/NJYksmj22y905xD+pEc5j8CZGebklE8SU6fqzPaBB3QpyI1AhCCYElygQnD//VqkTjkF/vWvwI9vcTAtmSoSgsaNdYdA8BaCnBxbtLLQnVBe4mau4h0+YygX8jl//d2ZXgk5LDxwBHt2FNN8x0odnrn99rLj/x8fMJvjeJJ7GcwkcnJu8Tq/KizUmd/48XYijYnRJZgPP9RtVB99VJf28/OhpIRN3Qcy/M8JsAa49FLdDC45GZ5/Ht56CwYMICczkRe5hemcwQk7vgT09zeDDQ1Z3wv3S3ExXHMNkdFpDOForuYdeBqYOJEh8hSfc5H/9DRnDtxyi34IcXG6x2Rqqn5BzzoLgPcBeI+8vH9WamtRkR5NoH9/rYlg964OpnRvvQvOfUpKdL4TEeYiufEIHFgPI7p8Q5ByWC2FRtl5tV8hsHpigrsQWCEnK1NyS+DWOqu0WEIU1zBOF5n274evvuKrvDM5jRn8oE7nFW7k96UJrKM920mj/9ODWMxRLKErHV6+HWbOpHj/Aa9jA+TmujeHBF0g9UcgQhDMx9sLC3VF4o03VtzUz7LdnzdWGYEIzuuv2xkAOAoMFdQRuHkEpaU6jXzwgfe2+cRzJt+xlVb8wGlsKG3LggOd6cIyWl1+qg7P3H67DtWMGgXPPstHXM7fdGRddCdOJoP9+72P2fL773Up/tprdSb+3Xdagdas0f1aHnlEh3t27dJtoefOZcq10+jPTzw0dJneF6BHDzjvPG3/4PMB+IFT2UA7zt5jX4irR7Bjh755ubn6Ib79Nl0ffBA++aTyd+zHH+Gdd2j6xn+ZyFC20pK/XptBaVwCHzCCQyI2uQvBrFlw8smwZYt23b7+WieiTZt0HGfoUDjnHACGMz6gwonVF9TyBAESJJdzmUJxYeCVBG4eQVSUFphwYzwCB/48An+UlGjxeMvlg5u5ubpn8m23wRdf2MvdhKBtW93D0a2EbmEt833himMSyuxduRJyacxAmcYgpnBak/k02/cXO2lO+k3nMWPsMs5lKqdPehk+f56rlaI/nVi+tztz6M13nEludrty506JyCKeaLKyEsqts3DLUC0hUJQiRPh2rubUU3WlqtsnDwsKdFRixw7dkzU/373MYt2XgGPkfvaviOuu01NfQbLqCNzO7SYEFYUE1pPOFbzHz/TnAAk0ZS/L6AqLgFtv1d8yPekkuynYHXqSWXwi5zKZL7NKKSvXrVlD+rvv6rjg2LFeNcl//63T9yGHoBsgrFqlPwCckMCeCfAL/enVyse4L7+ETZsoTG0Dt4EQwfv8k/sO/BfefhuaNSM/ayAQa787WVnQp48ePfH66/UNyckhNToafvmFM1o1Zhz+v8+6Y+wEUhslsnL0c6x//nOe4U5+vO5U3n9kKkMf7Mw0dTa/Fh5H6SXZRIx5DA49VOfYw4ZBq1a6DW5Sku4NetRR+h7ExenxwIA3m97DyL3P8cHmtUAHv3aAXQBy1hfetPZ2zmMcWx4eCqdMCKi23s0jAHvkAldqqsNDIF+vCfcv1F8os+jTR39BaPr04M7Trp3er1UrPb9rl54/91zvj1WBSNu29v8mTUR69xb57js9//LLev+HHiq/39y5IpmZIv/+t/fyffv0PllZ5fdp08b+f/fd9v//Pb9XSj//Qn4+7f/kMy6UVRxWtnJvZIrIUUeJnHaayODBIofZ6/ZENRPp2VNKDz1U9l8wQuSDD0Ty8kRE2+d7/vnzSmXBqXfKAeLk+9hz5aIzsrzum++XywoL7WV//ilyaOIOuZK3ZfcJgySbRpKdeoi2a/Roke+/FyksLLvHEyaIPP20yNKlgT0z6zyzZlW8XWlpeTuvukrPT2KQLKCnDBlS/trvukskLk5vb937pKTy2/n+IigWELl/6Ep5ltvkhzu+rtD+kbwjAvLwcd/qFXv2iHTqJIVJSSKLFrleS+PG7td6yy16/fXXu6/ft88+byJZsjrCThtL+vxTFCUSH+/Z+Jln9Lpnn9WfMhsyRGTcOPnp229FjjhCFscd43XdsnGjyJQpIvv3iyxcKAVEyzhGyWefed+fUaNEruMVEZB8YqQ0MVGkZ0/9IJs3F2naVGTBgoofqoj0T18vWSTqg15yicz69FO/244ZY7/PIiLyyy9STKRt1GuvVXq+khJ78xtvtJf7pi0vZs4UOeoo+e399ys9vj8I8AtlYc/kA/nVlBAcc4y+I5mZwZ1n3z6Riy6yPw35++/lX3DrM3WNGtnLDjvM3t96Z0S8M23r989/ikREiIwY4b1882b/50xMtP8PH+697tVXRR5+2J5vwTa5rvF78knSSJFBg0T69dPfTxwyRP4Y9pjcxxj5JPkakbPPlrVHni27SfHs2ELkuedk+WMT5Rlul0kMkjP5RkBk/Y1PiYDM5DgpVpHyXeMhZd9jLC0ViaJQ+pMp8uijItddJ/knniZ/ky5/ky55hxwuxUSIgOxPbS+vcq1kNrtQK2fjxvrc0dFSoGJkOUfInEGPSgI50qxZYM/Muu4ff/RePnOmyGWX6RdXROTAAf9CMI2BModj5KKLvO9tTIx9b4uLRW67rXIB8P3df7+evvGGt31XX60/0Wht15ztsoG2UoISefBBLd7R0TL/pZfKXfOvv1ac8Vx2mZ3W3NixwydNJ+wVmTZN5MorRUC+5zTp3HijLgm1bCly0knljpGRkSHy0ksiIKMYp98JskUOP1wEpPTQjlLaooVsppU0ZZe89Zb3Oa+4Qk8vO3KBNGGP7B33qb3y0ENFVq50N1601rz1lv7fsaPIqUyXP7sMFUlIkIKUFL2BC5dfrg9/3nkisnixSGqqbEg4XJqwR7Z0HiCSliaSm+v3vCIiBTmFMoSJ0off5b4LV5Z9ltTreRQXa0GbOFHkxBP1ivbtZV4AQuMPIwQSvBD07avvSLDfHxYRufNOKSsNffON40Vtrt+Tn3/W652Junt3vX1enp5//HE9f9NN5TOGM87QU8/7Uvaz0v2HH1acsRx/vPf8BReI3Huv97KuXUVatjxQ7trefVevb9lSz//rXyJQKmPPnyFyyillB8gjVvbQRARkFv2kVClZ3nOYKErks+N0CbH0H/8QufFGKbxgaNm2AiJNm8qBLkfLh1wq7zFCdp58kfyfekiOYqG88XqpgHZURETnzl9+KXLPPfJxmztlOqeKgGyitYyMfN/OxZ0UFIj88ot+0YqLy047bZr3ZlapffduPb91a/nM0xKC7zlNfuV4GTbM+z4mJmrvBHQB98YbA8v8nT/ru7wvvOBtn9u2jdkv3zS91F7w6KOuaf+++/Tq9HT3NGylsSFD3Ndv3Oh93shIz4rSUpl41puSS7wWJJDSyEi5+7T5Mm+e9zEyMjJEsrNlbuIAEZD7GCNTOEdEKckZeYMcIE5KIiLLChOWY2H9LvVc5nnn6emypaX629GjRols3+5uuIfu3e1na3nLd94pIn/+KcUxMfqlcEk71rtzX69vdMGndWsZcfxqAZEvbv3JPpBbuisqEtm4UYr72S/gXpJl9AlLRHbskOZsl77M1t51t272haalSfajz8nHr2fJp5/OrPC6KiJQITCVxQ6sMF9VavDj4nS8WUTXU1kkJuohh048kXKVilaFs1VZ7Kwj8A05Wn17Vq3yXm5VHq9cqe12xjGdeJqBl1FcXD6un5YG27bFlw1xYOHb01lXTCqeWXgqzJgBf/7Jby/OIZksWrKNZ7mdpuxhy/k3MPXCdxEi2Dj0Dq7lNUo2baPk/Q/ZOXUOX3IBFzJRH3j3bn57ZT6X8xFX8D5//uczHpKH+YOe7N6jb0ZZ8734eN3T+okneL7105zODJ4e/CtbacX/Sv6p2/p+/rl9AZ99poPiJ54Ixx+PpKXxNlfRii3l6gisSm8rrm9dcxrbdBOlM8/kmozhDGJyWR2Bb3qJjdUhcdD1BFX5wJA1llUglZk5JHJL6od6FL0pU7SdLlTWxHbnTj311xTUN72UlHiuTSl+6jSKrizlicgH4K672PzO9zw142guvtjlQI0bc2vXGXzCcB7nfs7la3j1VRZc9TKt2MqgXpv5joFA+To16162bq2nu/coGDEC3nzTvml+2LZNT++6S3cIA08dUbdurBs5UteFDBqkK7h//71sv12bC7iV53l84Vn6Zf3hB7Y31gNBrW7dH0aPhmee0WOLzJihDz5sGDRtqluetGtHxJLFPMb9PM+tNCGLN2Z2gxYt2EEav3GcvoYdO+C993T9xoYN/HHybVx6bRJr1zaq8LqqA1NZ7IJI8PvEx+v9ioq8haCR4xkmJelm2859QGfg0dHezUebNbNfTPDfy9R6aVeu1L2gk5O9Wyk5GTLErrguKSlfUdrS883144+3K8KhfGumtWv1dNMmKC5RqC7d2LkWrIZDd/Isd/IsM26AAs/HbtLT4Xau5aoJ1/LII7oxh31j9MTZBNGZ6Vh9NdzG07Fsm8kJ3MPvjIj9jPeix8BFF+nRX5OT4d13KT3mWFbc/DpHdiqk+KupDP9kPMMZz64nzoYDF+ib17w5CQXNUMRSvHgdFPxNXMbffMDvDOUz+K9uR3j49j+ZzARKUfxI+a8GxcRUXQhiYrQYpabqwkBenhb7xES7IY8viYmwP1vpTKwCrHvq74uqVnrzt96tQUBenk67ubmwjg48UPoI/34Kclfa690oLInkSv5HDIXMif4HT117LYU/6Ca1exwtinzTfTkh2O1+fDesiux33vG2H2Dj8OF07NIFHnpI99UAGD0ayclh8fqJxFLIr0ln8Y81X0FMTFlB7cABdOe8f/xDN8c9/XS9Ij5et86KiYFVq8h67GX+00/3BfqAEfRmPmOfyufuu4W/OZSpyzrqCm9H8zdLuBMSQt8DzQiBAyvjq8qAZFbLkfx8u7QB5YXAbR/Qz99XCPbssVsY+BOCnBxdQp8zRxeErSGM27Sx7XjzTS1AAwcGJgSgCyfWvHO7pUt1s07rGK+9pjuqegZV9cLZfNTyVDZtKt+RSERnes6MxvnfetmdJdodO3QJz8q0tm0DIYJJccNg/hB+PWsM/b57jqhIYPRorskfy1v3x/Dnn/CP0RfTgge4ibFcvXIiXG57D2X5yhkeu4EEmvEOV3HdytvhsMO456oi1P/e5v94iLV0oKREOx2TJ+umob5CUFFroRYt9LWMGqXz8REjtBAkJur0ceCAPWb+DTe4H6N9+8DG1beeY3a27hfjGSUb0M/AKqQEIwS5uTpdWyItotOFVUDxJwS5uVBAHBfxObER8BR2Gvce8sR7v4MRArdOd2X2KaVbZ914o05MjzyiB3Jq1Ig3+Rc/cCqr087mT4/7btmYm4tWmBEjdNPUN97QHUiuv95r+NjCHfY5F3I0CzmaMVfAWGucpS7lbbOegxGCGsZS+ap4BFURAud3EHyFID5eZ5jWy+FvSOrcXHjsMZ3BjhunC8Ggm39bdvTtq3sXWyV5cA8NOYf63bTJFgLny2xlHn37avF5+WU97/YVNWuIiYgI/UET0DZZH/OxOHBA3yen4LgJAeht4uKgd29to3WsrVv1NCICJCqaE394GHi47Fm+5Xm206fre5nF4dzMWKLHvMC1xy/WueDOndz+z53Ekc/oMemkn9qRSUsO5fxRzQDFdYfpY5RGRvMW1zKO0QiKIcXaAbH6CMTE6L5MULlH0KGDFoKuXXVz/bg4LeyNG+s0kJdnhzT8dUZs315n7CUlFX/Q3TmkSPfuMHGiPSr2nj22ncEIgeXFzZ1rL/vkE/tbCv6a5zrDTwUF+p2zPD/nPr5DuFj7VbsQWERFMW9bW2Z1G8fNGx9k2dam3HRsAgkJkOqwy7U5d1yc7sjmglthoLKwX016BKaOwEF1CEFenv4ujYVTCJwZLXgLwe7dehTJn3/WicwSgsrIydEFkE6ddA9o68U86ih7G+s4zv4RxcXlX1Jnp6SNG+3/bi/z0KF66jZSZlqafY7iYn3eZs10BrlpU/mXYvZsPeRAZR4B2Jmi1TnNOr+1PCLCu3Nbv37eL6vvUOF5hZG62+jAgSzsNoLnuZ3/8m+2nnwp9O3LTmkO6IRheYpW+tBVbKrseqz0E0xo6Ior9LRvXz11fg7VEgJnwcLi5JPt/9Zgib79NHzxfY5//mn/t+5fcrItBL/8oq+pVSu4+mr/HsHGjfp5WCP1jhhhh9gDEQLQz8x6zhUJgVUgSk3V99nXY6gIt/5BbvYdc4zOz/c2asuWfbrvTMeO3qFLKxMPtEe1mxBU1ofFEoL4+HooBEqpdkqpDKXUMqXUUqWUu4SGgdRUPQ2kZ7EvlhC89ZZ3D1ynEDRt6r2PUwisUU7nzPH2CJz4flIT9Au1f7/dq/m++/TUGeaxjuMsEfkKgeUZ9+qlfXxnL+D8fG9vZvFiGDlS/7dCAs7M2rqPTiFQSoerVq4s/3Kffroe9sYakgH8C4G/cfetzD8y0juENGcO/PqrPe9bae4s2R19dPnlTk/Meul9e1FbGb0VWnRWFufkVCwEAwboe2R9L/oSPWIDKSn+heC557y/rjZQ16vy22/+zwPlM3JngwRLCA47zBaC996z173zjn+PwLqnTnGqDF8hyMy004Uzc9+50y79g/08YmN1Onv66cA/6VmZR1BQoMP0FnPm2PV9vkLgr4OnPyrzCNzSiC0EoR+cKBweQTFwh4gcCfQDblBKHRkGO8rx9tu6l2u/fsHvawnBSy9pN98zpEmFHoGzjsAa8n3vXp1A4uLKC0Hv3np6ww12ArTGrrEy6scf1yVW50iplkj4DkvtfLHj4vQL9+yzf5SV3C3y8rxFqGtXLWpxcXYCdm5vXadTCKzjTJrk3dPaiTNzC1YILCIiyoc2djjis87wGNgvtHX/Lcp/HMg+rq8QWC+5JQQxMfpeRkbCN994v+SHHOK9b0yMdwb1+OM6SpWaaguBs/EB6BESrNATaBFJSqpcCCoqgVqhtU6ddIZXWmp7dhb+PIIlS/Q1OIW0IkpL9XWddlrZaA8MHGg/A+fz27XLHtcLvIXAEo5AP+lZmRBs3KjTh/XuzJpl35eOHfW2ljcYrEfg9LDdzu0WJsrO1oXSmJgqhCiCpMaFQES2isgCz/9sYDnQpuK9aobUVD2kS1XGdrcy9f37desc60V1vrAVeQRNmuiKw927dUbQokV5IWjTRrdUGzhQ76tUeY/AwkrMzgGtnC9CXp53xmDZopQe8sI3NBQXp8c9++ADfTyrhG/h7DbvTwgscbRssT4VaYmMMzN2luqDEYK8vPLNJN1CK85rA6/WggD88IPOgJ0egSW+/jwCi5gYnYneeKOuqN+wQcfxb75ZD+jpu62TyEi7FaQ/j8DyuJzH6NuXcs1+LXbv1pmrb0buDAVaHkGnTjqzy8srXy/lTwhWrdIebSM/rRx997MyzzPO8P5yp1tmWVzsnc4sYY6N9b7vY8ZU3sjDLTRkZcCzZqVy/fX6/5QpOty2YIFOA0lJ0Ly5Xufbgi4Qj6C0VHt+vjjfP39C4G/8suomrJXFSql0oBcwx2XdaGA0QFpaGpmZmUEfPycnp0r7VYUVK5oAPQFo1Wo+v//eBmjJrl3ryczUxdAdO1oBR5Tts2PHOjIz15XNx8cfw9KleWzblkpR0Xry8uIAO8aTlbWVa67RzYJ++gmiovozadJ+tm2LIy1tH5mZK8q2XbMmDehCamoBmZk6h8jJiQRO9Jw7n4KCIkCntLi4PDIz55CTk0Ni4j6WLoXMzEUAbNhwJCKNiI6eS9u22o3X+/QCyldkFBRsA1qyZMkK1q9PQqQZmZmzGD48gsWLuzF/flNOOmk75523gUmTjnEtVS1cuBGwxz1q3LiQnJwYZs9eSdOmW4EBZeuaN89n506txNnZwk8/LQTs4unvv28C2pY/CbB69SYyM1czdeqRgN0O/bnnYMOGjezfH132DDIy5rJxYy5bt3YH7Nx49+59ZGYuYt68FOAocnP3kM7n41oAABjYSURBVJm5mA4dkhHpxZIl0KPHPi64YBGZmc2BrmX7zp07izVr3L+XWFDQk61bIT8/kl69ilm4UCvsokWZHlHX9yAzM5OWLdP54Yf2fPPNr8THl3il/ZNPHkB6ei5RUaU0ahRfNrDg0qXbytLM7793JC6uNdnZa4DD+e67WSxZ0qnsniQnF7Jo0WrA23mfN28ZCxa0IzW1kNWrt5dbDzBlyiyaNStk+vQ0PvzwaJ59dhZwPJs3ryIrq7hsn02bHOMlOVDKfn5WgWP+/Fm0bduTTZt0KeKBB6Bly7l07Og/Z87L642V3p95ZhHTprVixYokMjLmcP/9A8q227BhLlFRnVi/PoKcnAKSkxuzefNm4DDeeGMRkZFCbm53IIpt2/aTmbnA7XRlbNsWCxxXbvmcOYsB/bGiH3/8jVatvF22v/7qTHR0k5rJxwLpdRaKH9AYmA8MqWzbmupZfDDMnGl3Ciws1EMBOHsLi4h86ugNDyKPPeZ9jBNOsIf2eeMNu4dxXJye3nST9/YtWtjH8h0fZvx4vfzYY+1l2dn29ikp3h0Z+/fX22RkZMhll4l06GDvd+65Ir16lb9mq3en78/qwTpunL4PrVvb+9xxh153zTUi69aV3zcqSk9HjvRe3rFjtoDIk0/q3vzOdSed5D0/aZL3/IUXes87h9u45hptl9Wr3PkbMcLu6Q92j/PTTvPerl8/vdw6rzUmzZ499jannKKXTZ3qva/Vg9mNs87SI2okJYlcd53uoezsFWwdQ0T3kAYRK8lbad85LESXLnoUBmt+0CD7WMOH62c+YYJet3ixvq89euiexnFxIu+8U/4evfmmSEKCyK232vv6/mZ6OsZaQ21Mnqyn774r8vnn7vs4f088UX7Zrl36/l5/vb3st9/838tfftH3ztp2+XI9bldUlMgPP3gfe9s2nbZ79tS9ik8+WcoNdWGl065dvc+zdatOb1mOYbW+/tr9uiZOtP+7jZF1/vn6HT2YfIza3LNYKRUNfA58JCJ+IsZ1C2e831nZHGhlMWiX3/rmb5s2cMIJOo7ayjMapG9l8dSp9n/fpqniCSs6K9qcrvH+/d6uqbNyuW1bHfO3XG0rNOSL5S47GTOGMhd79Ggdc3XeD6s/QVFR+ToT0PckOrp8hXJKSiFRUTo05Ntk0PfarbiuhW9o5cEH9f1p3967bb0v+/frwSu7eNp4+wsNWXUE1nKr5U9Kiv0BI+se+D5z39CQk/h4ff79+3UrsJde8u4vcPHFdnjNanVkhYe2b49l3z7vkS3z8rzDSs77OH++DodYLX/WrdN1K4cdpmP/+fnu9+ivv3So57DD3K8lMtJOp1ZYzxrSu1GjwEaNdaZhi9hYfX+PPdZe5q95bWmp7lRufbkPdMilSxf97KZM8d6+WTMd0s3J0WmpVavy7571zLds0SEtEd10u1Ur3an9k0/sbZct01PfdFubQkPhaDWkgLeB5SLyXE2fP1RYCdqaWhmx88WvqPkoeL+kbdvqXurTp9sZrm8Mtk8fO/7vmxlaMV9nfNVZR1BS4l1xaomNde6iIrv1htWc1RdfIYiN1TFw57Y//ugtQNY+WVk6kfu20IqL08dxtvQB3ZY6JcVdCHxf0muv9Z73rWy1vjRnDQsClBvPH3Smu3Onvs/gv7LYilVby50Zou93sH1traiFWny8LT49e+p6GWf91YQJ8JX+GB1Nm+oWL4sW6d/IkcfSo4fuW2KxYYPO5Cys+7h1q87Q+/cvLwTOuiq3pppWB8b27d2FYMAA20Yro/7+ez1NTi4vBL71H+BdSLGwxNaZbv3VH7k928aNoXNn/d+3biUyUr9r2dk67bRu7d5i74wz9DkPOUQ3f7au02kf6E6YLVuWLwg6M3+38Gi9FgLgBGAEcIpSapHnd3YY7KhWrBf0xBO9lzvHofFNCL4vgXO9MwO3MnnfxKiUnen6JhjrBXF+9MK31URJid1BzPlCWZ2/Nm7ULXl+/dW95OY7tItVKehbKecmBDEx2n5nxgT6BYqN1ZlGVzuUTny8FoKpU8t/Jc06b8+e5W0E/TJHROjWLdOm2fchLs57/CTfkqfVzv6YY/TUKhFX5hE4M0SrxGr3EvXetzIhAH2fnL2A/dG1q850nnoKYmJKKS3VrZaO9ITtS0vdheCXX/S0f3/9fOLjdV+Y3bt1pbclBM7WV9bzs4Yzad7c/Vr69tWVySJ2Rm3d18MPL/9BoV69yh/Dt/WSUnaacjb33LXLvQ+Qm6fQqJEtBHPK1VBqodi+XactN48A4Nxz9Tc1wNsDANu+0lLtlbldVyCthuqtEIjIryKiRKSHiPT0/KbVtB3VTefOesiRCRP8bxOMR+D8bwmBW6sMK4H6egQXX6x7ezoH/XKKUsuW+uW1MglfjwD04FxW6CHQ0BBULAQnn6x7Qr/wgp73FQJnk9RLL7Uz7YSEYhISdJjHan46caL2apYu1fO+zRfP1x/UorhYv9jOZr2gM75vv9W9o/fvh6uusivCnVhhF0s0fFvB+LYRd7YUO8UzFJHV1t53WJGKBji00sehh/pvkeOka1ed6a5dCx065PL773r8tM8+s7dxpqs9e/T9tMJNXbvqTDY93e5417y5nbacQiCibbKEwOow6EtKii5w5OR4l9jj43WBw7dJq9Wc1IlvgSM21i54depke7Y33aSF1/f5uAlBVJR+Tpb4p6R4q7vzGfrzCBIS9Bhzt9xSvmd9bq5Ol5GR2ts626Wo29A9gnqJUjo2bmX2VsnE6cpXNMQE2Jlenz7u+7m1g/bnEShlhzTcWLdOd3y77TZd4rM6JYEtBJU1VKiKEERE6MExrZfbesGsbWJjbVf+0EPt5Y0bF7NIN2LihRf0p3iHDNGZlnWvfDsWffGF/TzcXqg7PF/5uukmPU1K0h8B88UK78yapQfL8+cRXHop3H237gtgYYmItY9Vao6M1EJWEdazdQxZUyFHHqlFdP58SE0toHVruOYau7Mi6PtdXKw/u9iokV6flaXtss6Xng4LF+r/TZvaHoGz7kVEH8vK3CsSAtCis28fxMXpZj+HH67Tgq+XnJSk6xCcndN83xvf86Sn257FvHk6/W7dqp/HzJkVfyfcEoLGjYt59FF4/31r3t6mZcvyNoCddk86qXxhYOxY70KYm8A5+0vk5en08Oijdi99IwT1FKV0aMIqlfqWsk88Ub8czrgu2InQrbLOn0dQGVbPzH799IviLHU1b65LWk7cRjR1vixOfIXArTTltAPc48Dp6XbpLimpuCz0c8MNuv7EEoApU/QLfNRRdt0I6PXWi+T2QrVv792Jze0eWh27kpO1t3fuuf6FICYGnnzS+zixsfDxx3ZnL+t6u3bVx6oIK2P2N7S4L1YoragImja1jYyPt59JXJwWoR49tLe3dKkWguRk+362bWuXUJs0sYVgzhx7bKfSUttLiY52r+8BO6N/911dR9Gjh86VrbBMr17eMfrERO2p3XWXvcw3fOT2fWrLi2zVSoeIpk7V4Zqzz65YCKx017hxMQ88oIfH0PP2Ni1aeHvMFmd4BiZs69IyeelSu5J4/HhvMbZw2nXggC5IPvigbhRgVc67NagIBUYIQsTjj8Pw4TrDcnLWWXZc09cjOO44nan4xhOtjMVtMDDrGIGEDgIlIkKXrJy4jW5plaasOKmFr+dy9934xbfSz9kpyKq4BGjcuIjp03Xs2ldoDj/cfoF9vRTr3vkrWTm9JjchsF5EZ0jFt6NVZcNMX3KJ7Rm0bq09GqcA+cN3pM3K6NzZzsxTU73Vykonzky0bVsdGtqzx7vzovNamzTxvi+WeFkeAWhvQKnyJfVu3ez79/DDlo3ZHHnk/7d37jFWVVcc/hbjwGgZwAGUZwISR4JoZOJjaikhmPoYSfGZUEtKfLXSqqgx7SBJQ9XGtqa1NKkabS222qrVmhISIyqaGmpBQWacUUew0rRqpY9g1T9kGHb/2Ht79zlz7nPmnnOZu77kZu4998yc36zzWHutvffauZQZ5GwDufMU6mxosP08/hwnOQJ/3dx6q/3po9n+/vwFGyHnCJqboycxdASTJ0dtcsUVtv/Mb5teYDpsW9vgZ4DHz4hubLQpJt8Z39VlX4cORWuGVRN1BFViyhTbIkl6QPsbJmkkTtKs5htvtNUt/bDMEH8zllPzPl9LPiT+UIyXRgDbytm509ZXirN/v33AbN2ay9Un4W9q31cQzlAOOwnHjTvIpEnF0yTxnHuhiACijiPJEfhzFKYw4i3MQmWmk1i9urRWvi8LndQaTeKoo3KNjLgj8NdJGIXOnGmvm927oxVhw/81jAgg12fk+wggd+5CR7Btm21MxFu0zc399PbaocWe8Jr312Y8Wp46NXd+khyB54wz7N/YssV+7u+Pnq9Fi6IpOX+NxSt8xisChBo7OqJRQL71cJqa4KGHotuSytcsX26jBrDXY3d3bqZ7ODy2mqgjyICwwmQptLTYDr94xyrYwmArVkRbVYV48UU7Nr0Y4YV/5ZV29EkSCxYk3wjjx9uHwJlnFj6Ot4VPK4SOINTQ3FxZ4a1ijiCMLpL2SXIEcSpZgawUfARYqMUZx3f+t7REe0z9/xFec/5h1tNTOCKYONH2o9xzT27dFRjsCEL7zZ2bG+sfUuw8+r+RdG8kRTVxZs+2cxp8ivDgwagjWLo0WtbCRwTx0UahI4hHuPHSL0mlK8DOqfFzUDxbt0YbTtddB52duc8rV9roe/Nmq62ccz8UdD2CDCgUEZTLnDm2/k+pLFxY/jEuuqhwq3Qo/4fPnfqW+cCATSPEx36PHVv607a7O5fH97qLlfyFwh2C8TUUQsqNCErlzjtti/Wcc0r/nRNPtH0m+SKC8CHqhwkfOFDYEYjYvDVER7r4h6h/aE+fblMcJ52Us2XcgSYN7wxJSg15/HEKOYKxY60j8J3dEJ1IFk9f+Yigvz/aJk6K5Bsa7PVZ6FpYsSIXBSQNphg1Kvq3vV0fe8w20s46y656uWmTnQ9TSd2zSlBHkAHD6QjSIGmST8hQLtbbbrOtphkzbPXXgQG7WmCcceNKf9r6UT5gW2VdXXbRl2IUSg0VeoAlpeyGg5kzYf368n5n2TLb+TptWtTz5UsNeUJHED684y3z8EF6/fU2/RnOAo/3F8UfqJMnJ1SuC4hHBOE94p16Upqyry83g7y93T5YPeEaFPHozbf8DxwYlbg95MgjbZRWaJ2QDRvs0seffJI/ZZTkyC691L6MsRWQ+/rgrrvyH2e4UUeQAeWmhrImKSU1XDQ12c43P85+YCB5v0pTQ9OnR1uHhUhyBP7hky/98+yzL7BkyeIKlFWH9nbbUfrCC9FSnEkRQVjqOl9EEMenSW6+2R7r7rsLp//CRkJfH7z3XoEhPAyOCEK911xjhzmHDszT2pqbMX755baKsCdcgCc+4stHNdOmRWd0JTmCY46xjiApWpg716ZcGxpy0Wc5jsAjEtWeFuoIMuDCC6G39x1aWhLGlNUQo0bZkQvFIgKAO+4ovVMzCX9z5XMEo0dXsJB0mfiH0JNP5sqB+3WC4w+Q1att6zte9qFW8S3rMJ8tAiecYEtSlOoIIBodrVpVuobW1sHlPuL4h6S3adhYGjUqOpM4HxMm2PTY0UfbnHu4clvcoS9YYPc94oi3CavhJzmCp56yw5STrvOXXspFRv4azjfPxv+PwznSb6hoZ3EGzJkDK1f+reYfIBs32s7BUpbM7OzMLbtYCb7FWq18eyHuvz9a7uCCC2wH+S235P53P4fBd8bOn1/eilxZ4+0b7yvxo5fyjRoaDlpbiw8a8Ph7YsoU22B64onKjrl0qS3auGqVbaX7CV1xh+73bWqKNjT8Qzq0RWurnRWfdN9OmDB47k0xR5DWZLFSUEeg5OX88+3ohTQclr/xii0uUg2uuipXPC0f69bZmks9PTaNtWJFKtKGDe8I4qUMfL49jMQqWaq1EH190SqopdDQYGeGl+pA8nHTTfZ/9kurlhJRgI0Ibr89V4epHJ57zjqgfCkgH+XUkiPQ1JBSE/jURTw1tHevvZH9mPqsaGy0LUzIrS98OHHZZfDww4PLjpzg1klKKnqWZh/Wjh3R5U6HCz/R7eKLbemKeFHIQqxdW9kxlyyJTpjLhzoCRYnhc7LxEUM+dZG1Izjc6eiw0VY8urv6atsfcsMN0e1vvllaSnC4aGsrfc3jShCJVuLNEl82JV5VNUvUESg1QWNj8THmytBISvGNHm3r28TxkYIy/LS3w5o1g4skZok6AkVRlBRpaIhWqK0FtLNYURSlzlFHoCiKUueoI1AURalz1BEoiqLUOeoIFEVR6pxMHIGInCsifSKyR0Q6i/+GoiiKUi1SdwQi0gD8HDgPmAd8RUTmpa1DURRFsWQREZwO7DHG/NUYcwB4BFiWgQ5FURSFbCaUTQf+Hnz+BzBooUUR+TrgVzb9WESKlAVLZBLw76J7ZUOtalNd5aG6ykN1lc9QtJWwOnYNzyw2xtwH3DeUvyEirxhjTi2+Z/rUqjbVVR6qqzxUV/mkoS2L1NC7QLjG0Ay3TVEURcmALBzBy8DxIjJbREYDy4GNGehQFEVRyCA1ZIw5KCLXAk8DDcADxpjeKh1uSKmlKlOr2lRXeaiu8lBd5VN1bWK09q+iKEpdozOLFUVR6hx1BIqiKHXOiHUEtVTGQkT2ishrIrJLRF5x21pE5BkR2e1+Hp2CjgdEZJ+I9ATbEnWI5WfOft0iUrWFBPPoWici7zqb7RKRjuC7NU5Xn4icU0VdM0XkeRF5XUR6RWS1256pzQroqgWbNYnIdhHpctq+57bPFpFtTsOjbqAIIjLGfd7jvp+Vsq4NIvJOYLNT3PbUrn93vAYReVVENrnP6drLGDPiXthO6LeB44DRQBcwL0M9e4FJsW0/Ajrd+07ghynoWAS0AT3FdAAdwFOAAO3AtpR1rQNuTth3njufY4DZ7jw3VEnXVKDNvW8G3nLHz9RmBXTVgs0EGOveNwLbnC0eA5a77fcCq9z7bwL3uvfLgUdT1rUBuCRh/9Suf3e8m4DfApvc51TtNVIjgsOhjMUy4EH3/kHggmof0BjzJ+C/JepYBvzaWP4CTBCRqSnqyscy4BFjzKfGmHeAPdjzXQ1d7xtjdrr3HwFvYGfGZ2qzArrykabNjDHmY/ex0b0MsAR43G2P28zb8nHgLJGk1ZWrpisfqV3/IjIDOB/4hfsspGyvkeoIkspYFLpRqo0BNovIDrGlMwCONca8797/Ezg2G2l5ddSCDa91YfkDQeosE10uBF+AbUnWjM1iuqAGbObSHLuAfcAz2AhkvzHmYMLxP9Pmvv8QmJiGLmOMt9n3nc3uEpExcV0JmoebnwLfBg65zxNJ2V4j1RHUGguNMW3YiqvfEpFF4ZfGxnmZj+OtFR2Oe4A5wCnA+8CPsxIiImOBJ4AbjDH/C7/L0mYJumrCZsaYAWPMKdiqAacDc7PQESeuS0TmA2uw+k4DWoDvpKlJRJYC+4wxO9I8bpyR6ghqqoyFMeZd93Mf8CT25vjAh5ru576M5OXTkakNjTEfuBv3EHA/uVRGqrpEpBH7sH3YGPMHtzlzmyXpqhWbeYwx+4Hngc9jUyt+Amt4/M+0ue/HA/9JSde5Ls1mjDGfAr8ifZt9AfiyiOzFprCXAOtJ2V4j1RHUTBkLEfmciDT798DZQI/Ts9LtthL4Yxb6CujYCHzNjZ5oBz4M0iFVJ5aPvRBrM69ruRs9MRs4HtheJQ0C/BJ4wxjzk+CrTG2WT1eN2GyyiExw748EvoTtw3geuMTtFreZt+UlwBYXZaWh683AoQs2Dx/arOrn0hizxhgzwxgzC/uc2mKM+Spp22s4epxr8YXt9X8Lm59cm6GO47AjNrqAXq8Fm9d7DtgNPAu0pKDld9iUQT8273hlPh3Y0RI/d/Z7DTg1ZV2/ccftdhf/1GD/tU5XH3BeFXUtxKZ9uoFd7tWRtc0K6KoFm50MvOo09ADfDe6D7diO6t8DY9z2Jvd5j/v+uJR1bXE26wEeIjeyKLXrP9C4mNyooVTtpSUmFEVR6pyRmhpSFEVRSkQdgaIoSp2jjkBRFKXOUUegKIpS56gjUBRFqXPUEShKEUTkz+7nLBG5LGs9ijLcqCNQlCIYY850b2cBZTmCYHaootQs6ggUpQgi4qtW/gD4oqtbf6MrYnaniLzsipZ9w+2/WEReFJGNwOuZCVeUEtHWiqKUTie23v9SAFdJ9kNjzGmuauVWEdns9m0D5htb9llRahp1BIpSOWcDJ4uIrwkzHlvH5wCwXZ2AcrigjkBRKkeA64wxT0c2iiwGPslEkaJUgPYRKErpfIRdGtLzNLDKlYRGRFpdhVlFOazQiEBRSqcbGBCRLuxat+uxI4l2ujLG/yKFJUcVZbjR6qOKoih1jqaGFEVR6hx1BIqiKHWOOgJFUZQ6Rx2BoihKnaOOQFEUpc5RR6AoilLnqCNQFEWpc/4Pe4ymc+uRzQ4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curve\n",
    "plt.figure()\n",
    "steps = np.arange(1, num_steps+1, 1)\n",
    "plt.plot(steps, losses['train'], c='b', label='train')\n",
    "plt.plot(steps, losses['valid'], c='r', label='valid')\n",
    "plt.xlabel('iter')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.title('Learning curve')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 839,
     "status": "ok",
     "timestamp": 1535234591956,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "HP6PEVP2kVvX",
    "outputId": "1dfe2efc-8657-4dda-cbe8-812134d14802"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot F1 scores\n",
    "plt.figure()\n",
    "steps = np.arange(1, num_steps+1, 1)\n",
    "# plt.plot(steps, losses['train'], c='b', label='train')\n",
    "plt.plot(steps, f1_scores['valid'], c='r', label='valid')\n",
    "plt.xlabel('iter')\n",
    "plt.ylabel('F1')\n",
    "plt.legend()\n",
    "plt.title('F1 score history')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3189,
     "status": "ok",
     "timestamp": 1535235119405,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "-gjNTl5a30Kq",
    "outputId": "f798a9f9-36bf-4561-b048-790efc4bf867"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: ./tmp/elmo.ckpt\n",
      "Whole model saved in path: ./tmp/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "elmo_vars_dict = {v.name: v for v in elmo_vars}\n",
    "saver_elmo = tf.train.Saver(elmo_vars_dict)\n",
    "save_path = saver_elmo.save(sess, \"./tmp/elmo.ckpt\")\n",
    "print(\"Model saved in path: %s\" % save_path)\n",
    "saver_all = tf.train.Saver()\n",
    "save_path = saver_all.save(sess, \"./tmp/model.ckpt\")\n",
    "print(\"Whole model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score on validation: 89.38\n",
      "Learned ELMo layer combination weights:\n",
      "[1.0097947 1.0155122 0.9556877]\n"
     ]
    }
   ],
   "source": [
    "print('Best F1 score on validation: {:.2f}'.format(best_valid_f1*100))\n",
    "if TRAIN_ELMO:\n",
    "    layer_coeff, scale = sess.run([elmo_coef['layer_coefficients'], elmo_coef['scaling']])\n",
    "    elmo_params = {'layer_coefficients': layer_coeff, 'scaling': scale}\n",
    "    elmo_layer_coeff = np.exp(elmo_params['layer_coefficients'])*elmo_params['scaling']\n",
    "    print('Learned ELMo layer combination weights:')\n",
    "    print(elmo_layer_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 518,
     "status": "ok",
     "timestamp": 1535235043959,
     "user": {
      "displayName": "Konstantin Ostrovsky",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109832482076388645622"
     },
     "user_tz": -180
    },
    "id": "CBYNbQdkIo5B",
    "outputId": "59b9d390-c324-4d29-cea1-30fa7d3cb5f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0' shape=(1024, 16384) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0' shape=(16384,) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0' shape=(4096, 512) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0' shape=(1024, 16384) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0' shape=(16384,) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0' shape=(4096, 512) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0' shape=(1024, 16384) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0' shape=(16384,) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0' shape=(4096, 512) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0' shape=(1024, 16384) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0' shape=(16384,) dtype=float32>,\n",
       " <tf.Variable 'module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0' shape=(4096, 512) dtype=float32>,\n",
       " <tf.Variable 'module/aggregation/weights:0' shape=(3,) dtype=float32>,\n",
       " <tf.Variable 'module/aggregation/scaling:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo_vars"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "12. Finetune ELMo all params.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
